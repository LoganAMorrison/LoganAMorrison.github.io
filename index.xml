<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Logan A. Morrison</title>
    <link>https://loganamorrison.github.io/</link>
      <atom:link href="https://loganamorrison.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Logan A. Morrison</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 10 Apr 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://loganamorrison.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Logan A. Morrison</title>
      <link>https://loganamorrison.github.io/</link>
    </image>
    
    <item>
      <title>FlapJax Part 1 - Making a Flappy Bird game with PyGame</title>
      <link>https://loganamorrison.github.io/post/making-some-flapjax/making_the_game/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/making-some-flapjax/making_the_game/</guid>
      <description>&lt;p&gt;The flappy bird game is quite simple. Each step, the user can take one of two
options: do nothing or flap. There are pipes that slide by which have a gap
which the player is supposed to go through. If the player hits a pipe, then game
is over. In the original game, if the player hits the ground, the game is over
as well. Additionally, the original game allows for the bird to go arbitrarily
high of the top of the screen. We will deviate from these last two. We will clip
the player to always be on the screen and allow the player to touch the ground.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    All the code for the game is available &lt;a href=&#34;https://github.com/LoganAMorrison/flapjax/tree/main/flappy_bird&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;To implement the game, we will use &lt;code&gt;pygame&lt;/code&gt;. However, much of the dynamics will
be handled ourselves with basic Python code. We will write a couple classes to
handle the bird and the pipes as well as a &lt;code&gt;gym&lt;/code&gt;-compatible class for running
the game. We will be implementing the full game. The final product will look
like the following:&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;600&#34; height=&#34;450&#34; src=&#34;../images/final_game_img.png&#34;&gt;
&lt;/p&gt;
&lt;p&gt;We will grab the game images from &lt;a href=&#34;https://github.com/sourabhv/FlapPyBird&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this repo&lt;/a&gt;.
Other than the images, we will use nothing else from that repo. We will be mimicking
&lt;a href=&#34;https://flappybird.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this version&lt;/a&gt; of the game.&lt;/p&gt;
&lt;p&gt;We will be using a modular layout for our code structure. The layout will look like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.
├── flappy_bird
│   ├── core
│   │   ├── bird.py
│   │   ├── config.py
│   │   ├── flappy_game.py
│   │   ├── flappy.py
│   │   ├── __init__.py
│   │   ├── pipe.py
│   │   ├── render.py
│   │   ├── resources
│   │   │   ├── background-base.png
│   │   │   ├── background-day.png
│   │   │   ├── background-night.png
│   │   │   ├── bluebird-downflap.png
│   │   │   ├── bluebird-midflap.png
│   │   │   ├── bluebird-upflap.png
│   │   │   ├── pipe-green.png
│   │   │   ├── pipe-red.png
│   │   │   ├── redbird-downflap.png
│   │   │   ├── redbird-midflap.png
│   │   │   └── redbird-upflap.png
│   │   ├── resources.py
│   │   └── types.py
│   ├── envs
│   │   ├── __init__.py
│   │   └── v1.py
│   ├── __init__.py
├── MANIFEST.in
├── setup.cfg
└── setup.py
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    While this game works, it is far from optimized. See the possible improvements
section for my thoughts ways to make things better.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;defining-types-coretypespy&#34;&gt;Defining types &lt;code&gt;core.types.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;In this file, we simply define some useful types.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pygame

PyGameImage = pygame.surface.Surface
PyGameRect = pygame.rect.Rect
PyGameSurface = pygame.surface.Surface

RngGenerator = np.random.Generator
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loading-the-resources-coreresourcespy&#34;&gt;Loading the resources &lt;code&gt;core.resources.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Our first job will be to load the images of the game.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pathlib

import pygame

__all__ = [&amp;quot;background_images&amp;quot;, &amp;quot;pipe_images&amp;quot;, &amp;quot;bird_images&amp;quot;]


resources_dir = pathlib.Path(__file__).parent.absolute().joinpath(&amp;quot;resources&amp;quot;)

# Function to make loading a bit less verbose
def _load_image(name: str):
    return pygame.image.load(resources_dir.joinpath(name).as_posix())


background_images = {
    &amp;quot;day&amp;quot;: _load_image(&amp;quot;background-day.png&amp;quot;),
    &amp;quot;night&amp;quot;: _load_image(&amp;quot;background-night.png&amp;quot;),
    &amp;quot;base&amp;quot;: _load_image(&amp;quot;background-base.png&amp;quot;),
}

pipe_images = {
    &amp;quot;red&amp;quot;: _load_image(&amp;quot;pipe-red.png&amp;quot;),
    &amp;quot;green&amp;quot;: _load_image(&amp;quot;pipe-green.png&amp;quot;),
}

bird_images = {
    &amp;quot;blue&amp;quot;: {
        &amp;quot;upflap&amp;quot;: _load_image(&amp;quot;bluebird-upflap.png&amp;quot;),
        &amp;quot;midflap&amp;quot;: _load_image(&amp;quot;bluebird-midflap.png&amp;quot;),
        &amp;quot;downflap&amp;quot;: _load_image(&amp;quot;bluebird-downflap.png&amp;quot;),
    },
    &amp;quot;red&amp;quot;: {
        &amp;quot;upflap&amp;quot;: _load_image(&amp;quot;redbird-upflap.png&amp;quot;),
        &amp;quot;midflap&amp;quot;: _load_image(&amp;quot;redbird-midflap.png&amp;quot;),
        &amp;quot;downflap&amp;quot;: _load_image(&amp;quot;redbird-downflap.png&amp;quot;),
    },
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The images we grabbed are a bit narrow and not quite the shape we want. With
some experimentation, we can determine the scalings to make the images look
a bit better. I chose to scale the widths by 5/3. At the end of the day, I
ended up with the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for key, image in background_images.items():
    w = image.get_rect().width * 5.0 / 3.0
    h = image.get_rect().height * (0.714 if key == &amp;quot;base&amp;quot; else 1.25)
    background_images[key] = pygame.transform.scale(image, (w, h))


for key, image in pipe_images.items():
    w = image.get_rect().width * 5.0 / 3.0
    h = image.get_rect().height * 1.094
    pipe_images[key] = pygame.transform.scale(image, (w, h))


for color in bird_images.keys():
    for flap, image in bird_images[color].items():
        w = image.get_rect().width * 5.0 / 3.0
        h = image.get_rect().height * 5.0 / 3.0
        bird_images[color][flap] = pygame.transform.scale(image, (w, h))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;game-configurations-coreconfigpy&#34;&gt;Game configurations &lt;code&gt;core.config.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Next, we will have a class that specifies the configuration of the game.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import json
from typing import Optional, Tuple

import attrs
from attrs import field, validators

def gt_or_none(value):
    def f(*args):
        val = args[-1]
        assert val is None or val &amp;gt; value, f&amp;quot;Value must be None or &amp;gt;= {value}&amp;quot;

    return f

@attrs.define
class FlappyBirdConfig:
    &amp;quot;&amp;quot;&amp;quot;
    Configuration for the FlappyBird game.

    Attributes
    ----------
    bird_color: str
        Color of the bird. Can be &#39;blue&#39; or &#39;red&#39;.
    bird_jump_velocity: float
        Velocity of the bird after flap.
    bird_jump_frequency: int
        Number of steps before bird can falp again.
    bird_start_position: Tuple[int, int]
        Starting position of the bird.
    bird_dead_on_hit_ground: bool
        If True, game is over when bird hits the ground.
    bird_max_speed: Optional[float]
        If not None, the bird&#39;s speed cannot exceed `bird_max_speed`.
    bird_rotate: bool
        If True, the bird will rotate as it moves.

    pipe_color: str
        Color of the pipes. Can be &#39;green&#39; or &#39;red&#39;.
    pipe_speed: float
        Speed of the pipes.
    pipe_gap_size: int
        Size of gap between pipes.
    pipe_spacing: int
        Space between pipes.

    background: str
        Type of background. Can be &#39;day&#39; or &#39;night&#39;.
    hide_screen: bool
        If True, the screen will not be displayed.
    show_score: bool
        If True, the score will be displayed.
    show_game_over_screen: bool
        If True, the game-over screen will be displayed.

    gravity: float
        Gravitational acceleration.
    dt: float
        Time between frames.
    fps: int
        Frames per second of the game.
    &amp;quot;&amp;quot;&amp;quot;

    bird_color: str = field(default=&amp;quot;blue&amp;quot;, validator=validators.in_([&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;]))
    bird_jump_velocity: float = field(default=4.0, validator=validators.gt(0.0))
    bird_jump_frequency: int = field(default=7, validator=validators.ge(0))
    bird_start_position: Tuple[int, int] = field(default=(100, 250))
    bird_dead_on_hit_ground: bool = field(default=True)
    bird_constrained_to_screen: bool = field(default=True)
    bird_max_speed: Optional[float] = field(default=None, validator=gt_or_none(0.0))
    bird_rotate: bool = field(default=True)

    pipe_color: str = field(default=&amp;quot;green&amp;quot;, validator=validators.in_([&amp;quot;red&amp;quot;, &amp;quot;green&amp;quot;]))
    pipe_speed: float = field(default=3, validator=validators.gt(0))
    pipe_gap_size: int = field(default=150, validator=validators.gt(0))
    pipe_spacing: int = field(default=200, validator=validators.gt(0))

    background: str = field(default=&amp;quot;day&amp;quot;, validator=validators.in_([&amp;quot;day&amp;quot;, &amp;quot;night&amp;quot;]))
    hide_screen: bool = field(default=False)
    show_score: bool = field(default=True)
    show_game_over_screen: bool = field(default=True)

    gravity: float = field(default=2.0 / 5.0, validator=validators.gt(0.0))
    dt: float = field(default=1.0, validator=validators.gt(0.0))
    fps: Optional[int] = field(default=60, validator=gt_or_none(0))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;making-the-bird-corebirdpy&#34;&gt;Making the bird &lt;code&gt;core.bird.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Possibly the most important logic of the game is the bird. We will use Newton&amp;rsquo;s
2nd law and Euler steps to model the dynamics of our bird. We assume that there
is a constant gravitational force. In addition, we will fix the horizontal
position of the bird. All motion will be in the vertical direction.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;600&#34; height=&#34;450&#34; src=&#34;../images/bird_annotated.png&#34;&gt;
&lt;/p&gt;
&lt;p&gt;In this case, the acceleration of the bird will be constant and equal to the
gravitational acceleration. The differential equations for the y-components of
position and velocity are simply:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{y}{t} &amp;= v_{y}, &amp; \dv{v_{y}}{t} &amp;= -g
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;We will update the position and velocity using an Euler step:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    y_{t+1} &amp;= y_{t} + v_{y}\Delta t, &amp; v_{y,t+1} &amp;= v_{y,t} - g \Delta t
\end{align}
$$
&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We need to note that in &lt;strong&gt;pygame&lt;/strong&gt; (and most frameworks) the vertical direction is
flipped so that a the top of the screen is $y=0$ while the bottom is $y=H_{\mathrm{screen}}$.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For simplicity, we will set $\Delta t = 1$ and tune the other parameters to give
a natural feel to the motion. We need to know how to handle the bird&amp;rsquo;s flap.
Technically, we should use an impulse. In the case of a $\delta$-function
impulse, we would get a constant shift in the velocity. Instead of doing this,
we will simply change the velocity to some fixed value after a flap (we could
think about this as a $\delta$-function impulse with a strength equal to the
current velocity plus a constant off-set.) Explicitly, after a flap, we will
change the velocity to a fixed value $\bar{v}$&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    v_{y,t+1} = \begin{cases}
    v_{y,t} - g, &amp; \text{no flap}\\
    \bar{v}, &amp; \mathrm{flap}
    \end{cases}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;In addition to linear motion, we will also allow for rotation. We will assume a
constant angular velocity $\omega$. Then the angular equation of motion and its update is:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{\theta}{t} &amp;= \omega, &amp;
    \theta_{t+1} &amp;= \theta_{t} + \omega\Delta t
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;When the bird flaps, we will instantaniously change the angle to 45 degrees.&lt;/p&gt;
&lt;p&gt;To give our bird a flapping animation, after the bird flaps, we will switch between the
&lt;code&gt;upflap&lt;/code&gt; and &lt;code&gt;downflap&lt;/code&gt; images. For reference, the bird images are as follows:&lt;/p&gt;
&lt;div class=&#34;row&#34;&gt;
    &lt;style&gt;
        .column {
            float: left;
            width:33%;
            padding: 5px;
        }
    &lt;/style&gt;
    &lt;div class=&#34;column&#34;&gt;
        &lt;img width=&#34;32&#34; height=&#34;32&#34; src=&#34;../images/bluebird-midflap.png&#34; alt=&#34;&#34;/&gt;
        &lt;p align=&#34;center&#34;&gt;mid-flap&lt;/p&gt;
    &lt;/div&gt;
    &lt;div class=&#34;column&#34;&gt;
        &lt;img width=&#34;32&#34; height=&#34;32&#34; src=&#34;../images/bluebird-downflap.png&#34; alt=&#34;&#34;/&gt;
        &lt;p align=&#34;center&#34;&gt;down-flap&lt;/p&gt;
    &lt;/div&gt;
    &lt;div class=&#34;column&#34;&gt;
        &lt;img width=&#34;32&#34; height=&#34;32&#34; src=&#34;../images/bluebird-upflap.png&#34; alt=&#34;&#34;/&gt;
        &lt;p align=&#34;center&#34;&gt;up-flap&lt;/p&gt;
    &lt;/div&gt;
&lt;/div&gt; 
&lt;p&gt;Without further delay, let&amp;rsquo;s write down our bird class:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from typing import Optional
import numpy as np
import pygame

from .config import FlappyBirdConfig
from .resources import bird_images
from .types import PyGameImage, PyGameRect, PyGameSurface


class Bird:
    def __init__(self, x0, y0, window_height, config: FlappyBirdConfig):
        # Config
        self.jump_velocity = config.bird_jump_velocity
        self.jump_frequency = config.bird_jump_frequency
        self.gravity = config.gravity
        # Angular velocity. Set such that it will look like its flappy until it
        # reaches its max height.
        self.omega = 45.0 * self.gravity / (2 * self.jump_velocity)
        self.images = bird_images[config.bird_color]
        self.image: PyGameImage = self.images[&amp;quot;midflap&amp;quot;]
        self.dt = config.dt
        self.x0 = x0
        self.y0 = y0
        self.window_height = window_height
        self.rotate = config.bird_rotate
        self.max_speed: Optional[float] = config.bird_max_speed
        # Number of flaps it takes to reach max height after a flap
        self.num_flaps = int(np.ceil(self.jump_velocity / (self.gravity * self.dt)))

        # State
        self.x = x0
        self.y = y0
        self.velocity_y = 0.0
        self.angle = 0.0
        self.jump_counter = 0 # Counter to limit jumps (flaps)
        self.flap_counter = 0 # Counter for determinings which image to display
        self.flap_type: str = &amp;quot;midflap&amp;quot;

        self.reset()

    @property
    def left(self) -&amp;gt; int:
        # left side of image
        return int(self.x - self.image.get_width() / 2.0)

    @property
    def right(self) -&amp;gt; int:
        # right side of image
        return int(self.x + self.image.get_width() / 2.0)

    @property
    def top(self) -&amp;gt; int:
        # top side of image
        return int(self.y - self.image.get_height() / 2.0)

    @property
    def bottom(self) -&amp;gt; int:
        # bottom side of image
        return int(self.y + self.image.get_height() / 2.0)

    def reset(self):
        # Reset to initial state
        self.x = self.x0
        self.y = self.y0
        self.velocity_y = 0.0
        self.dead = False
        self.angle = 0.0
        self.jump_counter = 0

    def flap(self):
        # If jump_counter == 0, we can flap!
        if self.jump_counter == 0:
            self.velocity_y = -self.jump_velocity
            self.jump_velocity = self.jump_frequency
            self.angle = 45.0
            self.flap_type = &amp;quot;upflap&amp;quot;
            self.image = self.images[self.flap_type]
            self.flap_counter = self.num_flaps
            self.jump_counter = self.jump_frequency

    def step(self, action: int):
        # Set the image based on flap_counter
        if self.flap_counter &amp;gt; 0:
            # If flap_counter &amp;gt; 0, we are flapping. Osscilate between upflap and
            # downflap.
            self.flap_counter -= 1
            if self.flap_type == &amp;quot;upflap&amp;quot;:
                self.flap_type = &amp;quot;downflap&amp;quot;
            elif self.flap_type == &amp;quot;downflap&amp;quot;:
                self.flap_type = &amp;quot;upflap&amp;quot;
            self.image = self.images[self.flap_type]
        else:
            self.flap_type = &amp;quot;midflap&amp;quot;
            self.image = self.images[&amp;quot;midflap&amp;quot;]

        # Update jump_counter
        if self.jump_counter &amp;gt; 0:
            self.jump_counter -= 1

        if action == 1:
            self.flap()

        # Apply Euler steps
        self.angle = np.clip(self.angle - self.omega * self.dt, -90.0, 45.0)
        self.y += self.velocity_y * self.dt
        self.velocity_y += self.gravity * self.dt

        # Limit speed if requested
        if self.max_speed is not None:
            maxv = abs(self.max_speed)
            self.velocity_y = np.clip(self.velocity_y, -maxv, maxv)

        # Limit bird position to be on screen. If we hit the boundaries, set
        # velocity to zero.
        ymax = self.window_height - self.image.get_height() / 2.0
        if self.y &amp;gt; ymax:
            self.velocity_y = 0.0
            self.y = ymax
        if self.y &amp;lt; 0.0:
            self.y = 0.0
            self.velocity_y = 0.0

    @property
    def rect(self) -&amp;gt; PyGameRect:
        # Get the pygame rect (used for collision detection)
        rect = self.image.get_rect()
        rect.left = self.left
        rect.top = self.top
        return rect

    def draw(self, surface: PyGameSurface) -&amp;gt; None:
        # Draw the bird to the surface
        image = self.image
        rect = self.rect
        if self.rotate:
            image = pygame.transform.rotate(image, self.angle)
        surface.blit(image, rect)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;making-the-pipes-corepipespy&#34;&gt;Making the pipes &lt;code&gt;core.pipes.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Our next goal is to implement the pipes. The pipe dynamics are very simple
compared to the bird dynamics. The pipes will simply move to the left. However,
there are a few things we need to consider. First, we want the location of the
gap (where the bird can fly through) to be random. Second, our images of the
pipes have a finite height, and we want the pipes to fit on the screen.&lt;/p&gt;
&lt;p&gt;Let $h$ be the total height one segement of the pipe (upper or lower pipe). Let
$H$ be the height from the top of the screen to the ground. Lastly, let $G$ be
the height of the gap between the upper and lower pipe. Here is an annotated
image with these measurements (aside from $h$ since part of the pipe is hidden.)&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;600&#34; height=&#34;450&#34; src=&#34;../images/pipe_annotated.png&#34;&gt;
&lt;/p&gt;
&lt;p&gt;We might be tempted to choose the center between the upper can lower pipes to be
a random number between $0$ and $H$.  However, since $h &amp;lt; H_{g}$, this could
cause part of either the upper or lower pipe to be off the screen. To ensure the
pipes are completely on the screen, the center must be between:&lt;/p&gt;
&lt;p&gt;
$$
h_{\mathrm{min}} = H - h - G/2 &lt; h_{c} &lt; h + G / 2 = h_{\mathrm{max}} 
$$
&lt;/p&gt;
&lt;p&gt;Now that we know the limits, we can choose a random number between
$h_{\mathrm{min}} &amp;lt; h_{c} &amp;lt; h_{\mathrm{max}}$ for the location of the center.
Once we know the center, we then set the location of the bottom of the top pipe
$h_{t} = h_{c} - G/2$ and the location of the top of the bottom pipe to
$h_{b} =h_{c} + G/2$.&lt;/p&gt;
&lt;p&gt;This is all we need to implement the &lt;code&gt;Pipe&lt;/code&gt; class. Note that we only have one
image for the pipes. So for the top pipe, we need to rotate the image by $180$
degrees to make it look likes its coming from above.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pygame

from .config import FlappyBirdConfig
from .resources import pipe_images
from .types import PyGameImage, PyGameSurface, RngGenerator


class Pipe:
    def __init__(
        self,
        config: FlappyBirdConfig,
        x: float,
        ymin: float,
        ymax: float,
        rng: RngGenerator,
    ):
        # Config
        self.gap_size = config.pipe_gap_size
        self.velocity_x = config.pipe_speed
        self.ymin = ymin
        self.ymax = ymax
        image: PyGameImage = pipe_images[config.pipe_color]
        self.top_image = pygame.transform.rotate(image, 180.0)
        self.top_rect = self.top_image.get_rect()
        self.bottom_image = image
        self.bottom_rect = self.bottom_image.get_rect()
        self.width = self.top_rect.width
        self.dt = config.dt

        # State
        self.x = x
        self.y = 0.0
        self.reset(x, rng)

    def step(self) -&amp;gt; None:
        self.x -= self.velocity_x * self.dt
        left = int(self.left)
        self.top_rect.left = left
        self.bottom_rect.left = left

    def reset(self, x, rng: RngGenerator) -&amp;gt; None:
        self.x = x
        self.y = rng.uniform(low=self.ymin, high=self.ymax)

        left = int(self.left)
        self.top_rect.left = left
        self.top_rect.bottom = int(self.y - self.gap_size / 2.0)

        self.bottom_rect.left = left
        self.bottom_rect.top = self.top_rect.bottom + self.gap_size

    def draw(self, surface: PyGameSurface):
        surface.blit(self.top_image, self.top_rect)
        surface.blit(self.bottom_image, self.bottom_rect)

    @property
    def left(self) -&amp;gt; float:
        return self.x - self.width / 2.0

    @property
    def right(self) -&amp;gt; float:
        return self.x + self.width / 2.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;game-logic-coreflappypy&#34;&gt;Game Logic &lt;code&gt;core.flappy.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Now that we have the &lt;code&gt;Bird&lt;/code&gt; and &lt;code&gt;Pipe&lt;/code&gt; classes, we&amp;rsquo;re ready to implement the
main game logic. The dynamics of the bird and individual pipes is handled by
these classes. However, our main class will handle having multiple pipes.&lt;/p&gt;
&lt;p&gt;We want the game to appear as if there is a continuous stream of pipes. To
achieve this, we will hold onto multiple pipes. When a pipe moves past the
left-side of the screen, we will move that pipe to a position beyond the pipe
furthest to the right. Explicitly,&lt;/p&gt;
&lt;p&gt;
$$
\ell^{(i)}_{t+1} = \begin{cases}
    \ell^{(i)}_{t} + v_{p}\Delta t &amp; \ell^{(i)}_{t} &gt; 0\\
    \ell^{(i-1)}_{t} + \delta &amp; \ell^{(i)}_{t} &lt; 0
\end{cases}
$$
&lt;/p&gt;
&lt;p&gt;where $\ell^{(i)}_{t}$ is the location of the left-side of pipe $i$ at the
current step. When $\ell^{(i)}_{t} &amp;gt; 0$, we just let the class handle the
motion (just use Euler step.) When $\ell^{(i)}_{t} &amp;lt; 0$, the pipe has moved
beyond the left-side of the screen. We then set the new location of the
left-edge of the pipe to be some shift $\delta$ beyond the pipe before it in the
queue. The shift $\delta$ is equal to the pipe-width plus the pipe-spacing.&lt;/p&gt;
&lt;p&gt;We also need to ensure the number of pipes in our queue is large enough to keep
the flow steady with a consistent spacing between the pipe. We use
$\mathrm{ceil}(W / (w + w_{p}))$, where $w$ is the pipe-spacing and $w_{p}$ is
the width of a pipe.&lt;/p&gt;
&lt;p&gt;This is essentially all we need to implement the game. We use &lt;strong&gt;pygame&lt;/strong&gt;&amp;rsquo;s
collision detection to determine if the bird hits anything. We also detect if
the bird has moved passed a pipe by comparing the positions of the bird and
pipe in front of the bird. We also use &lt;strong&gt;pygame&lt;/strong&gt;&amp;rsquo;s interface to render the
screen. Since this isn&amp;rsquo;t a post about &lt;strong&gt;pygame&lt;/strong&gt;, we will not dig into these
aspects.&lt;/p&gt;
&lt;p&gt;In the implementation below, we added a few bells and whistles. We added some
dynamics for the base to make it appear as if the screen is moving to the left.
Additionally, we added functionality to display the score and a game-over screen
to display the current score and maximum score obtained using the current
instance of the game. The scoring and game-over screen are mainly to replicate
existing implementations and are only used in &lt;em&gt;human&lt;/em&gt; mode.&lt;/p&gt;
&lt;p&gt;We note, however, the &lt;code&gt;step&lt;/code&gt; function. This function records if the bird hit the
ground, a pipe or if the bird passed a pipe. It then returns a dictionary with
this information. That way, other classes may choose how to use this information
to decided what to do next.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from typing import List, Optional

import numpy as np
import pygame

from .bird import Bird
from .config import FlappyBirdConfig
from .pipe import Pipe
from .resources import background_images, pipe_images
from .types import PyGameImage, PyGameSurface, RngGenerator


class FlappyBird:
    def __init__(self, config: FlappyBirdConfig, rng: Optional[RngGenerator] = None):
        # Config
        self.dead_on_hit_ground = config.bird_dead_on_hit_ground
        self.bird_constrained_to_screen = config.bird_constrained_to_screen
        self.background: PyGameImage = background_images[config.background]
        self.base: PyGameImage = background_images[&amp;quot;base&amp;quot;]
        self.hide_screen = config.hide_screen
        self.show_score = config.show_score
        self.fps = config.fps
        if rng is None:
            self.rng = np.random.default_rng()

        # Screen/PyGame init
        pygame.init()
        pygame.display.init()
        self.screen: Optional[PyGameSurface] = None
        self.width = self.background.get_width()
        self.height = self.background.get_height()  # + self.base.get_height()
        self.rect = pygame.rect.Rect(0, 0, self.width, self.height)
        self.y_ground = self.background.get_height() - self.base.get_height()

        # Setup bases
        self.base_rects = [self.base.get_rect() for _ in range(3)]
        for i, rect in enumerate(self.base_rects):
            rect.top = self.y_ground
            rect.left = i * rect.width

        # Bird setup
        x0 = self.width / 2.0
        y0 = self.background.get_height() / 2.0
        self.bird = Bird(x0, y0, self.background.get_height(), config)

        # Pipe setup
        pipe_rect = pipe_images[config.pipe_color].get_rect()
        self.pipe_spacing = config.pipe_spacing
        self.pipe_gap_size = config.pipe_gap_size
        self.pipe_width = pipe_rect.width
        self.pipe_speed = config.pipe_speed
        npipes = int(np.ceil(self.width / (self.pipe_spacing + self.pipe_width)))

        bkg_h = self.background.get_height()
        ymin = bkg_h - pipe_rect.height - self.pipe_gap_size / 2.0
        ymax = pipe_rect.height + self.pipe_gap_size / 2.0
        shift = self.width + self.pipe_width / 2.0

        self.pipes: List[Pipe] = []
        for i in range(npipes):
            x = shift + i * (self.pipe_width + self.pipe_spacing)
            self.pipes.append(Pipe(config, x, ymin, ymax, self.rng))

        # Game state
        self.game_over = False
        self.score = 0
        self.next_pipe = 0
        self.best_score = 0
        self.clock = pygame.time.Clock()

    def flap(self):
        self.bird.flap()

    def step(self, action: int):
        assert action in [0, 1], &amp;quot;Invalid action. Must be 0 or 1.&amp;quot;
        state = {&amp;quot;reward&amp;quot;: 0, &amp;quot;hit-pipe&amp;quot;: False, &amp;quot;hit-ground&amp;quot;: False}

        self.bird.step(action)

        for i, pipe in enumerate(self.pipes):
            pipe.step()

            if pipe.right &amp;lt; 0.0:
                # New left position of the pipe
                left = self.pipes[i - 1].right + self.pipe_spacing
                # Make sure the new pipe starts off the screen
                left = np.clip(left, self.width, None)
                pipe.reset(left, self.rng)

        # Detect if player has passed a pipe
        if self.bird.left &amp;gt; self.pipes[self.next_pipe].right:
            self.next_pipe = (self.next_pipe + 1) % len(self.pipes)
            state[&amp;quot;reward&amp;quot;] = 1

        # Detect if bird hit a pipe
        for pipe in self.pipes:
            if pipe.top_rect.colliderect(self.bird.rect):
                state[&amp;quot;hit-pipe&amp;quot;] = True
            if pipe.bottom_rect.colliderect(self.bird.rect):
                state[&amp;quot;hit-pipe&amp;quot;] = True

        # detect if bird hit ground
        if self.bird.rect.bottom &amp;gt; self.y_ground:
            state[&amp;quot;hit-ground&amp;quot;] = True

        self.score += state[&amp;quot;reward&amp;quot;]

        return state

    def _render(self, hidden: Optional[bool] = None):
        force_reinit = False
        if not (self.hide_screen == hidden):
            self.hide_screen = hidden
            force_reinit = True

        if self.screen is None or force_reinit:
            pygame.init()
            pygame.display.init()
            mode = pygame.SHOWN if not self.hide_screen else pygame.HIDDEN
            self.screen = pygame.display.set_mode(self.rect.size, flags=mode)

        self.screen.fill((0, 0, 0))
        self.screen.blit(self.background, (0, 0))

        self.bird.draw(self.screen)

        for pipe in self.pipes:
            pipe.draw(self.screen)

        # Step bases
        for i, base_rect in enumerate(self.base_rects):
            base_rect.left -= int(self.pipe_speed)
            if base_rect.right &amp;lt; 0:
                base_rect.left = self.base_rects[i - 1].right - int(self.pipe_speed)
            self.screen.blit(self.base, base_rect)

    def _flip(self):
        if not self.hide_screen:
            pygame.event.pump()
            if self.fps is not None:
                self.clock.tick(self.fps)
            pygame.display.flip()

    def render(self, hidden: Optional[bool] = None):
        self._render(hidden)
        assert self.screen is not None

        if self.show_score:
            score = pygame.font.Font(&amp;quot;freesansbold.ttf&amp;quot;, 32).render(
                f&amp;quot;{self.score}&amp;quot;, True, (255, 255, 255)
            )
            rect = score.get_rect()
            rect.left = self.background.get_rect().left + 5
            rect.top = self.background.get_rect().top + 5
            self.screen.blit(score, rect)

        self._flip()

    def game_over_screen(self, hidden: Optional[bool] = None):
        self._render(hidden)
        assert self.screen is not None

        if self.show_score:
            score = pygame.font.Font(&amp;quot;freesansbold.ttf&amp;quot;, 32).render(
                f&amp;quot;Score: {self.score}&amp;quot;, True, (255, 255, 255)
            )
            rect = score.get_rect()
            rect.left = self.background.get_rect().width // 2 - rect.width // 2
            rect.top = self.background.get_rect().height // 3
            self.screen.blit(score, rect)

            best_score = pygame.font.Font(&amp;quot;freesansbold.ttf&amp;quot;, 32).render(
                f&amp;quot;Best Score: {self.best_score}&amp;quot;, True, (255, 255, 255)
            )
            rect = best_score.get_rect()
            rect.left = self.background.get_rect().width // 2 - rect.width // 2
            rect.top = self.background.get_rect().height // 3 + 40
            self.screen.blit(best_score, rect)

        self._flip()

    def reset(self):
        self.bird.reset()

        shift = self.width + self.pipe_width / 2.0
        for i, pipe in enumerate(self.pipes):
            x = shift + i * (self.pipe_spacing + pipe.top_rect.width)
            pipe.reset(x, self.rng)

        self.base_rects = [self.base.get_rect() for _ in range(3)]
        for i, rect in enumerate(self.base_rects):
            rect.top = self.y_ground
            rect.left = i * rect.width

        self.game_over = False
        self.score = 0
        self.next_pipe = 0

    def close(self):
        self.screen = None
        pygame.display.quit()
        pygame.quit()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;game-environment-envsv1py&#34;&gt;Game environment &lt;code&gt;envs.v1.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Before we train a network to play, we will make an class that implements the
&lt;code&gt;gym&lt;/code&gt; interface. In the &lt;code&gt;v1&lt;/code&gt; class, we say the game is over if the bird hits a
pipe or if the bird touches the ground. We remove the frame rate to make things
go as fast as possible. Additionally, we hide the screen so nothing is
displayed. (Rendering to the screen just takes more time and is annoying when
you used a window manager like xmonad, which I do.)&lt;/p&gt;
&lt;p&gt;There is really only one aspect that is worth mentioning. We need to convert the
&lt;strong&gt;pygame&lt;/strong&gt; screen into a numpy array to pass to our network. To do this, we used
*&lt;strong&gt;pygame&lt;/strong&gt;&amp;rsquo;s &lt;code&gt;surfarray.pixels3d&lt;/code&gt; function. Since we will be used &lt;strong&gt;flax&lt;/strong&gt; to
implement our network, we need to transpose the output of &lt;code&gt;surfarray.pixels3d&lt;/code&gt;.
&lt;code&gt;surfarray.pixels3d&lt;/code&gt; returns an image of shape &lt;code&gt;(W,H,C)&lt;/code&gt;, while we want &lt;code&gt;(H,W,C)&lt;/code&gt;.
We use &lt;code&gt;np.transpose(...,axes=(1,0,2)&lt;/code&gt; to achieve this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from typing import Tuple

import gym
import numpy as np
import pygame
from gym import spaces

from flappy_bird.core.config import FlappyBirdConfig
from flappy_bird.core.flappy import FlappyBird

ActType = int
ObsType = np.ndarray

config = FlappyBirdConfig(
    bird_color=&amp;quot;blue&amp;quot;,
    bird_jump_velocity=4.0,
    bird_jump_frequency=4,
    bird_dead_on_hit_ground=True,
    bird_max_speed=None,
    bird_rotate=True,
    pipe_color=&amp;quot;green&amp;quot;,
    pipe_speed=3,
    pipe_gap_size=150,
    pipe_spacing=200,
    background=&amp;quot;day&amp;quot;,
    hide_screen=True,
    show_score=False,
    show_game_over_screen=False,
    gravity=0.4,
    dt=1.0,
    fps=None,
)


class FlappyBirdEnvV0(gym.Env):
    metadate = {&amp;quot;render.modes&amp;quot;: [&amp;quot;human&amp;quot;, &amp;quot;none&amp;quot;]}

    def __init__(self) -&amp;gt; None:
        self.flappy = FlappyBird(config)
        self.show_game_over_screen = config.show_game_over_screen
        self.bird_dead_on_hit_ground = config.bird_dead_on_hit_ground
        self.grayscale = config.grayscale
        self.hide_screen = config.hide_screen

        shape = (self.flappy.height, self.flappy.width, 3)

        self.observation_space = spaces.Box(
            low=0, high=255, shape=shape, dtype=np.uint8
        )
        self.action_space = spaces.Discrete(2)

        self.game_over = True

    def _observation(self):
        self.flappy._render(self.hide_screen)
        assert self.flappy.screen is not None

        obs = np.array(pygame.surfarray.pixels3d(self.flappy.screen), dtype=np.uint8)
        return np.transpose(obs, axes=(1, 0, 2))

    def step(self, action: ActType) -&amp;gt; Tuple[ObsType, float, bool, dict]:
        assert not self.game_over, &amp;quot;Call reset before step.&amp;quot;
        state = self.flappy.step(action)

        if state[&amp;quot;hit-pipe&amp;quot;]:
            self.game_over = True

        if state[&amp;quot;hit-ground&amp;quot;] and self.bird_dead_on_hit_ground:
            self.game_over = True

        obs = self._observation()
        reward = state[&amp;quot;reward&amp;quot;]
        done = self.game_over
        info = dict()

        return obs, reward, done, info

    def render(self, mode: str = &amp;quot;none&amp;quot;):
        hidden = mode == &amp;quot;none&amp;quot;
        if self.game_over and self.show_game_over_screen:
            self.flappy.game_over_screen(hidden)
        else:
            self.flappy.render(hidden)

    def close(self) -&amp;gt; None:
        self.flappy.close()

    def reset(self) -&amp;gt; ObsType:
        self.flappy.reset()
        self.game_over = False
        return self._observation()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;bonus-game-for-human-play-coreflappy_gamepy&#34;&gt;Bonus: Game for human play &lt;code&gt;core.flappy_game.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;It is really important to determine visualize the game. This is essential for
determining if the parameters, such as, gravitational acceleration, the bird
jump velocity, pipe gap size, pipe spacing, etc. are set to reasonable values.
Perhaps the best way of doing so is do make the game playable by a human and
play it. For this purpose, we provide the &lt;code&gt;FlappyBirdGame&lt;/code&gt; class.&lt;/p&gt;
&lt;p&gt;This class uses &lt;strong&gt;pygame&lt;/strong&gt;&amp;rsquo;s &lt;code&gt;event&lt;/code&gt; module to parse keyboard input to allow the
user to make the bird jump. It uses a couple of features that the AI version
doesn&amp;rsquo;t, such as the game over screen and score. It also adds some animations
before the start of the game.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pygame

from .config import FlappyBirdConfig
from .flappy import FlappyBird

CONFIG = FlappyBirdConfig(
    bird_color=&amp;quot;blue&amp;quot;,
    bird_jump_velocity=4.0,
    bird_jump_frequency=7,
    bird_dead_on_hit_ground=True,
    bird_max_speed=None,
    bird_rotate=True,
    pipe_color=&amp;quot;green&amp;quot;,
    pipe_speed=3,
    pipe_gap_size=150,
    pipe_spacing=200,
    background=&amp;quot;day&amp;quot;,
    hide_screen=False,
    show_score=True,
    gravity=0.4,
    dt=1.0,
    fps=60,
)


class FlappyBirdGame:
    def __init__(self):
        self.game = FlappyBird(CONFIG)
        self.action_keys = [pygame.K_SPACE, pygame.K_UP, pygame.K_KP_ENTER]
        self.game_over = False

    def _step(self):
        for event in pygame.event.get():
            if event.type == pygame.KEYDOWN:
                if event.key in self.action_keys:
                    return self.game.step(1)
        return self.game.step(0)

    def step(self):
        assert not self.game_over, &amp;quot;Game is over. Call reset.&amp;quot;
        state = self._step()
        if state[&amp;quot;hit-ground&amp;quot;] or state[&amp;quot;hit-pipe&amp;quot;]:
            self.game_over = True

    def render(self):
        self.game.render()

    def reset(self):
        self.game.reset()
        self.game_over = False

    def _play(self):
        while not self.game_over:
            self.step()
            self.render()

    def _get_key_press(self):
        for event in pygame.event.get():
            if event.type == pygame.KEYDOWN:
                return event.key
        return None

    def game_over_screen(self) -&amp;gt; None:
        self.game.game_over_screen()
        while True:
            key = self._get_key_press()
            if key is not None:
                return

    def play(self):
        oscillate_amp = 5
        oscillate_period = 50
        t = 0

        # This loop waits for an action key to pressed. While waiting, the bird
        # will appear to oscillate up and down. Once the game starts, we hand
        # off control to _play. Once finished, we hand off control to the
        # game-over screen. Onces returned, we reset and wait for input.
        y0 = self.game.bird.y
        while True:
            self.render()
            key = self._get_key_press()
            if key is not None:
                if key in self.action_keys:
                    self._play()
                    self.game_over_screen()
                    self.reset()
                    y0 = self.game.bird.y
                elif key == pygame.K_ESCAPE:
                    self.game.close()
                    return

            self.game.bird.y = y0 + oscillate_amp * np.sin(2 * np.pi * t / oscillate_period)
            t = (t + 1) % oscillate_period
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;possible-improvements&#34;&gt;Possible Improvements&lt;/h3&gt;
&lt;p&gt;This implementation works perfectly fine for human play. However, it becomes a
bit more obvious how slow it is when the AI is training. Here are my thoughts on
how things &lt;em&gt;might&lt;/em&gt; be improved.&lt;/p&gt;
&lt;h4 id=&#34;collision-detection&#34;&gt;Collision detection&lt;/h4&gt;
&lt;p&gt;First, one thing I would have liked to change is the collision detection. When
the bird is rotated, the collisions do not see obvious. Sometimes the bird image
can go through a pipe while escaping the collision detection. The collision
detection might be improved by constructing a polygon around the bird and
detecting an intersection of the polygon with the ground or pipe. However, this
might slow things down more. But it would be more pleasing.&lt;/p&gt;
&lt;h4 id=&#34;sprites&#34;&gt;Sprites?&lt;/h4&gt;
&lt;p&gt;As one can tell from the implementation, we did not use the &lt;strong&gt;pygame&lt;/strong&gt; &lt;code&gt;sprite&lt;/code&gt;
module. It is possible that using the sprite module &lt;em&gt;might&lt;/em&gt; improve the
performance for rendering the screen since groups of sprites can be drawn at
once, reducing the switching back and forth between the underlying c code and
python.&lt;/p&gt;
&lt;h4 id=&#34;pyglet&#34;&gt;Pyglet?&lt;/h4&gt;
&lt;p&gt;The code might be faster using a newer package such as &lt;strong&gt;pyglet&lt;/strong&gt;. It was a bit
less obvious how to control a game using an AI using a &lt;strong&gt;pyglet&lt;/strong&gt;
implementation, so it was not used here. However, &lt;strong&gt;pyglet&lt;/strong&gt; might be faster.&lt;/p&gt;
&lt;h4 id=&#34;opengl-pil-opencv&#34;&gt;OpenGL, PIL, OpenCV&lt;/h4&gt;
&lt;p&gt;The game is quite simple. All the dynamics can be handled in python. The only
place where &lt;strong&gt;pygame&lt;/strong&gt; came in was in collision detection and rendering. The
collision detection with rectangles is simple and can be implemented ourselves.
However, the rendering is less trivial. This is where &lt;strong&gt;pygame&lt;/strong&gt; really came
into play (and in a couple places for font rendering for the human version.)&lt;/p&gt;
&lt;p&gt;Rendering might be made faster by directly communicating with OpenGL. Or one
might try using &lt;code&gt;PIL&lt;/code&gt; (the Pillow library) or &lt;code&gt;cv2&lt;/code&gt; (OpenCV). The require a bit
more manual labor than &lt;strong&gt;pygame&lt;/strong&gt;, but may yield performance gains (or maybe
not).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FlapJax Part 2 - Reinforcement Learning, Policy Gradients, and Proximal Policy Optimization</title>
      <link>https://loganamorrison.github.io/post/making-some-flapjax/ppo/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/making-some-flapjax/ppo/</guid>
      <description>&lt;p&gt;In this section, we will be implementing an Actor-Critic reinforcement algorithm.&lt;/p&gt;
&lt;h2 id=&#34;reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/h2&gt;
&lt;h3 id=&#34;terminology-and-deep-q-learning&#34;&gt;Terminology and Deep-Q Learning&lt;/h3&gt;
&lt;p&gt;First, let us set up terminology and pose the problem a reinforcement algorithm aims to solve. Supposed we have some
world which exists in states $s\in\mathcal{S}$, which describe all information about the world. For example, if our world is
a chess game, the $s$ contains all information about the positions of the game pieces. $\mathcal{S}$ is the state-space
containing all possible states in our world can that exist.&lt;/p&gt;
&lt;p&gt;The world contains a given number of &lt;em&gt;agents&lt;/em&gt;, which can perform actions $a\in\mathcal{A}$ inside the world (in the chess example,
the agent could be one of the players and the actions would be moving a chess piece to a valid location.) Here, $a$
is an action taken from the &lt;em&gt;action-space&lt;/em&gt; $\mathcal{A}$, which contains all allowed actions.&lt;/p&gt;
&lt;p&gt;The dynamics of the world are determined by the environment $\mathcal{E}$. Think of the environment as the natural laws of the
world or the game&amp;rsquo;s rules. The environment dictates how the world will transition from a state $s$ to the next state $s&amp;rsquo;$
given that the agent took the action $a$, i.e. $\mathcal{E}$ is a map from the current state and the agent action to a new
state: $\mathcal{E}: \mathcal{S}\times\mathcal{A}\to\mathcal{S}$.&lt;/p&gt;
&lt;p&gt;Reinforcement learning aims to construct an agent that performs a particular task. For example, maybe we want an
agent that can play (and win) chess against another player or maybe an agent that can drive a car. In order to construct such an
agent, we need a criterion for how well the agent is doing at performing the specified task. We do this by constructing
a &lt;em&gt;reward&lt;/em&gt; system $\mathcal{R}$. A reward is dished out to the agent every time the agent takes an action. The reward will be
high if the action was beneficial in bringing the agent closer to performing the required task and lower otherwise.
Mathematically speaking, the reward is a function that maps the current state, action, and next state to a real number
$\mathcal{R}: \mathcal{S}\times\mathcal{A}\times\mathcal{S}\to\mathbb{R}$.&lt;/p&gt;
&lt;p&gt;The agent is often described as a &lt;em&gt;policy&lt;/em&gt; $\pi$. The policy is a
function that takes the current state and outputs an action $\pi:
\mathcal{S}\to\mathcal{A}$. For our purposes, $\pi$ will be a neutral network.
As described above, the goal is to obtain an agent who chooses actions that
bring us closer to achieving or completing the specified task. Our way
of judging whether the agent chooses actions that bring us closer to the
goal is through the rewards. The optimal agent is one that &lt;em&gt;maximizes&lt;/em&gt; the
reward.&lt;/p&gt;
&lt;p&gt;Consider a trajectory taken by the agent starting from a state $s_{t}$,
i.e. a sequence of states $s_t,s_{t+1},s_{t+2},\dots$ produced by the agent
following its policy. Consider the &lt;em&gt;return&lt;/em&gt; - the sum of all future rewards
starting from $s_t$. The return is given by&lt;/p&gt;
&lt;p&gt;
$$
R(s_{t},a_{t};s_{t+1},a_{t+1};\dots) = r_t + r_{t+1} + r_{t+2} + \cdots  = \sum_{k=0}^{\infty}r_{t+k},
$$
&lt;/p&gt;
&lt;p&gt;with $r_{i} = \mathcal{R}(s_{i}, a, s_{i+1})$ and $a_{i}$ the action taken to
transition from $s_{i}\to s_{i+1}$. Our goal is to construct an agent to
maximize this sum. If the rewards are finite numbers, then this sum won&amp;rsquo;t
converge.  The trick to make this sum converge is to make it geometric by adding
in a &lt;em&gt;discount&lt;/em&gt; factor $\gamma\in(0,1)$ to suppress future rewards. Explicitly,
we multiply $r_{t+k}$ by $$\gamma^{k}$. Another way to think about the discount
factor is that we prioritize larger rewards now.  With a discount factor, our
total reward through the trajectory is&lt;/p&gt;
&lt;p&gt;
$$
R(s_{t},a_{t};s_{t+1},a_{t+1};\dots) = 
r_t + \gamma r_{t+1} + \gamma^{2}r_{t+2} + \cdots  = \sum_{k=0}^{\infty}\gamma^{k}r_{t+k}
$$
&lt;/p&gt;
&lt;p&gt;In order to ease the explanation of the optimization algorithms, we introduce three additional
concepts: the action-value function $Q^{\pi}(s,a)$, the value function
$V^{\pi}(s)$ and the advantage $A^{\pi}(s,a)$. The value function is just the
return obtained by following the policy $\pi$ forever.  The action-value
function $Q^{\pi}(s,a)$ is the return obtained by first taking the action $a$
given state $s$, then following the policy function forever afterwards. Lastly,
the advantage is the difference between the action-value function and the value
function $A^{\pi}(s,a) = Q^{\pi}(s,a) - V^{\pi}(s)$. Explicitly, the value and
action-value functions are given by:&lt;/p&gt;
&lt;p&gt;
$$
V^{\pi}(s_{t}) = \sum_{k=0}^{\infty}\gamma^{k} \mathcal{R}(s_{t+k}, \pi(s_{t+k}), s_{t+k+1})
$$
&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
Q^{\pi}(s_{t},a_{t}) 
&amp;= \mathcal{R}(s_{t},a_{t},s_{t+1}) + \sum_{k=1}^{\infty}\gamma^{k} \mathcal{R}(s_{t+k}, \pi(s_{t+k}), s_{t+k+1})\\\\
&amp;=\mathcal{R}(s_{t},a_{t},s_{t+1}) + \gamma V^{\pi}(s_{t+1})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;The advantage function $A^{\pi}(s,a)$ measures how much better it would be to
take the action $a$ in state $s$ rather than just using the policy $\pi$. Notice
that the value and action-value functions satisfy the following equations:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Q^{\pi}(s_{t}, a_{t}) &amp;amp;= \mathcal{R}(s_{t}, a_{t}, s_{t+1}) + \gamma Q^{\pi}(s_{t+1}, \pi(s_{t+1}))\\
V^{\pi}(s_{t}) &amp;amp;= \mathcal{R}(s_{t}, \pi(s_{t}), s_{t+1}) + \gamma V^{\pi}(s_{t+1})
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now, consider the &lt;em&gt;optimal&lt;/em&gt; value/action-value function, denoted as $V^{*}$ and $Q^{*}$. The optimal
versions satisfy the above equation, but instead of using $a_{t} = \pi(s_{t})$, we simply take the
action producing the maximum results. That is,&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
Q^{*}(s_{t}, a_{t}) &amp;= \mathcal{R}(s_{t}, a_{t}, s_{t+1}) + \gamma \max_{a_{t+1}}Q^{*}(s_{t+1}, a_{t+1})\\\\
V^{*}(s_{t}) &amp;= \max_{a_{t}}\mathcal{R}(s_{t}, a_{t}, s_{t+1}) + \gamma V^{\pi}(s_{t+1})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;These are known as Bellman equations. To optimize $Q^{\pi}$, we need to minimize the following
difference:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\delta &amp;= 
Q^{\pi}(s_{t}, a_{t}) - \qty(\mathcal{R}(s_{t}, a_{t}, s_{t+1}) + \gamma \max_{a_{t+1}}Q^{\pi}(s_{t+1}, a_{t+1}))
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;and then take our policy function to be $\pi(s) =\mathrm{argmax}_{a}Q^{\pi}(s,a)$.
This is the basic approach taken for Deep-$Q$ learning: initialized a network
that takes the state $s_{t}$ and outputs values for each possible action. That is,
our network approximates $Q^{\pi}(s,a)$. We use $\pi(s) =\mathrm{argmax}_{a}Q^{\pi}(s,a)$
to perform actions and update our network at each step by minimize $\delta$ in
the above equation.&lt;/p&gt;
&lt;p&gt;As currently described, this process is very inefficient. More efficient
implementations utilize replay-memory to train on batches of experience as well as
employ multiple network to improve stabilization. However we will not go into
these optimizations here. Instead we will explore a different method for determining
the maximal policy.&lt;/p&gt;
&lt;h3 id=&#34;probabilistic-policy-functions-and-policy-gradients&#34;&gt;Probabilistic Policy Functions and Policy Gradients&lt;/h3&gt;
&lt;p&gt;In the previous section, we assumed that the environment and the policy function
were deterministic. It is much more common to use a policy function which is a
distribution of actions given states. In this section, we will transition our
policy function and environment distributions. We will then discuss policy
gradients.&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s consider a probabilistic environment. That is, given the state
$s_{t}$, the probability of transitioning to the state $s_{t+1}$ is
$\mathcal{E}(s_{t+1}|s_{t},a_{t})$. In addition, we take our policy function to
be $\pi = \pi(a|s)$, i.e., a probability distribution over actions given the
state $s$. Given that our system has become stochastic, the trajectories taken by
an agent following $\pi$ will be stochastic. A stochastic process of this form
is a Markov Decision Process, where the transition function
$P(s_{t+1},s_{t}) = \mathcal{E}(s_{t+1}|s_{t},a_{t})\pi(a_{t}|s_{t})$ only depends
on the current state.&lt;/p&gt;
&lt;p&gt;As in the previous sections, our goal is to optimize our policy function in
order to maximize the total return. Given that our functions are now
probabilistic, the return is additionally probabilistic. Therefore, we will
maximize the expectation value of the return. In order to compute the
expectation value of the return, we will need to average over all possible
trajectories the agent can take following the policy. This requires knowing
the probability of a given trajectory. Consider a trajectory specified by
the state/action pairs ending in the state $s_{t+N+1}$:
$\tau=(s_{t},a_{t},\dots,s_{t+N},a_{t+N};s_{t+N+1})$. The probability of
this trajectory is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
P(\tau) &amp;= \rho(s_{t})\prod_{k=0}^{N}\mathcal{E}(s_{t+k+1}|s_{t+k},a_{t+k})\pi(a_{t+k}|s_{t+k})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;In this expression, $\rho(s_{t})$ specifies the probability of starting in state
$s_{t}$. Now consider the return given this trajectory. The reward given the
transition $s_{t},a_{t}\to s_{t+1}$ is $\mathcal{R}(s_{t},a_{t},s_{t+1})$. Thus,
the return of the trajectory is&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
R(\tau) &amp;= \sum_{k=0}^{N}\mathcal{R}(s_{t+k},a_{t+k},s_{t+k+1})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;To compute the expectation value of the return, we need to average the return
over all possible trajectories, which requires an integration over all possible
trajectories. That is, we need to perform a path integral:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\mathbb{E}\qty[R] &amp;= \int\mathcal{D}\tau P(\tau)R(\tau)\\\\
&amp;= 
\qty[\prod_{k=0}^{N}\int\dd{a_{t+k}}\int\dd{s_{t+k}}]
\int\dd{s_{t+N+1}}
\rho(s_{t})\prod_{k=0}^{N}\mathcal{E}(s_{t+k+1}|s_{t+k},a_{t+k})\pi(a_{t+k}|s_{t+k})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Now supposed our policy function is parameterized by internal variables
$\theta$: $\pi = \pi_{\theta}$.  If we want to optimize our policy function to
yield the maximum return, we need to maximize $\mathbb{E}[R]$.  To do so, we can
use gradient accent. The gradient of the expectation value of $R$ is:&lt;/p&gt;
&lt;p&gt;
\begin{align}
\mathbb{E}_{\tau}\qty[R] &amp;= \int\mathcal{D}\tau R(\tau) \nabla_{\theta}P_{\theta}(\tau)\\\\
&amp;= \int\mathcal{D}\tau R(\tau) P_{\theta}(\tau)\nabla_{\theta}\log P_{\theta}(\tau)\\\\
&amp;= \mathbb{E}_{\tau}\qty[R(\tau)\nabla_{\theta}\log P_{\theta}(\tau)]
\end{align}
&lt;/p&gt;
&lt;p&gt;were we used $\nabla f = f \nabla\log f$. However, note that $\nabla\log P_{\theta}\tau$ is&lt;/p&gt;
&lt;p&gt;
\begin{align}
\nabla_{\theta}\log P(\tau) &amp;= \nabla_{\theta}\log\rho(s_{t}) 
+ \sum_{k=0}^{N}\nabla_{\theta}\log\mathcal{E}(s_{t+k+1}|s_{t+k},a_{t+k})
+ \sum_{k=0}^{N}\nabla_{\theta}\log\pi_{\theta}(a_{t+k}|s_{t+k})\\\\
 &amp;= \sum_{k=0}^{N}\nabla_{\theta}\log\pi_{\theta}(a_{t+k}|s_{t+k})
\end{align}
&lt;/p&gt;
&lt;p&gt;(since only $\pi$ depends on $\theta$.) Therefore, the expectation value of the return is:&lt;/p&gt;
&lt;p&gt;
\begin{align}
\mathbb{E}_{\tau}\qty[R] &amp;= \mathbb{E}_{\tau}\qty[R(\tau)
\sum_{k=0}^{N}\nabla_{\theta}\log\pi_{\theta}(a_{t+k}|s_{t+k})
]
\end{align}
&lt;/p&gt;
&lt;p&gt;In practice, it is impractical to perform the functional integral needed to
compute this expectation value.  Instead, we make use Monte Carlo integration to
compute the expectation value. Recall that:&lt;/p&gt;
&lt;p&gt;
\begin{align}
\int_{\Omega}\dd{\vec{x}}f(\vec{x}) \sim \frac{1}{N}\sum_{\vec{x}_{i}}f(\vec{x}_{i})
\end{align}
&lt;/p&gt;
&lt;p&gt;which is true if sampling $\vec{x}\sim\Omega$ uniformly. If instead we sample from a
distribution $p(\vec{x})$, then we have&lt;/p&gt;
&lt;p&gt;
\begin{align}
\int_{\Omega}\dd{\vec{x}}f(\vec{x}) \sim \frac{1}{N}\sum_{\vec{x}_{i}}\frac{f(\vec{x}_{i})}{p(\vec{x}_{i})}
\end{align}
&lt;/p&gt;
&lt;p&gt;Thus, if we sample our trajectories from $P(\tau)$ (which is what we&amp;rsquo;re doing
when we let follow the policy function in our stochastic environment), our
expectation value of the return is asymptotic (as $N\to\infty$) to&lt;/p&gt;
&lt;p&gt;
\begin{align}
\mathbb{E}_{\tau}\qty[R] &amp;\sim \frac{1}{N}\sum_{\tau_{i}}R(\tau_{i})
\sum_{k=0}^{N}\nabla_{\theta}\log\pi_{\theta}(a^{\tau_{i}}_{t+k}|s^{\tau_{i}}_{t+k})
]
\end{align}
&lt;/p&gt;
&lt;p&gt;Thus, to optimize our policy function to yield the maximum return, we collect
$N$ trajectories, perform a gradient decent on $-\mathbb{E}[R]$ and repeat until
we converge to the optimal policy.&lt;/p&gt;
&lt;p&gt;An important thing to note is the our above expression can be reduced. In the
current form, we&amp;rsquo;re weighting $\nabla_{\theta}\log\pi_{\theta}(a_{k}|s_{k})$ by
the entire return $R(\tau)$. It turns out that the expectation value returns
accumulated prior to $s_{k}$ will vanish. To show this, consider a term in the
expectation value of the form:&lt;/p&gt;
&lt;p&gt;
\begin{align}
\mathcal{R}(s_{m},a_{m},s_{m+1})\nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{n})
\end{align}
&lt;/p&gt;
&lt;p&gt;with $t &amp;lt; n,m &amp;lt; t + N$. The expectation value of this term can be written as:&lt;/p&gt;
&lt;p&gt;
\begin{align}
I_{m,n} &amp;= \mathbb{E}[\mathcal{R}(s_{m},a_{m},s_{m+1})\nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{n})] \\\\
&amp;= \qty(\prod_{k=0}^{N}\int\dd{a_{k}}\dd{s_{k}}P\qty(s_{k+1},s_{k}))\rho(s_{t})\int\dd{s_{t+N+1}}
\mathcal{R}(s_{m},a_{m},s_{m+1})\nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{n})
\end{align}
&lt;/p&gt;
&lt;p&gt;Note that we can safely integrate over all $a_{k},s_{k}$ for $k&amp;gt;m+1,n$. This is because the probability of
having some tail trajectory (unweighted by $R$ or $\nabla_{\theta}\log\pi_{\theta}$) is one. Thus,&lt;/p&gt;
&lt;p&gt;
\begin{align}
I_{m,n}
&amp;= \qty(\prod_{k=0}^{\mathrm{max}(m+1,n)}\int\dd{a_{k}}\dd{s_{k}}P\qty(s_{k+1}|s_{k},a_{k})\pi\qty(a_{k}|s_{k}))
\rho(s_{t})\mathcal{R}(s_{m},a_{m},s_{m+1})\nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{n})
\end{align}
&lt;/p&gt;
&lt;p&gt;Now suppose $m &amp;lt; n$. In this case, we can peel off the last integrals of $a_{n},s_{n},s_{n+1}$, obtaining&lt;/p&gt;
&lt;p&gt;
\begin{align}
\int\dd{s_{n}}\int\dd{a_{n}}\int\dd{s_{n+1}}
P\qty(s_{n+1}|s_{n},a_{n})\pi(a_{n}|s_{n})
P\qty(s_{n}|s_{n-1},a_{n-1})\pi(a_{n-1}|s_{n-1})
\nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{n})
\end{align}
&lt;/p&gt;
&lt;p&gt;The integral over $s_{n+1}$ can be performed and the result is 1. Thus, we are left with&lt;/p&gt;
&lt;p&gt;
\begin{align}
\int\dd{s_{n}}
P\qty(s_{n}|s_{n-1},a_{n-1})\pi(a_{n-1}|s_{n-1})
\int\dd{a_{n}}
\pi(a_{n}|s_{n})
\nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{n})
\end{align}
&lt;/p&gt;
&lt;p&gt;The last integral can be evaluated. To evaluate, we first rewrite the integrand using
$\pi(a_{n}|s_{s})\nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{s}) = \nabla_{\theta}\pi_{\theta}(a_{n}|s_{n})$.
Then, pulling the derivative outside the integral, we end up with:&lt;/p&gt;
&lt;p&gt;
\begin{align}
\int\dd{a_{n}} \pi(a_{n}|s_{n}) \nabla_{\theta}\log\pi_{\theta}(a_{n}|s_{n}) 
&amp;= \int\dd{a_{n}} \nabla_{\theta} \pi(a_{n}|s_{n})\\\\ 
&amp;= \nabla_{\theta} \int\dd{a_{n}} \pi(a_{n}|s_{n})\\\\ 
&amp;= 0
\end{align}
&lt;/p&gt;
&lt;p&gt;where we used the fact that $\int\pi(a_{n}|s_{n})\dd{a_{n}} = 1$.&lt;/p&gt;
&lt;p&gt;In the case where $m \geq n$, we cannot perform the last few steps. This is
because the tail trajectory beyond $n$ will be weighted by
$\mathcal{R}(s_{m},a_{m}, s_{m+1})$.  Since $\mathcal{R}(s_{m}, a_{m}, s_{m+1})$
is dependent on the actions taken in steps before $m$, the integral over the
tail trajectory will also be dependent on previous actions and hence dependent
on $a_{n}$.  Thus, the integral over $a_{n}$ will have additional factors from
the tail trajectory that prevent us from evaluating the integral analytically.&lt;/p&gt;
&lt;p&gt;These results tell use that only future rewards matter inside the expectation
value. This allows us to reduce the terms inside the expectation value of the
return to:&lt;/p&gt;
&lt;p&gt;
\begin{align}
\mathbb{E}_{\tau}\qty[R] &amp;= \mathbb{E}_{\tau}\qty[
\sum_{k=0}^{N}\nabla_{\theta}\log\pi_{\theta}(a_{t+k}|s_{t+k})
\sum_{n=k}^{N}\mathcal{R}(s_{t+n},a_{n},s_{t+n+1})
]
\end{align}
&lt;/p&gt;
&lt;p&gt;Another important fact is that we are free to add any function $b$ to the above
expression that only depends on state, as it will drop out of the expectation
value. A typical approach is to augment the above expression as:&lt;/p&gt;
&lt;p&gt;
\begin{align}
\mathbb{E}_{\tau}\qty[R] &amp;= \mathbb{E}_{\tau}\qty[
\sum_{k=0}^{N}\nabla_{\theta}\log\pi_{\theta}(a_{t+k}|s_{t+k})
\sum_{n=k}^{N}\qty(\mathcal{R}\qty(s_{t+n},a_{n},s_{t+n+1}) - b(s_{t}))
]
\end{align}
&lt;/p&gt;
&lt;p&gt;Here $b$ is known as the &lt;em&gt;baseline&lt;/em&gt;. Adding it has no effect on the expectation
value, but it often helps in the training of the policy. The approach we will
end up taking is to set $b$ to be the value function. Then, the above expression
will reduce to&lt;/p&gt;
&lt;p&gt;
\begin{align}
\mathbb{E}_{\tau}\qty[R] &amp;= \mathbb{E}_{\tau}\qty[
\sum_{k=0}^{N}\nabla_{\theta}\log\pi_{\theta}(a_{t+k}|s_{t+k})
\hat{A}_{t+k}
]
\end{align}
&lt;/p&gt;
&lt;p&gt;where $\hat{A}_{t} = Q^{\pi}(s_{t},a_{t}) - V^{\pi}(s_{t})$ is the advantage.
This has the benefit that in cases where the advantage is zero, i.e., when we are
accurately predicting the value function, the term doesn&amp;rsquo;t contribute, allowing
us to focus on situations where we are incorrectly predicting the value function. See
&lt;a href=&#34;https://spinningup.openai.com/en/latest/spinningup/extra_pg_proof2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this post&lt;/a&gt;
for a proof that using the action-value $Q^{\pi}(a_{t}|s_{t})$ results in the
same expectation value.&lt;/p&gt;
&lt;h3 id=&#34;proximal-policy-optimization&#34;&gt;Proximal Policy Optimization&lt;/h3&gt;
&lt;p&gt;Proximal Policy Optimization (PPO) is similar in spirit to the concepts
described above but aims to be more stable and efficient. It puts together ideas
from Advantage Actor-Critic (A2C), Trust-Region Policy Optimization (TRPO) and
asynchronous methods. We will describe the basic principles of the various
algorithm then put them together to reproduce PPO.&lt;/p&gt;
&lt;p&gt;First, we will be using an Actor-Critic configuration where we have an &lt;strong&gt;actor&lt;/strong&gt;
network that computes the policy $\pi_{\theta}(a|s)$ and a &lt;strong&gt;critic&lt;/strong&gt; network
which computes the value function $V_{\theta}(s)$. These networks can share
parameters or have separate parameters. The goal is to have the actor-critic
maximize the expectation value of the return. The TRPO algorithm suggest using
the following &lt;em&gt;surrogate&lt;/em&gt; function:&lt;/p&gt;
&lt;p&gt;
$$
\underset{\theta}{\mathrm{maximize}}\quad
\hat{\mathbb{E}}_{t}\qty[
    \frac{\pi_{\theta}(a_{t}|s_{t})}{\pi_{\theta_{\mathrm{old}}}(a_{t}|s_{t})}
    \hat{A}_{t}
]
$$
&lt;/p&gt;
&lt;p&gt;subject to the constraint that the relative entropy (KL divergence) is less than
a hyperparameter $\delta$&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\hat{\mathbb{E}}_{t}\qty[\mathrm{KL}\qty[\pi_{\theta_{\mathrm{old}}}(\cdot|s_{t}),\pi_{\theta}(\cdot|s_{t})]] \leq \delta
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Here $\pi_{\theta_{\mathrm{old}}}$ represents the distribution from the previous
iteration. This expectation value looks different from the one we developed in
our previous exploration into policy gradients, but it turns out that if
$\vb*{\theta_{\mathrm{old}}}$ is not too far off from $\vb*{\theta}$ then the two expression
yield the same gradient up to terms of order $\vb*{\theta}-\vb*{\theta_{\mathrm{old}}}$:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\grad_{\vb*{\theta}}
\frac{\pi_{\vb*{\theta}}}{\pi_{\vb*{\theta}_{\mathrm{old}}}}
&amp;=
\frac{\pi_{\vb*{\theta}}}{\pi_{\vb*{\theta}_{\mathrm{old}}}}
\grad_{\vb*{\theta}}\log\pi_{\vb*{\theta}}\\\\
&amp;=
\frac{
\pi_{\vb*{\theta_{\mathrm{old}}}} 
+ \delta\vb*{\theta}\cdot\eval{\grad_{\vb*{\theta}}\pi}_{\vb*{\theta}_{\mathrm{old}}}
+ \cdots
}{
    \pi_{\vb*{\theta}_{\mathrm{old}}}
}
\grad_{\vb*{\theta}}\log\pi_{\vb*{\theta}}\\\\
&amp;=
\grad_{\vb*{\theta}}\log\pi_{\vb*{\theta}}
+ \order{\delta\vb*{\theta}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;with $\delta\vb*{\theta} = (\vb*{\theta} - \vb*{\theta}_{\mathrm{old}})$. Thus,
maximizing the surrogate yields the same result as maximizing the
expectation of the return since the two gradients are identical at the extrema.
The constraint on the relative entropy ensures that we don&amp;rsquo;t stray too far from
the old values, keeping $\delta\vb*{\theta}$ small.&lt;/p&gt;
&lt;p&gt;PPO uses a similar surrogate, but doesn&amp;rsquo;t use the relative entropy constraint
(but there are versions which employ the relative entropy.) Instead, PPO uses
the following:&lt;/p&gt;
&lt;p&gt;
$$
L^{\mathrm{CLIP}}_{t}(\theta) = -\min(r_{t}(\theta)\hat{A}_{t}, \mathrm{clip}(r_{t}(\theta), 1-\epsilon,1+\epsilon)\hat{A}_{t})
$$
&lt;/p&gt;
&lt;p&gt;where $r_{\vb*{\theta}} = \pi_{\vb*{\theta}} / \pi_{\vb*{\theta}_{\mathrm{old}}}$.
In this form, it&amp;rsquo;s not very intuitive what&amp;rsquo;s going on. It is instructive to
consider what this function does when the advantage is positive or negative:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\hat{A}_{t} &gt; 0: \qquad
L^{\mathrm{CLIP}}_{t}(\theta)
&amp;=-\min(r_{t}, 1+\epsilon)\hat{A}_{t}\\\\
\hat{A}_{t} &lt; 0: \qquad
L^{\mathrm{CLIP}}_{t}(\theta)
&amp;=-\max(r_{t}, 1-\epsilon)\hat{A}_{t}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;This loss function looks as follows:&lt;/p&gt;
&lt;img src=&#34;../images/loss.png&#34; alt=&#34;ppo_loss_function&#34; width=&#34;600&#34;/&gt;
&lt;p&gt;We can see that, if we&amp;rsquo;re minimizing $L^{\mathrm{CLIP}}_{t}(\vb*{\theta})$, then
the clipping cuts off how much we&amp;rsquo;re allowed to minimize. For example, if
$\hat{A}_{t}&amp;gt;0$, then increasing the probability $\pi_{\theta}(a|s)$ beyond a
certain point has not effect on the loss function, specifically when
$r_{t}(\theta) &amp;gt; 1 + \epsilon$. When $\hat{A}_{t}&amp;lt;0$, then
we have the reverse situation: decreasing the probability will have no effect
beyond $r_{t}(\theta) &amp;lt; 1-\epsilon$. Thus, there is no incentive to move
$r_{t}(\vb*{\theta})$ further than $\epsilon$, as moving further than $\epsilon$
makes the gradient from $L^{\mathrm{CLIP}}_{t}$ zero.&lt;/p&gt;
&lt;p&gt;Next, let&amp;rsquo;s discuss the advantage function. PPO uses the Generalized Advantage
Estimation (GAE). The GAE used by PPO is given by the following:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\hat{A}_{t} &amp;= \delta_{t} + (\gamma\lambda)\delta_{t+1} + \cdots + (\gamma\lambda)^{N}\delta_{t+N}\\\\
\delta_{t} &amp;= r_{t} + \gamma V(s_{t+1}) - V(s_{t})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where $N$ is the number of times steps taken for the trajectory (fixed for all trajectories),
$\gamma$ is the discount and $\lambda$ is an additional hyperparameter. For $\lambda=1$, this
reduces to the standard advantage with a finite number of steps. See &lt;a href=&#34;https://arxiv.org/abs/1506.02438&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this paper&lt;/a&gt;
for a detailed explanation of GAE.&lt;/p&gt;
&lt;p&gt;Since we have a critic, we will add a loss function to train the critic. We use the mean-squared-error
for the critic:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
L_{t}^{\mathrm{VF}}(\theta) &amp;= \qty(V_{\theta}(s_{t}) - V_{t}^{\mathrm{targ}})^2
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where $V_{t}^{\mathrm{targ}}$ is the actual return observed using the policy.
PPO uses one additional loss function used to encourage exploration. We add a loss
function that aims to increase the entropy of the policy&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
L_{t}^{\mathrm{entropy}}(\theta) &amp;= -S[\pi_{\theta}]
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Thus, our total loss function is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
L_{t}(\theta) &amp;= \hat{\mathbb{E}}_{t}\qty[
    L_{t}^{\mathrm{CLIP}}(\theta)
    + c_1 L_{t}^{\mathrm{VF}}(\theta) 
    + c_2 L_{t}^{\mathrm{entropy}}(\theta)
]
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where $c_{1}$ and $c_{2}$ are additional hyperparameters. The last item we need to discuss is the
asynchronous evaluation. Taking inspiration from A2C, we improve training speed and batch size
by running multiple trajectories at the same time. For example, if we run $M$ separate trajectories
at the same time, each for $N$ time steps, then we end up with a batch of size $MN$.&lt;/p&gt;
&lt;p&gt;These are all the elements of PPO. The full algorithm is as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$\textbf{for}$ iteration $\leftarrow 1,\text{MaxSteps}$ $\textbf{do}$&lt;br&gt;
$\quad$// Collect trajectories&lt;br&gt;
$\quad\textbf{for}$ actor $\leftarrow 1, M$ $\textbf{do}$&lt;br&gt;
$\quad\quad\textbf{for}$ $t$ $\leftarrow 1, N$ $\textbf{do}$&lt;br&gt;
$\quad\quad\quad$Step environment using $\pi_{\theta}$&lt;br&gt;
$\quad\quad\quad$Store $V_{t}$, $r_{t}$, $a_{t}$, $s_{t}$, $\log\pi(a_{t}|s_{t})$&lt;br&gt;
$\quad\quad\textbf{end}$ $\textbf{for}$&lt;br&gt;
$\quad\quad$Compute GAEs $\hat{A}_{1},\dots,\hat{A}_{N}$&lt;br&gt;
$\quad\textbf{end}$ $\textbf{for}$&lt;/p&gt;
&lt;p&gt;$\quad$// Optimize&lt;br&gt;
$\quad n_{\mathrm{batch}} \leftarrow \text{mini_batch_size}$&lt;br&gt;
$\quad N_{\mathrm{batches}} \leftarrow MN / n_{\mathrm{batch}}$&lt;br&gt;
$\quad\textbf{for}$ batch $\leftarrow 1, N_{\mathrm{batches}}$ $\textbf{do}$&lt;br&gt;
$\quad\quad$ Extract $\log\pi_{\vb*{\theta}_{\mathrm{old}}}$, action $a$ state $s$, value $V$, advantage $\hat{A}$ from trajectory&lt;br&gt;
$\quad\quad$ Compute $r_{\vb*{\theta}} = \exp(\log\pi_{\vb*{\theta}}(a) - \log\pi_{\vb*{\theta}_{\mathrm{old}}})$&lt;br&gt;
$\quad\quad$ Compute loss $L_{t}(\vb*{\theta})$&lt;br&gt;
$\quad\quad$ Back-propagate to update $\vb*{\theta}$&lt;br&gt;
$\quad\textbf{end}$ $\textbf{for}$&lt;br&gt;
$\textbf{end}$ $\textbf{for}$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;The PPO paper: &lt;a href=&#34;https://arxiv.org/abs/1707.06347&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PP0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The TRPO paper: &lt;a href=&#34;https://arxiv.org/abs/1502.05477&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TRPO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paper on Generalized advantage functions: &lt;a href=&#34;https://arxiv.org/abs/1506.02438&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GAE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paper on Asynchronous Actor-Critic &lt;a href=&#34;https://arxiv.org/abs/1602.01783&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A2C&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paper on Deep Q-Networks: &lt;a href=&#34;https://arxiv.org/pdf/1312.5602.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DQN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paper on distributional rewards: &lt;a href=&#34;https://arxiv.org/pdf/1707.06887.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Distributional Rewards&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paper on per-experience replay: &lt;a href=&#34;https://arxiv.org/pdf/1511.05952.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PER&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paper on double Deep-Q networks: &lt;a href=&#34;https://arxiv.org/pdf/1511.06581.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DDQN&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/1509.06461.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DDQN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1507.06527.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DRQN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paper on Actor-Critic methods: &lt;a href=&#34;https://proceedings.neurips.cc/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Actor Critc&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>FlapJax Part 3 - Implementation of the proximal policy optimization algorithm using Jax and Flax</title>
      <link>https://loganamorrison.github.io/post/making-some-flapjax/impl/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/making-some-flapjax/impl/</guid>
      <description>&lt;p&gt;In this part of the post, we will actually write all the code to implement the
Proximal-Policy-Optimization algorithm. We will be using
&lt;a href=&#34;https://jax.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;jax&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&#34;https://flax.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;flax&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&#34;https://optax.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;optax&lt;/code&gt;&lt;/a&gt; to implement the algorithm,
network and optimization. If the reader is unfamiliar with these tools, I advise
reading though their documentation. These tools have a bit of a learning curve.
But once you get used to them, they are a joy to work with. Much of the code
written here is easily adapted to &lt;code&gt;tensorflow&lt;/code&gt; or &lt;code&gt;pytorch&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    All the code for the PPO algorithm is available &lt;a href=&#34;https://github.com/LoganAMorrison/flapjax/tree/main/proximal_policy_optimization&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;gym-environment&#34;&gt;&lt;code&gt;gym&lt;/code&gt; Environment&lt;/h2&gt;
&lt;p&gt;It will be helpful to make a couple adjustments to the observations returned by the game. Let&amp;rsquo;s take a quick peek at the observation:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env = FlappyBirdEnvV0()

# Step in such a way that we will always go through pipes. We only use this for
# visualization.
def env_step_without_dying(env, nsteps):
    observation = env.reset()
    for _ in range(nsteps):
        env.flappy.bird.y = env.flappy.pipes[env.flappy.next_pipe].top_rect.bottom + env.flappy.pipe_gap_size / 2
        observation, _, _, _ = env.step(env.action_space.sample())
    return observation

observation = env_step_without_dying(env, 150)
plt.figure(dpi=100)
plt.imshow(observation)
plt.xticks([])
plt.yticks([]);
print(f&amp;quot;observation.shape = {observation.shape}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;observation.shape = (640, 480, 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/ppo_files/ppo_3_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The first change we will make is to resize the observation. As is, the image size is way to big. My 6GB GPU can&amp;rsquo;t handle it. We will reduce the size to be 84X84 just like people do for Atari. We use &lt;strong&gt;gym&lt;/strong&gt;&amp;rsquo;s wrapper for this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env = FlappyBirdEnvV0()
env = ResizeObservation(env, (84, 84))

observation = env.reset()
# Step a few times to bring the pipes into view
for _ in range(10):
    env.step(env.action_space.sample())

fig, axes = plt.subplots(1, 4, dpi=100, figsize=(10,3))
for i in range(len(axes)):
    axes[i].imshow(env.step(env.action_space.sample())[0])
    axes[i].set_xticklabels([])
    axes[i].set_yticklabels([])
    axes[i].grid(True, which=&amp;quot;both&amp;quot;, color=&amp;quot;w&amp;quot;, linestyle=&amp;quot;-&amp;quot;, linewidth=1, alpha=0.2)
print(f&amp;quot;observation.shape = {observation.shape}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;observation.shape = (84, 84, 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/ppo_files/ppo_5_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This size is much more manageable.&lt;/p&gt;
&lt;p&gt;Next, note that color isn&amp;rsquo;t necessary (the objects can be inferred by their
shape) and the color dimension just takes up more memory. So our first
modification to the observations will be to convert the observations to
gray-scale. To do this, we will use the &lt;strong&gt;gym&lt;/strong&gt; wrapper:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env = FlappyBirdEnvV0()
env = ResizeObservation(env, (84, 84))
env = GrayScaleObservation(env)

observation = env.reset()
# Step a few times to bring the pipes into view
for _ in range(10):
    env.step(env.action_space.sample())

fig, axes = plt.subplots(1, 4, dpi=100, figsize=(10,3))
for i in range(len(axes)):
    axes[i].imshow(env.step(env.action_space.sample())[0])
    axes[i].set_xticklabels([])
    axes[i].set_yticklabels([])
    axes[i].grid(True, which=&amp;quot;both&amp;quot;, color=&amp;quot;w&amp;quot;, linestyle=&amp;quot;-&amp;quot;, linewidth=1, alpha=0.2)
print(f&amp;quot;observation.shape = {observation.shape}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;observation.shape = (84, 84)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/ppo_files/ppo_7_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We can clearly still tell where the &amp;ldquo;bird&amp;rdquo; is and where the pipes are and we&amp;rsquo;ve cut the memory down by a factor of 3. The next modification we will make is frame-skipping. If we use the game as is, from one frame to the next, not a whole lot changes. Additionally, there are many steps between rewards. To make the observations more dynamical and reduce the time between rewards, we can skip frame. A common approach is to skip 4 frames and return the last frame or a max-pool of the last two observations.&lt;/p&gt;
&lt;p&gt;We will adapt the &lt;code&gt;gym.wrappers.AtariPreprocessing&lt;/code&gt; code (which implements frame-skipping, among other things.) Our frame-skipping class will be:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class FrameSkip(gym.Wrapper):
    def __init__(self, env: gym.Env, frame_skip: int = 4):
        super().__init__(env)
        assert frame_skip &amp;gt; 0

        self.frame_skip = frame_skip

        # buffer of most recent two observations for max pooling
        assert env.observation_space.shape is not None
        self.obs_buffer = [
            np.empty(env.observation_space.shape, dtype=np.uint8),
            np.empty(env.observation_space.shape, dtype=np.uint8),
        ]

        self.observation_space = env.observation_space

    def step(self, action):
        r = 0.0

        done = False
        info = dict()
        for t in range(self.frame_skip):
            observation, reward, done, info = self.env.step(action)
            r += reward

            if done:
                break
            if t == self.frame_skip - 2:
                self.obs_buffer[1] = observation
            elif t == self.frame_skip - 1:
                self.obs_buffer[0] = observation

        return self._get_obs(), r, done, info

    def reset(self, **kwargs):
        self.obs_buffer[0] = self.env.reset(**kwargs)
        self.obs_buffer[1].fill(0)
        return self._get_obs()

    def _get_obs(self):
        if self.frame_skip &amp;gt; 1:  # more efficient in-place pooling
            np.maximum(self.obs_buffer[0], self.obs_buffer[1], out=self.obs_buffer[0])
        obs = self.obs_buffer[0]
        return obs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Every time &lt;code&gt;env.step(action)&lt;/code&gt; is called, this wrapper will apply the same action a given number of times, record the last two observations and return their max-pool. That way we get all the important information from the last two observations. Let&amp;rsquo;s take a look at what the observations look like:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;env = FlappyBirdEnvV0()
env = ResizeObservation(env, (84, 84))
env = GrayScaleObservation(env)
env = FrameSkip(env)

env.reset()
# Step a few times to bring the pipes into view
for _ in range(10):
    env.step(env.action_space.sample())

fig, axes = plt.subplots(1, 4, dpi=100, figsize=(10,3))
for i in range(len(axes)):
    axes[i].imshow(env.step(env.action_space.sample())[0])
    axes[i].set_xticklabels([])
    axes[i].set_yticklabels([])
    axes[i].grid(True, which=&amp;quot;both&amp;quot;, color=&amp;quot;w&amp;quot;, linestyle=&amp;quot;-&amp;quot;, linewidth=1, alpha=0.2)
print(f&amp;quot;observation.shape = {observation.shape}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;observation.shape = (84, 84)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../images/ppo_files/ppo_11_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Comparing with our observations without frame-skipping, we can now see motion between frames.&lt;/p&gt;
&lt;p&gt;Before moving on to the code for the implementing the model, let&amp;rsquo;s add a couple methods to make calling our environment a bit easier.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def env_reset(env: Union[GymEnv, GymVecEnv]):
    &amp;quot;&amp;quot;&amp;quot;Reset environment and return jax array of observation.&amp;quot;&amp;quot;&amp;quot;
    observation = env.reset()
    return jnp.array(observation, dtype=jnp.float32)


def env_step(
    action: jnp.ndarray, env: Union[GymEnv, GymVecEnv]
) -&amp;gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:
    &amp;quot;&amp;quot;&amp;quot;Step environment and return jax array of observation, reward and terminal status.&amp;quot;&amp;quot;&amp;quot;
    act = np.array(jax.device_get(action), dtype=np.int32)

    if not isinstance(env, gym.vector.VectorEnv):
        observation, reward, done, _ = env.step(act[0])
    else:
        observation, reward, done, _ = env.step(act)

    observation = np.array(observation)
    reward = np.array(reward, dtype=np.int32)
    done = np.array(done, dtype=np.int32)

    # Make the batch dimension for non-vector environments
    if not isinstance(env, gym.vector.VectorEnv):
        observation = np.expand_dims(observation, 0)
        reward = np.expand_dims(reward, 0)
        done = np.expand_dims(done, 0)

    return observation, reward, done
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;models&#34;&gt;Models&lt;/h2&gt;
&lt;p&gt;Next, let&amp;rsquo;s implement the model. We will use the architecture from the &amp;ldquo;Human-level control through deep reinforcement learning.&amp;rdquo; paper which has three convolutional layers followed by a single dense layer. We then pipe this output to the &amp;ldquo;actor&amp;rdquo; layer (which outputs the logits corresponding to probabilities of actions) and &amp;ldquo;critic&amp;rdquo; layer (which estimates the value function.)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ActorCriticCnn(nn.Module):
    n_actions: int
    n_hidden: int

    def setup(self):
        self.conv1 = nn.Conv(features=32, kernel_size=(8, 8), strides=(4, 4))
        self.conv2 = nn.Conv(features=64, kernel_size=(4, 4), strides=(2, 2))
        self.conv3 = nn.Conv(features=64, kernel_size=(3, 3), strides=(1, 1))
        self.hidden = nn.Dense(features=self.n_hidden)
        self.actor = nn.Dense(features=self.n_actions)
        self.critic = nn.Dense(1)

    def __call__(self, x):
        x = x.astype(jnp.float32) / 255.0
        # Convolutions
        x = nn.relu(self.conv1(x))
        x = nn.relu(self.conv2(x))
        x = nn.relu(self.conv3(x))
        # Dense
        x = x.reshape((x.shape[0], -1))
        x = nn.relu(self.hidden(x))
        # Actor-Critic
        logits = self.actor(x)
        value = self.critic(x)
        return logits, value
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For non-image based observations, we include a simple MLP model (we will use this to verify the algorithm with CartPole.)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ActorCriticMlp(nn.Module):

    n_hidden: int
    n_actions: int

    def setup(self):
        self.common = nn.Dense(features=self.n_hidden)
        self.actor = nn.Dense(features=self.n_actions)
        self.critic = nn.Dense(1)

    def __call__(self, x):
        x = nn.relu(self.common(x))
        logits = self.actor(x)
        value = self.critic(x)
        return logits, value
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will also make a couple functions to jit the calling of the model and another for converting the output of the model to a tuple with the action, value and log probability.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@functools.partial(jax.jit, static_argnums=0)
def apply_model(
    apply_fn: Callable[..., Any],
    params: flax.core.FrozenDict,
    observation: Union[jnp.ndarray, np.ndarray],
) -&amp;gt; Tuple[jnp.ndarray, jnp.ndarray]:
    return apply_fn(params, observation)


@jax.jit
@jax.vmap
def select_log_prob(action, log_probs):
    &amp;quot;&amp;quot;&amp;quot;Vectorized function to select log-probabilities from vector of actions.&amp;quot;&amp;quot;&amp;quot;
    return log_probs[action]


@functools.partial(jax.jit, static_argnums=0)
def action_value_logprob(
    apply_fn: Callable[..., Any],
    params: flax.core.FrozenDict,
    key,
    observation: Union[jnp.ndarray, np.ndarray],
):
    logits, value = apply_fn(params, observation)

    # Sample from the actor distribution to get actions
    action = jax.random.categorical(key, logits)
    # Get log-probabilities
    log_probs = jax.nn.log_softmax(logits)
    # Get log-probability corresponding to action
    log_prob = select_log_prob(action, log_probs)
    # Squeeze value to remove extra dimension
    return action, jnp.squeeze(value), log_prob
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ppo-algorithm&#34;&gt;PPO Algorithm&lt;/h2&gt;
&lt;h3 id=&#34;configuration&#34;&gt;Configuration&lt;/h3&gt;
&lt;p&gt;Now we will implement the proximal-policy-optimization algorithm. Recall that this algorithm has a few parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;horizon&lt;/code&gt;: Number of time steps in the trajectory,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gamma&lt;/code&gt; ($\gamma$): Discount of future rewards,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lam&lt;/code&gt; ($\lambda$): General Advantage Estimation (GAE) parameter,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c1&lt;/code&gt; ($c_{1}$): Prefactor of value-function loss,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c2&lt;/code&gt; ($c_{2}$): Prefactor of entropy loss&lt;/li&gt;
&lt;li&gt;&lt;code&gt;epsilon&lt;/code&gt; ($\epsilon$): Clipping parameter for actor loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to these parameters, we have addition hyperparameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;epochs&lt;/code&gt;: Number of epochs to train for each trajectory,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mini_batch_size&lt;/code&gt;: Number of trajectory points to train at a time,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_actors&lt;/code&gt;: Number of environments to run at once,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;total_frames&lt;/code&gt;: Number of frames to train agent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will group these parameters into a &lt;code&gt;NamedTuple&lt;/code&gt; for convenience:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class PPOConfig(NamedTuple):
    horizon: int = 2048
    epochs: int = 10
    mini_batch_size: int = 64
    gamma: float = 0.99
    lam: float = 0.95
    n_actors: int = 1
    epsilon: Union[float, optax.Schedule] = 0.1
    c1: float = 0.5
    c2: float = 0.01
    total_frames: int = int(1e6)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;trajectory-creation&#34;&gt;Trajectory Creation&lt;/h3&gt;
&lt;p&gt;We will also make a &lt;code&gt;NamedTuple&lt;/code&gt; for the components of the trajectory needed for training. These components are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;observations&lt;/code&gt;: Collect observations along trajectory,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log_probs&lt;/code&gt;: Model log-probabilities,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;actions&lt;/code&gt;: Actions the model took,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;returns&lt;/code&gt;: Returns at each time step,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;advantages&lt;/code&gt;: Computed advantages from GAE.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Trajectory(NamedTuple):
    observations: jnp.ndarray
    log_probs: jnp.ndarray
    actions: jnp.ndarray
    returns: jnp.ndarray
    advantages: jnp.ndarray
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we will write a function to compute the advantages and returns from the
rewards and values. There is one tricky part to this. What do we do if one of
our environments reaches a terminal state (game-over)? We want to use this
trajectory despite reaching a terminal state. What we will do is perform a reset
on the accumulated rewards when we reach a terminal observation, the continue
accumulating after the terminated state. Our &lt;code&gt;generalized_advantage_estimation&lt;/code&gt;
function will compute the following:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align*}
\hat{A}_{t} &amp;= \delta_{t} + (\gamma\lambda)\delta_{t+1} + \cdots + (\gamma\lambda)^{N}\delta_{t+N}\\
\delta_{t} &amp;= r_{t} + \gamma V(s_{t+1}) - V(s_{t})
\end{align*}
$$
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@jax.jit
@functools.partial(jax.vmap, in_axes=(1, 1, 1, None, None), out_axes=1)
def generalized_advantage_estimation(
    rewards: np.ndarray,
    values: np.ndarray,
    terminals: np.ndarray,
    gamma: float,
    lam: float,
) -&amp;gt; Tuple[jnp.ndarray, jnp.ndarray]:
    assert (
        rewards.shape[0] == values.shape[0] - 1
    ), &amp;quot;Values must have one more element than rewards.&amp;quot;
    assert (
        rewards.shape[0] == terminals.shape[0]
    ), &amp;quot;Rewards and terminals must have same shape.&amp;quot;

    advantages = []
    advantage = 0.0

    for t in reversed(range(len(rewards))):
        # Eqn.(11) and (12) from ArXiv:1707.06347. Note, multiplying by `terminals` 
        # (which is zero when done=True) will cause the advantage to reset.
        delta = rewards[t] + (gamma * values[t + 1] * terminals[t]) - values[t]
        advantage = delta + (gamma * lam * advantage * terminals[t])
        advantages.append(advantage)

    advantages = jnp.array(advantages[::-1])
    # Note return is just the advantage + values
    returns = advantages + jnp.array(values[:-1])
    return returns, advantages
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will write a function to construct the trajectory. This simply consists
of running the environment a specified number of steps and accumulating the
needed results. This function will also call our
&lt;code&gt;generalized_advantage_estimation&lt;/code&gt; function to compute the returns and
advantages.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def create_trajectory(
    initial_observation: jnp.ndarray,
    apply_fn: Callable[..., Any],
    params: flax.core.FrozenDict,
    env: Union[GymEnv, GymVecEnv],
    key,
    horizon: int,
    gamma: float,
    lam: float,
):
    observation = initial_observation

    # Collected quantities
    traj_observations = []
    traj_log_probs = []
    traj_values = []
    traj_rewards = []
    traj_actions = []
    traj_dones = []

    for _ in range(horizon):
        key, rng = jax.random.split(key, 2)
        action, value, log_prob = action_value_logprob(
            apply_fn, params, rng, observation
        )

        traj_actions.append(action)
        traj_values.append(np.array(value))
        traj_observations.append(observation)
        traj_log_probs.append(log_prob)

        observation, reward, done = env_step(action, env)

        traj_rewards.append(reward)
        traj_dones.append(done)

    _, next_value = apply_model(apply_fn, params, observation)
    traj_values.append(np.squeeze(np.array(next_value)))

    traj_rewards = np.array(traj_rewards)
    traj_values = np.array(traj_values)
    traj_terminals = 1 - np.array(traj_dones)

    traj_returns, traj_advantages = generalized_advantage_estimation(
        traj_rewards, traj_values, traj_terminals, gamma, lam
    )

    trajectory = Trajectory(
        observations=jnp.array(traj_observations),
        log_probs=jnp.array(traj_log_probs),
        actions=jnp.array(traj_actions),
        returns=traj_returns,
        advantages=traj_advantages,
    )

    # Return observation as well so we can continue where we left off.
    return trajectory, observation
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another useful function to write is one the takes the trajectory created from &lt;code&gt;create_trajectory&lt;/code&gt; (which as a shape of &lt;code&gt;(horizon, ...)&lt;/code&gt;), shuffle the batch dimension, and reshape to &lt;code&gt;(n, mini_batch_size,...)&lt;/code&gt; (with &lt;code&gt;n * mini_batch_size = horizon&lt;/code&gt;) so we can easily iterator over mini batches.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@functools.partial(jax.jit, static_argnums=(2, 3))
def trajectory_reshape(
    trajectory: Trajectory, key, batch_size: int, mini_batch_size: int
):
    permutation = jax.random.permutation(key, batch_size)
    # Flatten and permute
    trajectory = tree_map(
        lambda x: x.reshape((batch_size,) + x.shape[2:])[permutation], trajectory
    )
    # change shape of trajectory elements to (iterations, minibatch_size)
    iterations = batch_size // mini_batch_size
    trajectory = tree_map(
        lambda x: x.reshape((iterations, mini_batch_size) + x.shape[1:]), trajectory
    )
    return trajectory
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loss&#34;&gt;Loss&lt;/h3&gt;
&lt;p&gt;Now we need to implement the loss function. Recall that the loss function for the &lt;code&gt;PPO&lt;/code&gt; algorithm is:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align*}
    L &amp;= L^{\mathrm{CLIP}} + c_{1}L^{\mathrm{VF}} + c_{2}L^{\mathrm{entropy}}\\
\end{align*}
$$
&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align*}
    L^{\mathrm{CLIP}} &amp;= -\mathrm{min}(r_{\theta}\hat{A}, \mathrm{clip}(r_{\theta},1-\epsilon,1+\epsilon)\hat{A})\\
    L^{\mathrm{VF}} &amp;= (V_{\theta} - V^{\mathrm{target}})^2\\
    L^{\mathrm{entropy}} &amp;= -S[\pi_{\theta}]
\end{align*}
$$
&lt;/p&gt;
&lt;p&gt;In these expression $r_{\theta} = \pi_{\theta} / \pi_{\theta_{\mathrm{old}}}$, $V$ is the return and $A$ is the advantage. To compute the loss, we need all them elements of the trajectory. We use the values of the trajectory to compute the new action probabilities.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@functools.partial(jax.jit, static_argnums=1)
def loss_fn(
    params: flax.core.FrozenDict,
    apply_fn: Callable[..., Any],
    batch: Tuple,
    epsilon: float,
    c1: float,
    c2: float,
):

    observations, old_log_p, actions, returns, advantages = batch

    logits, values = apply_fn(params, observations)
    values = jnp.squeeze(values)
    log_probs = jax.nn.log_softmax(logits)
    log_p = select_log_prob(actions, log_probs)

    # Normalize the advantages to give the network to make them easier
    # for the network to estimate.
    advantages = (advantages - jnp.mean(advantages)) / (jnp.std(advantages) + 1e-8)

    # Compute actor loss using conservative policy iteration with an
    # additional clipped surrogate and take minimum between the two.
    # See Eqn.(7) of ArXiv:1707.06347
    prob_ratio = jnp.exp(log_p - old_log_p)
    surrogate1 = advantages * prob_ratio
    surrogate2 = advantages * jnp.clip(prob_ratio, 1.0 - epsilon, 1.0 + epsilon)
    actor_loss = -jnp.mean(jnp.minimum(surrogate1, surrogate2), axis=0)

    # Use mean-squared error loss for value function
    critic_loss = c1 * jnp.mean(jnp.square(returns - values), axis=0)
    # Entropy bonus to ensure exploration
    entropy_loss = -c2 * jnp.mean(jnp.sum(-jnp.exp(log_probs) * log_probs, axis=1))

    loss = actor_loss + critic_loss + entropy_loss

    return loss, (actor_loss, critic_loss, entropy_loss)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;training&#34;&gt;Training&lt;/h3&gt;
&lt;p&gt;Now we implement the training. In order to make things more compact, we will write a jax-compatible class to store the model parameters and configuration. We adapt the &lt;code&gt;flax.training.TrainState&lt;/code&gt; for our purposes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class PPOTrainState(struct.PyTreeNode):
    &amp;quot;&amp;quot;&amp;quot;Jax-compatible class holding train-state for the Proximal-Policy-Optimization algorithm.

    Parameters
    ----------
    step : int
        Current training step.
    apply_fn : Callable
        Function to compute forward pass through model.
    params : flax.core.FrozenDict
        Model parameters
    lr: Union[float, optax.Schedule]
        Learning rate of the model.
    tx: optax.GradientTransformation
        Training optimizer.
    opt_state: optax.OptState
        State of the optimizer.
    config: PPOConfig
        Configuration of the PPO algorithm.
    &amp;quot;&amp;quot;&amp;quot;

    step: int
    apply_fn: Callable = struct.field(pytree_node=False)
    params: flax.core.FrozenDict

    tx: optax.GradientTransformation = struct.field(pytree_node=False)
    opt_state: optax.OptState

    config: PPOConfig = struct.field(pytree_node=False)

    def apply_gradients(self, *, grads, **kwargs):
        &amp;quot;&amp;quot;&amp;quot;Return the new train state after applying gradients.

        Parameters
        ----------
        grads:
            Gradients returns by loss function.

        Returns
        -------
        new_state: PPOTrainState
            The new train state.
        &amp;quot;&amp;quot;&amp;quot;
        updates, opt_state = self.tx.update(grads, self.opt_state, self.params)
        params = optax.apply_updates(self.params, updates)

        return self.replace(
            step=self.step + 1,
            params=params,
            opt_state=opt_state,
            **kwargs,
        )

    def batch_size(self) -&amp;gt; int:
        &amp;quot;&amp;quot;&amp;quot;Compute the batch size.&amp;quot;&amp;quot;&amp;quot;
        return self.config.horizon * self.config.n_actors

    def epsilon(self) -&amp;gt; chex.Numeric:
        &amp;quot;&amp;quot;&amp;quot;The current clipping parameter.&amp;quot;&amp;quot;&amp;quot;
        if isinstance(self.config.epsilon, Callable):
            return self.config.epsilon(self.step)
        return self.config.epsilon

    def learning_rate(self) -&amp;gt; chex.Numeric:
        return self.opt_state.hyperparams[&amp;quot;learning_rate&amp;quot;]  # type:ignore

    @classmethod
    def create(
        cls,
        *,
        apply_fn: Callable,
        params: flax.core.FrozenDict,
        lr: Union[float, optax.Schedule],
        config: PPOConfig,
        max_grad_norm: Optional[float] = None,
    ):
        @optax.inject_hyperparams
        def make_optimizer(learning_rate):
            tx_comps = []
            if max_grad_norm is not None:
                tx_comps.append(optax.clip_by_global_norm(max_grad_norm))
            tx_comps.append(optax.adam(learning_rate))
            return optax.chain(*tx_comps)

        tx = make_optimizer(lr)
        opt_state = tx.init(params)

        return cls(
            step=0,
            apply_fn=apply_fn,
            params=params,
            tx=tx,
            opt_state=opt_state,
            config=config,
        )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we allow for a time-varying clipping parameter. Next, we implement a function to optimize the model. This function will compute the loss and gradients, apply the gradients and return the new state as well as the losses for logging.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@functools.partial(jax.jit, static_argnums=2)
def optimize(state: PPOTrainState, traj: Tuple):
    &amp;quot;&amp;quot;&amp;quot;Perform a backwards pass on model, update and return new state and losses.&amp;quot;&amp;quot;&amp;quot;
    epsilon = state.epsilon()
    c1 = state.config.c1
    c2 = state.config.c2

    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)
    (loss, (aloss, closs, eloss)), grads = grad_fn(
        state.params, state.apply_fn, traj, epsilon, c1, c2
    )
    state = state.apply_gradients(grads=grads)  # type: ignore

    return state, loss, aloss, closs, eloss
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we write a function to perform a training step. This function takes in the state and trajectory, reshapes the trajectory to be of shape &lt;code&gt;(n, mini_batch_size,...)&lt;/code&gt; and then loops over each mini-batch (iterates over leading dimension), optimizing the model each loop iteration. We then repeat this process a specified number of times (&lt;code&gt;epochs&lt;/code&gt; parameter). Finally, the new state and average losses are returned.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def train_step(state: PPOTrainState, trajectory: Trajectory, key):
    losses = {
        &amp;quot;total&amp;quot;: [],
        &amp;quot;actor&amp;quot;: [],
        &amp;quot;critic&amp;quot;: [],
        &amp;quot;entropy&amp;quot;: [],
    }

    batch_size = state.batch_size()
    mini_batch_size = state.config.mini_batch_size

    for _ in range(state.config.epochs):
        key, rng = jax.random.split(key, 2)
        traj_reshaped = trajectory_reshape(trajectory, rng, batch_size, mini_batch_size)
        for traj in zip(*traj_reshaped):
            state, *t_losses = optimize(state, traj)

            losses[&amp;quot;total&amp;quot;] += t_losses[0]
            losses[&amp;quot;actor&amp;quot;] += t_losses[1]
            losses[&amp;quot;critic&amp;quot;] += t_losses[2]
            losses[&amp;quot;entropy&amp;quot;] += t_losses[3]

    losses = {key: val for key, val in zip(losses.keys(), map(np.average, losses.values()))}
    return state, losses

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It will be useful to have a function that estimates the performance of the model. To estimate the performance, we will run the model over a number of episodes and return the average of the accumulated reward:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def evaluate_model(
    state: PPOTrainState, env: GymEnv, episodes: int, key, expand_dims=True
):
    &amp;quot;&amp;quot;&amp;quot;Estimate model performance by running model over a number of episodes and return the average accumulated reward.

    Parameters
    ----------
    state : PPOTrainState
        Current train state.
    env : GymEnv
        Environment to run model though.
    episodes : int
        Number of episodes to run model for.
    key : _type_
        key for random number generation.
    expand_dims : bool, optional
        If True, the observation is given a batch dimension. Default is True.

    Returns
    -------
    reward: float
       Average reward. 
    &amp;quot;&amp;quot;&amp;quot;
    episode_rewards = []
    for _ in range(episodes):
        episode_reward = 0
        observation = env.reset()
        done = False
        while not done:
            if expand_dims:
                observation = jnp.expand_dims(observation, 0)
            logits, _ = apply_model(state.apply_fn, state.params, observation)
            key, rng = jax.random.split(key, 2)
            action = jax.random.categorical(rng, logits)
            if expand_dims:
                observation, reward, done, _ = env.step(int(action[0]))
            else:
                observation, reward, done, _ = env.step(int(action))
            episode_reward += reward
        episode_rewards.append(episode_reward)

    return np.average(episode_rewards)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;testing-with-cartpole&#34;&gt;Testing with &lt;code&gt;CartPole&lt;/code&gt;&lt;/h2&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A notebook with the code is available &lt;a href=&#34;https://github.com/LoganAMorrison/flapjax/blob/main/cartpole.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;training-1&#34;&gt;Training&lt;/h3&gt;
&lt;p&gt;Before going for flappy bird, we will start with a much more simile problem: &lt;code&gt;CartPole&lt;/code&gt;. This environment can return non-image observations of the system, which are much easier to learn from. We will use our MLP model to implement our agent. First, let&amp;rsquo;s set up out environment. We will use &lt;code&gt;gym&lt;/code&gt;&amp;rsquo;s async vector environment.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_actors = 8
train_env = gym.vector.make(&amp;quot;CartPole-v1&amp;quot;, asynchronous=True, num_envs=n_actors)
eval_env = gym.make(&amp;quot;CartPole-v1&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s set our configuration parameters. We will use stable-baselines3&amp;rsquo;s RL-zoo hyperparameters &lt;a href=&#34;https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hyperparameters&lt;/a&gt; which have been tuned.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def ppo_num_opt_steps(
    total_frames: int, horizon: int, n_actors: int, epochs: int, mini_batch_size: int
) -&amp;gt; int:
    &amp;quot;&amp;quot;&amp;quot;Compute the number of optimization steps.&amp;quot;&amp;quot;&amp;quot;
    batch_size = horizon * n_actors
    # Number of frames we see per train step
    frames_per_train_step = batch_size
    # Number of times we call optimizer per step
    opt_steps_per_train_step = epochs * (batch_size // mini_batch_size)
    # Number of train steps
    num_train_steps = total_frames // frames_per_train_step
    # Total number of optimizer calls
    total_opt_steps = opt_steps_per_train_step * num_train_steps

    return total_opt_steps


horizon = 32
epochs = 20
mini_batch_size = 256
total_frames = int(1e5)
total_opt_steps = ppo_num_opt_steps(
    total_frames, horizon, n_actors, epochs, mini_batch_size
)

config = PPOConfig(
    horizon=horizon,
    epochs=epochs,
    mini_batch_size=mini_batch_size,
    gamma=0.98,
    lam=0.8,
    c1=1.0,
    c2=0.0,
    total_frames=total_frames,
    epsilon=optax.linear_schedule(0.2, 0.0, total_opt_steps),
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we create our train state. Note we will use a linearly decaying learning rate.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create Model
key = jax.random.PRNGKey(1234)
n_hidden = 512
n_actions = train_env.action_space[0].n  # type: ignore
model = ActorCriticMlp(n_hidden=n_hidden, n_actions=n_actions)

# Optimizer parameters
learning_rate = optax.linear_schedule(0.001, 0.0, total_opt_steps)
max_grad_norm = 0.5

# Initialize training state
observation = env_reset(train_env)
key, rng = jax.random.split(key, 2)
params = model.init(rng, observation)
state = PPOTrainState.create(
    apply_fn=model.apply,
    params=params,
    lr=learning_rate,
    config=config,
    max_grad_norm=max_grad_norm,
)
del params
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we configure our logging and checkpoint directories as well as some parameters for specifying the frequencies:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;checkpoint_dir = pathlib.Path(&amp;quot;.&amp;quot;).absolute().joinpath(&amp;quot;checkpoints/cartpole/run1&amp;quot;).as_posix()
log_dir = pathlib.Path(&amp;quot;.&amp;quot;).absolute().joinpath(&amp;quot;logs/cartpole/run1&amp;quot;).as_posix()

summary_writer = tensorboard.SummaryWriter(log_dir)
summary_writer.hparams(config._asdict())

batch_size = config.horizon * config.n_actors
frames_per_train_step = batch_size
num_train_steps = config.total_frames // frames_per_train_step

reward = 0.0

horizon = state.config.horizon
gamma = state.config.gamma
lam = state.config.lam

log_frequency = 1
eval_frequency = 1
eval_episodes = 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;start_step = 0
with tqdm(range(start_step, num_train_steps)) as t:
    for step in t:
        frame = step * frames_per_train_step
        t.set_description(f&amp;quot;frame: {step}&amp;quot;)

        key, rng1, rng2 = jax.random.split(key, 3)
        trajectory, observation = create_trajectory(
            observation,
            state.apply_fn,
            state.params,
            train_env,
            rng1,
            horizon,
            gamma,
            lam,
        )
        state, losses = train_step(state, trajectory, rng2)

        if step % log_frequency == 0:
            summary_writer.scalar(&amp;quot;train/loss&amp;quot;, losses[&amp;quot;total&amp;quot;], frame)
            summary_writer.scalar(&amp;quot;train/loss-actor&amp;quot;, losses[&amp;quot;actor&amp;quot;], frame)
            summary_writer.scalar(&amp;quot;train/loss-critic&amp;quot;, losses[&amp;quot;critic&amp;quot;], frame)
            summary_writer.scalar(&amp;quot;train/loss-entropy&amp;quot;, losses[&amp;quot;entropy&amp;quot;], frame)
            summary_writer.scalar(
                &amp;quot;train/learning-rate&amp;quot;, state.learning_rate(), frame
            )
            summary_writer.scalar(&amp;quot;train/clipping&amp;quot;, state.epsilon(), frame)

        if step % 25 == 0:
            key, rng = jax.random.split(key, 2)
            reward = evaluate_model(state, eval_env, eval_episodes, rng)
            summary_writer.scalar(&amp;quot;train/reward&amp;quot;, reward, frame)

        t.set_description_str(f&amp;quot;loss: {losses[&#39;total&#39;]}, reward: {reward}&amp;quot;)

        if checkpoint_dir is not None:
            checkpoints.save_checkpoint(checkpoint_dir, state, frame)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;Here are the results from training the MLP on the CartPole environment. The
network was trained for about 1 hr. Below is an image of the training results.
Not that the maximum reward for this environment is 500. We reached this at the
very end. The training wasn&amp;rsquo;t complete, but since this is for example purposes,
these results are sufficient.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;800&#34; height=&#34;450&#34; src=&#34;../images/cartpole/stats.png&#34;&gt;
&lt;/p&gt;
&lt;p&gt;Here is gif of the agent surviving all 500 steps.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;500&#34; height=&#34;500&#34; src=&#34;../images/cartpole/cartpole.gif&#34;&gt;
&lt;/p&gt;
&lt;p&gt;We thus conclude that we are on the right track! Next, let&amp;rsquo;s try the flappy bird environment.&lt;/p&gt;
&lt;h2 id=&#34;training-flappy-bird&#34;&gt;Training Flappy Bird&lt;/h2&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A notebook with the code is available &lt;a href=&#34;https://github.com/LoganAMorrison/flapjax/blob/main/flappybird.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;training-2&#34;&gt;Training&lt;/h3&gt;
&lt;p&gt;We are now ready to train an agent to play flappy bird. As in the &lt;code&gt;CartPole&lt;/code&gt; example, we first set up our environments.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Initialize environments
def make_env():
    env = FlappyBirdEnvV0()
    env = ResizeObservation(env, (84, 84))
    env = GrayScaleObservation(env, keep_dim=True)
    env = FrameSkip(env)

    return env
    
train_env = gym.vector.SyncVectorEnv([make_env for _ in range(config.n_actors)])
eval_env = make_env()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we setup our config:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;total_frames=int(1e7)
n_actors=8
horizon=128
mini_batch_size=256
epochs=4
total_opt_steps = ppo_num_opt_steps(
    total_frames, horizon, n_actors, epochs, mini_batch_size
)

gamma=0.99
lam=0.95
epsilon=optax.linear_schedule(0.1, 0.0, total_opt_steps)
c1=0.5
c2=0.01
learning_rate=optax.linear_schedule(2.5e-4, 0.0, total_opt_steps)
max_grad_norm=0.5

# Configuration
config = PPOConfig(
    n_actors=n_actors,
    total_frames=total_frames,
    horizon=horizon,
    mini_batch_size=mini_batch_size,
    lam=lam,
    gamma=gamma,
    epochs=epochs,
    c1=c1,
    c2=c2,
    epsilon=epsilon,
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we initialize the training state:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create Model
key = jax.random.PRNGKey(0)
n_hidden = 256
n_actions = train_env.action_space[0].n  # type: ignore
model = ActorCriticCnn(n_hidden=n_hidden, n_actions=n_actions)

# Initialize model
observation = env_reset(train_env)
key, rng = jax.random.split(key, 2)
params = model.init(rng, observation)
state = PPOTrainState.create(
    apply_fn=model.apply,
    params=params,
    lr=learning_rate,
    config=config,
    max_grad_norm=max_grad_norm,
)
del params
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set up logging and logging parameters:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;checkpoint_dir = pathlib.Path(&amp;quot;.&amp;quot;).absolute().joinpath(&amp;quot;checkpoints/flappy_bird/run1&amp;quot;).as_posix()
log_dir = pathlib.Path(&amp;quot;.&amp;quot;).absolute().joinpath(&amp;quot;logs/flappy_bird/run1&amp;quot;).as_posix()

summary_writer = tensorboard.SummaryWriter(log_dir)
summary_writer.hparams(config._asdict())

log_frequency = 1
eval_frequency = 1
eval_episodes = 25

batch_size = config.horizon * config.n_actors
frames_per_train_step = batch_size
num_train_steps = config.total_frames // frames_per_train_step

reward = 0.0

horizon = state.config.horizon
gamma = state.config.gamma
lam = state.config.lam
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And train! (this will take a VERY long time&amp;hellip;)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;start_step = 0
with tqdm(range(start_step, num_train_steps)) as t:
    for step in t:
        frame = step * frames_per_train_step
        t.set_description(f&amp;quot;frame: {step}&amp;quot;)

        key, rng1, rng2 = jax.random.split(key, 3)
        trajectory, observation = create_trajectory(
            observation,
            state.apply_fn,
            state.params,
            train_env,
            rng1,
            horizon,
            gamma,
            lam,
        )
        state, losses = train_step(state, trajectory, rng2)

        if step % log_frequency == 0:
            summary_writer.scalar(&amp;quot;train/loss&amp;quot;, losses[&amp;quot;total&amp;quot;], frame)
            summary_writer.scalar(&amp;quot;train/loss-actor&amp;quot;, losses[&amp;quot;actor&amp;quot;], frame)
            summary_writer.scalar(&amp;quot;train/loss-critic&amp;quot;, losses[&amp;quot;critic&amp;quot;], frame)
            summary_writer.scalar(&amp;quot;train/loss-entropy&amp;quot;, losses[&amp;quot;entropy&amp;quot;], frame)
            summary_writer.scalar(
                &amp;quot;train/learning-rate&amp;quot;, state.learning_rate(), frame
            )
            summary_writer.scalar(&amp;quot;train/clipping&amp;quot;, state.epsilon(), frame)

        if step % 25 == 0:
            key, rng = jax.random.split(key, 2)
            reward = evaluate_model(state, eval_env, eval_episodes, rng)
            summary_writer.scalar(&amp;quot;train/reward&amp;quot;, reward, frame)

        t.set_description_str(f&amp;quot;loss: {losses[&#39;total&#39;]}, reward: {reward}&amp;quot;)

        if checkpoint_dir is not None:
            checkpoints.save_checkpoint(checkpoint_dir, state, frame)

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;results-1&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;Here are the results after training for about 1 day and 18 hrs. After about 1M
steps, I had changed the evaluation frequency for once every step to once every
25 steps since the training had slowed to a snail&amp;rsquo;s pace (this is why things
slightly smooth out in the rewards at 1M steps.)&lt;/p&gt;
&lt;p&gt;Clearly the training is not finished (I stopped because I don&amp;rsquo;t want to train
for a week!) However, we can see the agent definitely learned. The maximum
average reward was about 50.&lt;/p&gt;
&lt;p&gt;Additionally, I did no hyperparameter optimization. So there is definitely room
for improvement. Hyperparameter optimization would just take way too long on my
single 6GB 2060.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;600&#34; height=&#34;450&#34; src=&#34;../images/flappy_bird_stats.png&#34;&gt;
&lt;/p&gt;
&lt;p&gt;Here is a gif of the agent flying through the environment. Keep in mind that we
are skipping 4 frames at a time so things looks a bit choppy.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;500&#34; height=&#34;500&#34; src=&#34;../images/flappy_bird_quarter.gif&#34;&gt;
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Using jax to integrate N-body phase space</title>
      <link>https://loganamorrison.github.io/post/jax-phase-space/</link>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/jax-phase-space/</guid>
      <description>&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-algorithm-rambo&#34;&gt;The algorithm: RAMBO&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#1-generate-qmu_i&#34;&gt;(1) Generate $q^{\mu}_{i}$&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#2-boost-generate-pmu_i&#34;&gt;(2) Boost: generate $p^{\mu}_{i}$&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#3-correct-the-masses-generate-kmu_i&#34;&gt;(3) Correct the masses: generate $k^{\mu}_{i}$&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#4-computing-the-weight&#34;&gt;(4) Computing the weight&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-jax-implementation&#34;&gt;The Jax implementation&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#example-muon-decay-mupm-to-epm--nu_mu--nu_e&#34;&gt;Example: Muon decay $\mu^{\pm} \to e^{\pm} + \nu_{\mu} + \nu_{e}$&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In phenomenological studies of quantum field theory, we often need to compute
cross-sections or decay widths. These computations require the evaluation of an
integral over phase space. For example, for a process with an initial state of
momentum $P$ and transitioning into $N$ final state particles with momenta
$p_{1},\dots,p_{N}$, the phase space integral is given by the following
expression.&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \mathrm{LIPS} &amp;= \qty(\prod_{i=1}^{N}\int\frac{\dd[3]{\boldsymbol{p}_{i}}}{(2\pi)^{3}2E_{i}})\qty(2\pi)^{4}\delta^{4}
    \qty(P-\sum_{i=1}^{N}p_{i})\abs{\mathcal{M}}^{2}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;In this expression, $E_{i}$ is the energy of the $i^{\mathrm{th}}$ final state
particle, and $\mathcal{M}$ the matrix element for the process. When the process
includes more than two or three particles in the final state, computing the
cross-section or width becomes difficult. In these cases, we often need to
resort to numerical integration. However, standard quadrature techniques are
often much too slow. The standard approach is to use Monte Carlo integration
(often with importance sampling, stratified sampling, or other techniques.) For
these integrations to be reasonably fast, the implementer must write the code in
a compiled (or just-in-time compiled) language.&lt;/p&gt;
&lt;p&gt;This post will investigate how well the Jax library performs this integration.
Furthermore, we will compare the Jax implementation to an equivalent NumPy
implementation and a multi-threaded &lt;code&gt;c++&lt;/code&gt; implementation. This post is organized
as follows. First, we introduce the algorithm used to perform the integration.
We then present the Jax implementation of the algorithm and demonstrate it with
a simple example. Lastly, we show some simple benchmarks between Jax, NumPy, and
C++.&lt;/p&gt;
&lt;h2 id=&#34;the-algorithm-rambo&#34;&gt;The algorithm: RAMBO&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;RAMBO&lt;/code&gt; algorithm is rather simple. At a high-level, the algorithm is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generate $N$ massless, isotropic momenta $q_{i}$ with energy components distributed according to $q^{0}_{i} \exp(-q^{0}_{i})$.&lt;/li&gt;
&lt;li&gt;Lorentz boost the $q_{i}$, producing new massless momenta $p_{i}$ which conserve momenta and have the correct center-of-mass energy.&lt;/li&gt;
&lt;li&gt;Rescale the $p_{i}$, producing new momenta $k_{i}$ which have correct masses.&lt;/li&gt;
&lt;li&gt;Compute the weight of the phase-space point.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In our first step, we enforce the energies to be distributed according to
$q^{0}_{i} \exp(-q^{0}_{i})$ simply because it results in a simple measure,
making the calculation of the phase space density easy. Steps two and three are
done in such a way that the calculation of the phase space density in the final
step is straight forward.&lt;/p&gt;
&lt;p&gt;Without much explanation, we will give the detailed algorithm.&lt;/p&gt;
&lt;h3 id=&#34;1-generate-qmu_i&#34;&gt;(1) Generate $q^{\mu}_{i}$&lt;/h3&gt;
&lt;p&gt;To generate the $q_{i}$, choose $4N$ random numbers:
$\rho^{(1)}_{i}, \rho^{(2)}_{i}, \rho^{(3)}_{i}, \rho^{(4)}_{i}$. The $q_{i}$&amp;rsquo;s
are then:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    q^{0}_{i} &amp;= e_{i}, &amp; 
    q^{1}_{i} &amp;= e \cos(\phi_{i}) \sqrt{1 - z_{i}^{2}}, &amp;
    q^{2}_{i} &amp;= e \sin(\phi_{i}) \sqrt{1 - z_{i}^{2}}, &amp;
    q^{3}_{i} &amp;= e \cos(\theta_{i}).\\
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;with $e$, $z_{i}$ and $\phi_{i}$ given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    e &amp;= -\log(\rho^{(3)}_{i} \rho^{(4)}_{i}), &amp;
    z_{i} &amp;= 2\rho^{(1)}_{i}-1, &amp;
    \phi &amp;= 2\pi \rho^{(2)}_{i}
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;2-boost-generate-pmu_i&#34;&gt;(2) Boost: generate $p^{\mu}_{i}$&lt;/h3&gt;
&lt;p&gt;The boosted momenta are:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    p^{0}_{i} &amp;= x \qty(\gamma q^{0}_{i} + \boldsymbol{b}\cdot\boldsymbol{q}_{i}), &amp;
    \boldsymbol{p}_{i} &amp;= x \qty(\qty(a \boldsymbol{b}\cdot\boldsymbol{q}_{i} + q_{i}^{0}) \boldsymbol{b} + \boldsymbol{q}_{i}). 
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where the various undeclared variables are:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    x &amp;= E\_{\mathrm{cme}} / M, &amp;
    \gamma &amp; = Q^{0} / M, &amp;
    a &amp;= \frac{1}{1+\gamma}, \\
    Q &amp;= \sum_{j=1}^{N}q_{i}, &amp; 
    M &amp;= \sqrt{Q\cdot Q}, &amp;
    \boldsymbol{b} &amp;= -\frac{1}{M}\mqty(Q^{1} &amp; Q^{2} &amp; Q^{3}).
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;3-correct-the-masses-generate-kmu_i&#34;&gt;(3) Correct the masses: generate $k^{\mu}_{i}$&lt;/h3&gt;
&lt;p&gt;The $k^{\mu}_{i}$ are computed using:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    k^{0}_{i} &amp;= \sqrt{\qty(\xi p^{0}_{i})^2 + m_{i}^{2}}, &amp;
    \boldsymbol{k}_{i} &amp;= \xi \boldsymbol{p}_{i}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where $\xi$ is the solution to:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    0 = E_{\mathrm{cm}} - \sum_{j=1}^{N}\sqrt{m_{j}^{2} + \qty(\xi p_{j}^{0})^{2}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;This equation can be solved using Newton or Halley iterations. Typically it converges in a few steps.&lt;/p&gt;
&lt;h3 id=&#34;4-computing-the-weight&#34;&gt;(4) Computing the weight&lt;/h3&gt;
&lt;p&gt;The weight is computed using&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    w &amp;= \frac{\qty(\frac{\pi}{2})^{N-1} \qty(E_{\mathrm{cm}})^{2N-3} \qty(2\pi)^{4-3N}}{(N-1)! (N-2)!}
    {\qty(\sum_{j=1}^{N}\frac{\abs{\boldsymbol{k}_{j}}}{E_{\mathrm{cm}}})}
    {\qty(\sum_{j=1}^{N}\frac{\abs{\boldsymbol{k}_{j}}^{2}}{k^{0}_{i}})}^{-1}
    {\qty(\prod_{j=1}^{N}\frac{\abs{\boldsymbol{k}_{j}}}{k^{0}_{i}})}
\end{align}
$$
&lt;/p&gt;
&lt;h2 id=&#34;the-jax-implementation&#34;&gt;The Jax implementation&lt;/h2&gt;
&lt;p&gt;Implementing the algorithm above using Jax is a learning experience in using
Jax. The implementation is a breeze if you&amp;rsquo;re familiar with Jax. We will write a
few functions that will make the functions we need to implement the algorithm.
Before we get into it, let&amp;rsquo;s explain the general structure of each function we
will make.&lt;/p&gt;
&lt;p&gt;Each function we will construct will work on a tensor of shape &lt;code&gt;(4, N, M)&lt;/code&gt;, where
&lt;code&gt;N&lt;/code&gt; is the number of final state particles and &lt;code&gt;M&lt;/code&gt; is the size of a batch to be
processed. If p is the tensor, then &lt;code&gt;p[0,:,:]&lt;/code&gt; holds the energies while
&lt;code&gt;p[1,:,:], p[3,:,:], p[4,:,:]&lt;/code&gt; hold the $x,y$ and $z$ component&amp;rsquo;s of the
3-momentum. The &lt;code&gt;p[:,0,:],...,p[:,N-1,:]&lt;/code&gt; are the moment for particles &lt;code&gt;1-N&lt;/code&gt;.
The last dimension contains the batch.&lt;/p&gt;
&lt;p&gt;We will need to import &lt;code&gt;jax&lt;/code&gt; and the &lt;code&gt;math&lt;/code&gt; module.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jax
import jax.numpy as jnp
import math
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate the $q^{\mu}_{i}$, we will create a function that takes in the
number of final state particles and the batch size and return the function to
compute the momenta.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_momenta_initializer(n: int, batch_size: int):
    def init(key):
        keys = jax.random.split(key, 4)
        rho1 = jax.random.uniform(keys[0], shape=(n, batch_size))
        rho2 = jax.random.uniform(keys[1], shape=(n, batch_size))
        rho3 = jax.random.uniform(keys[2], shape=(n, batch_size))
        rho4 = jax.random.uniform(keys[3], shape=(n, batch_size))

        ctheta = 2 * rho1 - 1.0
        stheta = jnp.sqrt(1.0 - ctheta ** 2)
        phi = 2.0 * jnp.pi * rho2
        e = -jnp.log(rho3 * rho4)

        return jnp.array(
            [e, e * stheta * jnp.cos(phi), e * stheta * jnp.sin(phi), e * ctheta]
        )

    return jax.jit(init)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we write a function to make the boosting function. We given the center-of-mass energy,
this is a simple translation of the expressions given above.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_momenta_boost(cme):
    def boost(ps):
        sum_ps = jnp.sum(ps, axis=1)
        inv_mass = jnp.sqrt(
            sum_ps[0] ** 2 - sum_ps[1] ** 2 - sum_ps[2] ** 2 - sum_ps[3] ** 2
        )
        inv_mass = 1.0 / inv_mass

        bx = -inv_mass * sum_ps[1]
        by = -inv_mass * sum_ps[2]
        bz = -inv_mass * sum_ps[3]

        x = cme * inv_mass
        g = sum_ps[0] * inv_mass
        a = 1.0 / (1.0 + g)

        bdotp = bx * ps[1] + by * ps[2] + bz * ps[3]
        fact = a * bdotp + ps[0]

        return jnp.array(
            [
                x * (g * ps[0] + bdotp),
                x * (fact * bx + ps[1]),
                x * (fact * by + ps[2]),
                x * (fact * bz + ps[3]),
            ]
        )

    return jax.jit(boost)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we can make the function to correct the masses, we need a function to solve
$f(\xi) = 0 = \sum\sqrt{m_{i}^{2} + \qty(\xi p_{i}^{0})^{2}} - E_{\mathrm{cm}}$.
We will solve this using Newton iterations. Note that the derivative of $f(\xi)$ is
given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{f}{\xi} = \sum_{j=1}^{N} \frac{\xi\qty(p_{j}^{0})^{2} }{\sqrt{m_{j}^{2} + \qty(\xi p_{j}^{0})^{2}}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Defining $f_{i} = \sqrt{m_{i}^{2} + \qty(\xi e_{i})^{2}}$, $e_{i} = p_{i}^{0}$, we have:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    f(\xi) &amp;= \sum_{i} f_{i} - E_{\mathrm{cm}}, &amp; \dv{f}{\xi} &amp;= \sum_{i} \frac{\xi e_{i}^{2}}{f_{i}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Recall that the Newton iteration requires us to update $\xi$ using
$\xi_{j+1} = \xi_{j}-f(\xi_{j})/f&amp;rsquo;(\xi_{j})$, starting from $\xi_{0}$. We will take
$\xi_{0}$ to be $\xi_{0} = \sqrt{1 - \qty(M/E_{\mathrm{cm}})^{2}}$ with $M = \sum_{i}m_{i}$.
Note that we can also use &lt;code&gt;jax.jvp&lt;/code&gt; to automatically perform the derivative for us. We will show
both method. For similicity, we will use a fixed number of iterations. Usually 10 is more than enough.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_correct_masses(cme, masses, iterations):
    n = len(masses)
    ms = jnp.array(masses).reshape((n, 1))
    xi0 = math.sqrt(1.0 - (sum(masses) / cme) ** 2)

    def compute_scale_factor(ps):
        shape = ps.shape[1:]
        e = ps[0]
        xi = xi0 * jnp.ones((shape[-1],))
        for _ in range(iterations):
            # Using jax.jvp:
            def func(xi_):
                return jnp.sum(jnp.hypot(e * xi_, ms), axis=0) - cme

            f, df = jax.jvp(func, (xi,), (jnp.ones_like(xi),))
            # by hand:
            # deltaf = jnp.hypot(e * xi, ms)
            # f = jnp.sum(deltaf, axis=0) - cme
            # df = jnp.sum(xi * e ** 2 / deltaf, axis=0)
            xi = xi - f / df

        return xi

    def correct_masses(ps):
        xi = compute_scale_factor(ps)
        return jnp.array(
            [
                jnp.hypot(xi * ps[0], ms),
                xi * ps[1],
                xi * ps[2],
                xi * ps[3],
            ]
        )

    return jax.jit(correct_masses)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we write our function to compute the weights.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_compute_weights(n, cme):
    pi = jnp.pi
    fact_nm2 = math.factorial(n - 2)
    fact = 1.0 / ((n - 1) * fact_nm2 ** 2)
    base_wgt = (
        fact * (0.5 * pi) ** (n - 1) * cme ** (2 * n - 4) * (0.5 / pi) ** (3 * n - 4)
    )

    def weight_rescale_factor(ps):
        modsqr = jnp.sum(ps[1:] ** 2, axis=0)
        mod = jnp.sqrt(modsqr)
        inveng = 1.0 / ps[0]

        t1 = jnp.sum(mod / cme, axis=0) ** (2 * n - 3)
        t2 = 1.0 / jnp.sum(modsqr * inveng, axis=0)
        t3 = jnp.prod(mod * inveng, axis=0)

        return t1 * t2 * t3 * cme

    def compute_weights(ps):
        return weight_rescale_factor(ps) * base_wgt

    return jax.jit(compute_weights)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we put it all together, constructing a function that takes in a key and
returns the weights and momenta.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_generator(cme, masses, iterations, batch_size):
    n = len(masses)
    init = make_momenta_initializer(n, batch_size)
    boost = make_momenta_boost(cme)
    correct_masses = make_correct_masses(cme, masses, iterations)
    compute_weights = make_compute_weights(n, cme)

    def generator(key):
        ps = init(key)
        ps = boost(ps)
        ps = correct_masses(ps)
        ws = compute_weights(ps)
        return ps, ws

    return jax.jit(generator)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;example-muon-decay-mupm-to-epm--nu_mu--nu_e&#34;&gt;Example: Muon decay $\mu^{\pm} \to e^{\pm} + \nu_{\mu} + \nu_{e}$&lt;/h3&gt;
&lt;p&gt;For an example, we will use our new code to compute the decay width for a muon
decaying into an electron and two neutrinos. The analytic expression for the
width is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \Gamma &amp;= \frac{G_{F}^{2}m_{\mu}^{5}}{192 \pi^{3}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see if we can obtain this result using our &lt;code&gt;jax&lt;/code&gt; code. The below code will
generate weights and momenta for a batch, then compute the average and standard
deviation.  After we obtain our results, we divide by $1/(2m_{\mu})$ to obtain
the width $\Gamma$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_compute_decay_width(msqrd, m, fsp_masses, batch_size):

    generator = make_generator(m, fsp_masses, 10, batch_size)

    def compute_decay_width(key):
        ps, ws = generator(key)
        ws = ws * msqrd(ps)
        avg = jnp.average(ws)
        std = jnp.std(ws) / math.sqrt(batch_size)
        return avg / (2 * m), std / (2 * m)

    return jax.jit(compute_decay_width)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last piece of the puzzle we need is a function to compute the integrand of
the decay width.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;MMU = 1.056584e-01 # Mass of the muon in GeV
GF = 1.166379e-05  # Fermi constant in GeV^-2

@jax.jit
def lnorm_sqr(p):
    &amp;quot;&amp;quot;&amp;quot;
    Compute the squared Lorenzian norm of a four-vector.
    &amp;quot;&amp;quot;&amp;quot;
    return p[0, :] ** 2 - p[1, :] ** 2 - p[2, :] ** 2 - p[3, :] ** 2

@jax.jit
def msqrd_mu_to_e_nu_nu(ps):
    &amp;quot;&amp;quot;&amp;quot;
    Compute the squared matrix element for muon decay into an electron
    and two neutrinos.
    &amp;quot;&amp;quot;&amp;quot;
    t = lnorm_sqr(ps[:, 0, :] + ps[:, 2, :])
    return 16.0 * GF**2 * t * (MMU**2 - t)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s test it out and make sure things are working correctly:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cme = MMU
masses = [0.0, 0.0, 0.0]
width = GF2 * MMU**5 / (192.0 * jnp.pi**3)

compute_decay_width_jax = make_compute_decay_width(msqrd_mu_to_e_nu_nu, cme, masses, 1 &amp;lt;&amp;lt; 19)
percent_error = abs((compute_decay_width_jax(jax.random.PRNGKey(1234)) - width) / width)
print(percent_error)
# output: DeviceArray(0.1358793, dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we do some benchmarks against &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;c++&lt;/code&gt;, let&amp;rsquo;s show the amount of time it takes
for this operation. First, the amount of time for the jit and a single evaluation is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def compile_and_eval():
    compute_decay_width = make_compute_decay_width(msqrd_mu_to_e_nu_nu, MMU, masses, 1 &amp;lt;&amp;lt; 19)
    compute_decay_width(jax.random.PRNGKey(1234))

%timeit compile_and_eval()
# output: 685 ms ± 7.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the time for a single evaluation (after jit) is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;compute_decay_width = make_compute_decay_width(msqrd_mu_to_e_nu_nu, MMU, masses, 1 &amp;lt;&amp;lt; 19)
%timeit compute_decay_width(jax.random.PRNGKey(1234))
# output: 3.01 ms ± 7.46 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s take a look at some benchmarks. We will benchmark a pure &lt;code&gt;numpy&lt;/code&gt;
version, two &lt;code&gt;jax&lt;/code&gt; versions (one on the CPU and another on the GPU), and two
&lt;code&gt;C++&lt;/code&gt; versions, a single-threaded and a multi-threaded version (compiled with
&lt;code&gt;-O3 -march=native&lt;/code&gt;). These computations are taking place on a machine with a
Ryzen 3900X 12-core, 24-thread CPU, and a GeForce 2060 6GB GPU. We use between 1
and $2^{22}$ for our &lt;code&gt;batch_size&lt;/code&gt;. We set the center-of-mass energy to $100$ and
use a 5-body final state with masses $[1,2,3,4,5]$. Additionally, we use a flat
matrix element $\mathcal{M} = 1$.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;600&#34; height=&#34;450&#34; src=&#34;./benchmarks.png&#34;&gt;
&lt;/p&gt;
&lt;p&gt;Unsurprisingly, the &lt;code&gt;C++&lt;/code&gt; versions dominate for small numbers of points ($n \lesssim 500$).
However, we begin to see the power of jax when we cross $n\sim 5000$. The GPU version seems
to be limited only by the data transfer time to the GPU up until 100,000 points, after which
we begin to see the computation cost come into play. Clearly the GPU is the winner in this
case. Interestingly, the jax CPU version is on par with the single-threaded &lt;code&gt;C++&lt;/code&gt; version,
demonstrating that jax is useful even if one doesn&amp;rsquo;t have a GPU.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Boosting your spectra</title>
      <link>https://loganamorrison.github.io/post/boosting/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/boosting/</guid>
      <description>&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#starting-from-rest-frame&#34;&gt;&lt;strong&gt;Starting from Rest Frame&lt;/strong&gt;&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#boost-integral-in-terms-of-scaleless-varibles&#34;&gt;Boost Integral in terms of Scaleless Varibles&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#examples&#34;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#dirac-delta-function-spectrum&#34;&gt;&lt;em&gt;Dirac-Delta Function Spectrum&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#muon-decay&#34;&gt;&lt;em&gt;Muon Decay&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;starting-from-rest-frame&#34;&gt;&lt;strong&gt;Starting from Rest Frame&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Suppose we know the energy spectrum \(\dv*{N_{f}}{E_{1}}\) of some product \(f\)
from the decay of a state \(I\) in the rest frame of \(I\).
From this spectum,
we would like to obtain the corresponding spectrum, \(\dv*{N_{f}}{E_{2}}\) in a
boosted frame. First, assume that the
four-momentum of \(f\) in the initial
frame is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
p^{\mu}_{1} &amp;amp; = (E_{1}; \mathbf{p}_{1})
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where \(\mathbf{p}_{1}\) is the three-momentum of \(f\). without loss of generality,
let&amp;rsquo;s assume that \(\mathbf{p}_{1}\) lies in the \(xz\)-plane:&lt;/p&gt;
&lt;p&gt;$$
\mathbf{p}_{1} = (|{\mathbf{p}_{1}}| \tilde{z}_{1}, 0, |\mathbf{p}_{1}|z_{1}),
$$&lt;/p&gt;
&lt;p&gt;with \(z_{1}\) equal to the cosine of the angle \(\mathbf{p}_{1}\) makes with the \(z\) axis and
\(\tilde{z}_{1} = \sqrt{1-z_{1}^2}\). Assume we boost along the \(z\)-axis, we can translate this four-momentum
in the new frame using \(p^{\mu}_{2} = {\Lambda}{^\mu_\nu}p^{\nu}_{1}\) with&lt;/p&gt;
&lt;p&gt;$$
{\Lambda}{^\mu_\nu} = \begin{pmatrix}
\gamma &amp;amp; 0 &amp;amp; 0 &amp;amp; \gamma\beta \\
0&amp;amp;1&amp;amp;0&amp;amp;0\\
0&amp;amp;0&amp;amp;1&amp;amp;0\\
\beta\gamma&amp;amp;0&amp;amp;0&amp;amp;\gamma
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Explicity, \(p^{\mu}_{2}\) is given by:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
p^{\mu}_{2} &amp;amp; = (E_{2}; \mathbf{p}_{2})                         \\
E_{2}       &amp;amp; = \gamma E_{1} + \beta\gamma|{\mathbf{p}_{1}}|z_{1} \\
\mathbf{p}_{2}  &amp;amp; =
(|{\mathbf{p}_{1}}|\tilde{z}_{1}, 0, \beta\gamma E_{1} + \gamma|{\mathbf{p}_{1}}|z_{1})
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Notice that \(E_{2}\) explicity depends on \(z_{1}\), which we have integrated over in obtaining \(\dv*{N_{f}}{E_{1}}\). To
reintroduce \(z_{1}\), we use:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
{\dv{N_{f}}{E_{1}}}(E_{1}) &amp;amp; = \int_{-1}^{1}\dd{z} \pdv{N_{f}}{E_{1}}{z_{1}}, &amp;amp;
\pdv{N_{f}}{E_{1}}{z_{1}}  &amp;amp; = \frac{1}{2} \dv{N_{f}}{E_{1}}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In order to translate this expression into \(\dv*{N_{f}}{E_{2}}\), we have two options. The first is to introduce a \(\delta\)-function enforcing the
correct relation between \(E_{2}\) and \(E_{1}\) and integrate over \(E_{1}\) in addition to \(z_{1}))&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
. The trick is to
first use:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
N_{f} = \int\dd{z_{1}}\dd{E_{1}}\pdv{N_{f}}{E_{1}}{z_{1}}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and insert:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
1 &amp;amp; = \int\dd{E_{2}}\delta(E_{2} - E_{2}(E_{1}, z_{1}))
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where \(E_{2}(E_{1},z_{1}) = \gamma E_{1} + \beta\gamma|{\mathbf{p}_{1}}|z_{1}\)
Inserting this factor of unity, we obtain:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
N_{f}
= \int\dd{E_{2}}\int\dd{z_{1}}\int\dd{E_{1}}\pdv{N_{f}}{E_{1}}{z_{1}} \delta(E_{2} - E_{2}(E_{1}, z_{1}))
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Differentiating with respect to \(E_{2}\), we find:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dv{N_{f}}{E_{2}}
= \int\dd{z_{1}}\int\dd{E_{1}}\pdv{N_{f}}{E_{1}}{z_{1}} \delta(E_{2} - E_{2}(E_{1}, z_{1}))
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The second method is to use one of the following (which is equivalent; see &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;)&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dd[2]{N}
= \pdv{N_{f}}{E_{1}}{z_{1}}\dd{E_{1}}\dd{z_{1}}
= \pdv{N_{f}}{E_{1}}{z_{1}} \mathcal{J} \dd{E_{2}}\dd{z_{2}}
= \pdv{N_{f}}{E_{1}}{z_{1}} \tilde{\mathcal{J}} \dd{E_{2}}\dd{z_{1}}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;with the Jacobians, \(\mathcal{J}\) or \(\tilde{\mathcal{J}}\), given by:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{J}               &amp;amp; =
\mqty| \pdv{E_{1}}{E_{2}} &amp;amp; \pdv{E_{1}}{z_{2}}             \ \pdv{z_{1}}{E_{2}} &amp;amp; \pdv{z_{1}}{z_{2}} |, &amp;amp;
\tilde{\mathcal{J}}       &amp;amp; =  \mqty| \pdv{E_{1}}{E_{2}} |
\end{align}
$$&lt;/p&gt;
&lt;p&gt;depending on if one wishes to convert \(z_{1}\) into \(z_{2}\) (since the
angular varibles will ultimately be integrated over, either choice is fine.) We
will focus on the \(\delta\)-function approach since it is easiest to deal with.&lt;/p&gt;
&lt;p&gt;In computing \(\dv*{N_{f}}{E_{2}}\), we need to perform one integration. But we
have the choice of either integration over \(E_{1}\) or \(z_{1}\). The differences
in the two will appear in the limits of integration. Suppose we integrate over
\(z_{1}\). Then, the \(\delta\)-function can be casted to&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \delta(\gamma E\_{1} + \beta\gamma|{\mathbf{p}_{1}}|z_{1} - E_{2})
     &amp; = 
    \frac{1}{\gamma\beta\abs{\mathbf{p}_{1}}}\delta(z_{1} - z^{0}_{1}), 
     &amp; 
    z^{0}_{1}
     &amp; =
    \frac{E_{2}-\gamma E_{1}}{\gamma\beta\abs{\mathbf{p}_{1}}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;As a side note, if we used the Jacobian for $ (E_{1},z_{1}) \to (E_{1},E_{2})$, which is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dd{E_{1}}\dd{z_{1}} = \mqty|\pdv{z_{1}}{E_{2}}|\dd{E_{1}}\dd{E_{2}} = 
    \frac{1}{\gamma\beta\abs{\mathbf{p}}_{1}}\dd{E_{1}}\dd{E_{2}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;then we get the same factor of $ 1/\gamma\beta\abs{\mathbf{p}_{1}}$.&lt;/p&gt;
&lt;p&gt;Since $ -1 &amp;lt; z_{1} &amp;lt; 1$, the $ \delta$-function only has support if&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    -1 &lt; \frac{E_{2}-\gamma E_{1}}{\gamma\beta\abs{\mathbf{p}_{1}}} &lt; 1
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \gamma\qty(E_{2}-\beta\sqrt{E_{2}^{2}-m_{f}^{2}}) &lt; E_{1} &lt; 
    \gamma\qty(E_{2}+\beta\sqrt{E_{2}^{2}-m_{f}^{2}})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Defining $E^{\pm}_{1} = \gamma\qty(E_{2}\pm\beta\abs{\mathbf{p}_{2}})$ with $\abs{\mathbf{p}_{2}} = \sqrt{E_{2}^{2}-m_{f}^{2}}$, we find:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\boxed{
    \dv{N_{f}}{E_{2}}
    = \frac{1}{2\gamma\beta}\int^{E^{+}_{1}}_{E^{-}_{1}} \frac{\dd{E_{1}}}{\abs{\mathbf{p}_{1}}} \dv{N_{f}}{E_{1}}
    = \frac{1}{2\gamma\beta}\int^{E^{+}_{1}}_{E^{-}_{1}} \frac{\dd{E_{1}}}{\sqrt{E_{1}^{2}-m^2_{f}}} \dv{N_{f}}{E_{1}}
    }
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Note that the bounds may be different that $E^{\pm}_{1}$, depending on $E_{2}$. The function $\dv*{N_{f}}{E_{1}}$ itself has
limits $E^{\mathrm{min}}_{1}$ and $E^{\mathrm{max}}_{1}$. Thus, the actual limits of integration are:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \mathrm{max}(E^{\mathrm{min}}_{1}, E^{-}_{1}) \leq E_{1} \leq \mathrm{min}(E^{\mathrm{max}}_{1}, E^{+}_{1})
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;boost-integral-in-terms-of-scaleless-varibles&#34;&gt;Boost Integral in terms of Scaleless Varibles&lt;/h3&gt;
&lt;p&gt;It is sometimes advantagous to deal with scaleless varibles when working with
spectra. For example, it is common to define $x_{i} \equiv 2E_{i}/Q_i$, where
$Q_i$ is the center-of-mass energy. If, in addition, we define a scaleless mass
$\mu_i = 2m_{f}/Q_i$, then we can write:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{x_{i}} &amp; = \frac{Q_{i}}{2}\dv{N_{f}}{E_{i}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;and hence:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{x_{i}} &amp; 
    = \frac{Q_{2}}{2}\frac{1}{2\gamma\beta}\int^{x^{+}_{1}}_{x^{-}_{1}} \frac{(Q_{1}/2)\dd{x_{1}}}{\sqrt{(Q_{1}^2/4)x_{1}^{2}-(Q_{1}^2/4)\mu^2_{f}}} 
    \frac{2}{Q_{1}}\dv{N_{f}}{x_{1}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Simplifying and using $ Q_{2} = \gamma Q_{1}$, we find:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\boxed{
    \dv{N_{f}}{x_{2}}  
    = \frac{1}{2\beta}\int^{x^{+}_{1}}_{x^{-}_{1}} \frac{\dd{x_{1}}}{\sqrt{x_{1}^{2}-\mu^2_{1}}} 
    \dv{N_{f}}{x_{1}}
    }
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;In this case, the integration bounds are given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    x^{-}_{1} &amp; \equiv \mathrm{max}\qty(x^{\mathrm{min}}_{1}, \gamma^{2}\qty(x_{2}-\beta\sqrt{x_{2}^2-\mu_{2}^2})) \\
    x^{+}_{1} &amp; \equiv \mathrm{min}\qty(x^{\mathrm{max}}_{1}, \gamma^{2}\qty(x_{2}+\beta\sqrt{x_{2}^2-\mu_{2}^2}))
\end{align}
$$
&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;dirac-delta-function-spectrum&#34;&gt;&lt;em&gt;Dirac-Delta Function Spectrum&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;In the case where $\dv*{N_{f}}{E_{1}} = N \delta(E_{1}-\bar{E})$, we can
exactly perform the integral in \EqnRef{eqn:boost_e}. In this case, we find&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{E_{2}}
    = \frac{1}{2\gamma\beta}\int^{E^{+}_{1}}_{E^{-}_{1}} \frac{\dd{E_{1}}}{\sqrt{E_{1}^{2}-m^2_{f}}} N \delta(E_{1} - \bar{E})
    = \frac{1}{2\gamma\beta}\frac{N}{\sqrt{\bar{E}^{2}-m^2_{f}}} 
    \begin{cases}
        1 &amp; \qq*{if} E^{+}_{1}\leq \bar{E} \leq E^{+}_{1}, \\
        0 &amp; \mathrm{otherwise}
    \end{cases}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;As an example, take $ \pi^{0} \to \gamma + \gamma$. In this case,
$ \dv*{N_{f}}{E_{1}} = 2\delta(E_{1} - m_{\pi^{0}}/2)$, and the spectrum is&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{E_{2}}
    = \frac{2}{\gamma\beta m_{\pi^{0}}}
    \begin{cases}
        1 &amp; \qq*{if} \gamma E_{2}(1-\beta)\leq m_{\pi^{0}}/2 \leq \gamma E_{2}(1+\beta), \\
        0 &amp; \mathrm{otherwise}
    \end{cases}
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;muon-decay&#34;&gt;&lt;em&gt;Muon Decay&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The muon decays via $ \mu^{\pm} \to e^{\pm} + \nu_{e} + \nu_{\mu}$. This decay
can also proceed radiatively. The result has been worked out in &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.
The result for an unpolarized muon is:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N}{x} &amp; = \frac{\alpha}{3\pi}\sum_{n=0}^{4}\qty(a_{n} + b_{n}L(y))x^{n-1}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where $ x\equiv 2E_{\gamma}/m_{\mu}$, $ L(x) \equiv \log((1-x)/r)$, $ r = (m_{e}/m_{\mu})^2$ and&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    a_0 &amp; = -\frac{17}{2},     &amp; 
    a_1 &amp; = \frac{37}{3},      &amp; 
    a_2 &amp; = -\frac{49}{4},     &amp; 
    a_3 &amp; = 13,                &amp; 
    a_4 &amp; = -\frac{55}{12}        \\
    b_0 &amp; = 3,                 &amp; 
    b_1 &amp; = -5,                &amp; 
    b_2 &amp; = 6,                 &amp; 
    b_3 &amp; = -6,                &amp; 
    b_4 &amp; = 2                 
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Note the limits on $ x$ are $ 0 \leq x \leq 1 - r$. Since the photon is
massless, \EqnRef{eqn:boost_x} takes the form:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{x_{2}} &amp; 
    = \frac{1}{2\beta}\int^{x^{+}}_{x^{-}} \frac{\dd{x_{1}}}{x_{1}}
    \dv{N_{f}}{x_{1}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    x^{-} &amp; \equiv \gamma^{2}x_{2}\qty(1 - \beta),                       &amp; 
    x^{+} &amp; \equiv \mathrm{min}\qty(1-r, \gamma^{2}x_{2}\qty(1 + \beta))
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;First, the integral of the polynomial part of $ \dv*{N}{x}$ is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \frac{1}{2\beta}\sum_{n=0}^{4}a_{n}\int^{x^{+}}_{x^{-}} \dd{x_{1}}x_{1}^{n-2}
    =
    \frac{1}{2\beta}\qty[
    a_0\frac{x^{+} - x^{-}}{x^{+}x^{-}} + 
    a_1\log(\frac{x^{+}}{x^{-}}) + \sum_{n=2}^{4}a_n \frac{  \qty(x^{+})^{n} - \qty(x^{-})^{n}  }{n}]
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;The log terms have the form:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \int^{x^{+}_{1}}_{x^{-}_{1}} \dd{x_{1}}x_{1}^{n-2} L(x_1)
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;To integrate, we use:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \int\dd{x}x^{-2}L(x) &amp; = \log(1-x) - log(x) - \frac{1}{x}L(x)                                          \\
    \int\dd{x}x^{-1}L(x) &amp; = L(x)\log(x) + \mathrm{Li}_{2}(1-x)                                            \\
    \int\dd{x}L(x)       &amp; = -x - (1-x) L(x)                                                               \\
    \int\dd{x}x L(x)     &amp; = \frac{1}{4}x (2 + x) -\frac{1}{2}\log(1-x) + \frac{1}{2}x^2 L(x)              \\
    \int\dd{x}x^2L(x)    &amp; = -\frac{1}{18}x (6 + 3 x + 2 x^2) - \frac{1}{3}\log(1-x) + \frac{1}{3}x^3 L(x)
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Using the definitions of $ b_{n}$, we find:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
     &amp; \frac{1}{2\beta}\sum_{n=0}^{4}b_{n}\int^{x^{+}_{1}}_{x^{-}_{1}} \dd{x_{1}}x_{1}^{n-2} L(x_1)                                              \\
     &amp; \quad = \frac{1}{2\beta}\bigg{[} -3\log(x) + \frac{16}{3}\log(1-x) - \frac{1}{18} x (66 - 21 x + 4 x^2) - 5 \mathrm{Li}_{2}(1-x)          \\   
     &amp; \hspace{2cm}    \log(\frac{1-x}{r})\qty(-6 - \frac{3}{x} + 6 x - 3 x^2 + \frac{2}{3}x^3 - 5\log(x))\bigg{]}\notag\bigg{|}^{x^{+}}_{x^{-}}
\end{align}
$$
&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Elor, G., Rodd, N. L., &amp;amp; Slatyer, T. R. (2015). Multistep cascade annihilations of dark matter and the Galactic Center Excess. Physical Review D, 91(10). &lt;a href=&#34;https://doi.org/10.1103/physrevd.91.103531&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1103/physrevd.91.103531&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Kim, D., Ee, J.-H., Yu, C., &amp;amp; Lee, J. (2021). Derivation of jacobian formula with Dirac delta function. European Journal of Physics, 42(3), 035006. &lt;a href=&#34;https://doi.org/10.1088/1361-6404/abdca9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1088/1361-6404/abdca9&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Kuno, Y., &amp;amp; Okada, Y. (2001). Muon decay and physics beyond the standard model. Reviews of Modern Physics, 73(1), 151–202. &lt;a href=&#34;https://doi.org/10.1103/revmodphys.73.151&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1103/revmodphys.73.151&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulation Based Inference for Efficient Theory Space Sampling: an Application to Supersymmetric Explanations of the Anomalous Muon (g-2)</title>
      <link>https://loganamorrison.github.io/publication/sbi-mssm-2022/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/sbi-mssm-2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Precision gamma-ray constraints for sub-GeV dark matter models</title>
      <link>https://loganamorrison.github.io/publication/matching-2021/</link>
      <pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/matching-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Asymptotic analysis of the Boltzmann equation for dark matter relic abundance</title>
      <link>https://loganamorrison.github.io/publication/asymptotic-boltzman-2021/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/asymptotic-boltzman-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sterile neutrino dark matter from generalized  CPT -symmetric early-Universe cosmologies</title>
      <link>https://loganamorrison.github.io/publication/cpt-rhn-2021/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/cpt-rhn-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Large N-ightmare dark matter</title>
      <link>https://loganamorrison.github.io/publication/large-nightmare-2021/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/large-nightmare-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Direct Detection of Hawking Radiation from Asteroid-Mass Primordial Black Holes</title>
      <link>https://loganamorrison.github.io/publication/hawking-rad-2021/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/hawking-rad-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hunting for Dark Matter and New Physics with (a) GECCO</title>
      <link>https://loganamorrison.github.io/publication/gecco-2021/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/gecco-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Thesis Defense</title>
      <link>https://loganamorrison.github.io/talk/thesis-defense/</link>
      <pubDate>Thu, 10 Dec 2020 13:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/talk/thesis-defense/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Large-Nightmare Dark Matter</title>
      <link>https://loganamorrison.github.io/talk/large-nightmare-dark-matter/</link>
      <pubDate>Sun, 20 Sep 2020 13:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/talk/large-nightmare-dark-matter/</guid>
      <description></description>
    </item>
    
    <item>
      <title>One-loop charge-breaking minima in the two-Higgs doublet model</title>
      <link>https://loganamorrison.github.io/publication/one-loop-thdm-2020/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/one-loop-thdm-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hazma: a python toolkit for studying indirect detection of sub-GeV dark matter</title>
      <link>https://loganamorrison.github.io/publication/hazma-2020/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/hazma-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Visualizing Fourier Series</title>
      <link>https://loganamorrison.github.io/post/visualizing-fourier-series/</link>
      <pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/visualizing-fourier-series/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./fourier_physics_116C.gif&#34; alt=&#34;Alt Text&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Its fall again and I&amp;rsquo;m TAing PHYS 116C (for the third time). The first topic of PHYS 116C is Fourier series. So, naturally, I thought I&amp;rsquo;d make a post about Fourier series. At some point, I stumbled acrossed &lt;a href=&#34;https://www.youtube.com/watch?v=Mm2eYfj0SgA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; video by &lt;code&gt;The Coding Train&lt;/code&gt;. In this post, I&amp;rsquo;d like to replicate what the &lt;code&gt;The Coding Train&lt;/code&gt; did, but in more generality, i.e. for a general Fourier series. I will focus on periodic functions on the interval $(-\pi, \pi)$ for simplicity (one can easily modify what I write to accomidate more general intervals). I will also be using &lt;code&gt;Julia&lt;/code&gt;, but the code can be easily adapted to any language (but at some put you&amp;rsquo;ll need a plotting library, so I&amp;rsquo;d say &lt;code&gt;Julia&lt;/code&gt;, &lt;code&gt;python&lt;/code&gt; or &lt;code&gt;Mathematica&lt;/code&gt; is the way to go.)&lt;/p&gt;
&lt;h1 id=&#34;fourier-series&#34;&gt;Fourier Series&lt;/h1&gt;
&lt;p&gt;The concept of Fourier series is incredibly useful for many fields in science,
ranging from math, to physics, to engineering. As a physicist, I use Fourier
series almost every day (mostly in infinite period limit, i.e. the Fourier
transform, but thats a topic for a later day.) The goal of a Fourier series is
to decompose a periodic function into a countably infinite number of sines and
cosines with varying frequencies. This can be done for any piecewise continuous
function over the real or complex numbers. Given some piecewise continuous
function, $f(t)$, over the real numbers, which is periodic over the interval
$(-\pi,\pi)$, we can write down its Fourier series as:
$$
\begin{align}
f(t) &amp;amp;= \dfrac{a_{0}}{2} + \sum_{n=1}^{\infty}a_{n}\cos(nt)  + \sum_{n=1}^{\infty}b_{n}\sin(nt)
\end{align}
$$
where $a_{0}, a_{n}$ and $b_{n}$ are the &lt;strong&gt;Fourier&lt;/strong&gt; coefficients. It is
straight forward to compute these coefficients using a technique known as
&lt;em&gt;Fourier&amp;rsquo;s trick&lt;/em&gt;. The idea is to realize that sine and cosines with different
frequencies are orthogonal over the interval $(-\pi,\pi)$ (i.e. if you integrate
the product of a sine and/or cosine of different frequencies of ($-\pi,\pi$) you
get zero). For example,
$$
\dfrac{1}{\pi}\int_{-\pi}^{\pi}\cos(nt)\cos(mt) = \begin{cases} 0 &amp;amp; n\neq m\\
1 &amp;amp; n=m
\end{cases}
$$
Similar identities hold for other combinations of sines and cosines. If we use this orthogonality of sines and cosines, we can integrate both sides of the definition of the Fourier series to isolate the $a_{n}$&amp;rsquo;s and $b_{n}$&amp;rsquo;s. The results are:
$$\begin{align}
a_{n} &amp;amp;= \dfrac{1}{\pi}\int_{-\pi}^{\pi}f(t)\cos(nt)dt, &amp;amp;
b_{n} &amp;amp;= \dfrac{1}{\pi}\int_{-\pi}^{\pi}f(t)\sin(nt)dt
\end{align}$$
Given these simple formulas, we can then easily compute Fourier series of any function we might like. Before doing so, I&amp;rsquo;d like to present an alternate form of the real Fourier series consisting of just cosines (which will be useful for us later on). To get rid of the sines, one can make use of the following identity:
$$\begin{align}
c_{n}\cos(nt + \phi_{n}) &amp;amp;= a_{n}\cos(nt) + b_{n}\sin(nt)\\\
c_{n} &amp;amp;= \sqrt{a_{n}^2 + b_{n}^2}\\
\phi_{n} &amp;amp;= -\tan^{-1}(b_{n}/a_{n})
\end{align}$$
(this is easiest to prove using complex exponentials.) Then, we can write down the Fourier series as:
$$\begin{align}
f(t) &amp;amp;= \sum_{n=0}^{\infty}c_{n}\cos(nt + \phi_{n})
\end{align}$$
with $c_{0} = a_{0} / 2$ and $\phi_{0} = 0$.&lt;/p&gt;
&lt;p&gt;Before moving onto the main topic, let&amp;rsquo;s write some code to compute Fourier series. I will be using &lt;code&gt;Julia&lt;/code&gt; (since its the best), but the reader can easily adapt the code to their favorite programing language.&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s create a Julia &lt;code&gt;struct&lt;/code&gt; for representing the Fourier series of a function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;struct FourierSeries
    a0::Float64
    ans::Array{Float64, 1}
    bns::Array{Float64, 1}
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s also create a constructor that will take in a function and return a filled &lt;code&gt;FourierSeries&lt;/code&gt; object. To do this, we will need to compute some integrals. We will use the &lt;code&gt;QuadGK&lt;/code&gt; library to do this (you can install via &lt;code&gt;Pkg.add(&amp;quot;QuadGK&amp;quot;)&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using QuadGK

&amp;quot;&amp;quot;&amp;quot;
    FourierSeries(f; N=10)

Generate a FourierSeries object containing the the first `N` (excluding a0)
Fourier coefficients of the function `f` over the interval (-π, π).
&amp;quot;&amp;quot;&amp;quot;
function FourierSeries(f::Function; N::Int=10)
    a0::Float64 = quadgk(t-&amp;gt; f(t), -π, π)[1] / π
    ans = Array{Float64, 1}(undef, N)
    bns = Array{Float64, 1}(undef, N)
    for n in 1:N
        ans[n] = quadgk(t-&amp;gt; f(t) * cos(n * t), -π, π)[1] / π
        bns[n] = quadgk(t-&amp;gt; f(t) * sin(n * t), -π, π)[1] / π
    end
    FourierSeries(f, a0, ans, bns)
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calling &lt;code&gt;FourierSeries(f)&lt;/code&gt; will return a &lt;code&gt;FourierSeries&lt;/code&gt; object with the first 10 Fourier coefficients computed. Likewise, &lt;code&gt;FourierSeries(f; N=100)&lt;/code&gt; would compute the first 100 Fourier coefficients. We will also what to be able to evaluate the Fourier series at a given time. Thus, to avoid explicitly writing the sum everytime, let&amp;rsquo;s write a function to do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot;&amp;quot;&amp;quot;
    eval(t, fs::FourierSeries)

Evaluate the Fourier series `fs` at the time `t`.
&amp;quot;&amp;quot;&amp;quot;
function eval(t::Float64, fs::FourierSeries)
    fs.a0 / 2 + sum(fs.ans[n] * cos(n * t) + fs.bns[n] * sin(n * t)
                    for n in 1:length(fs.ans))
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For convinience, we also make a vectorized function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function eval(ts::AbstractRange, fs::FourierSeries)
    [eval(t, fs) for t in ts]
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which can take in a range of times and return an array of the Fourier series evaluated at those times. Now, we can go nuts and compute the Fourier series for any function we wish. For example, we can compute the Fourier series of the step function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# step function: zero for t &amp;lt; 0 and π for t &amp;gt; 0.
f(t) = t &amp;lt; 0 ? 0.0 : π;
fs = FourierSeries(f)
# Plot it!
using Plots;
ts = LinRange(-π, π, 100);
plot(ts, eval(ts, fs), linewidth=1.5, label=&amp;quot;Fourier&amp;quot;, framestyle=:box)
plot!(ts, [f(t) for t in ts], linewidth=2, label=&amp;quot;f&amp;quot;)
ylabel!(&amp;quot;f(t)&amp;quot;)
xlabel!(&amp;quot;t&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../../assets/img/fs_step_function.svg&#34; alt=&#34;Fourier series of step function&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;epicycles&#34;&gt;Epicycles&lt;/h1&gt;
&lt;p&gt;If you&amp;rsquo;ve ever taken a physics course, you&amp;rsquo;ve likely encountered the simple harmonic oscillator (SHO). The motion of a SHO is described by the form $x(t) = A\cos(\omega t + \phi_{0})$, where $A$ is the amplitude of the oscillator, $\omega$ is the angular frequency and $\phi_{0}$ is the initial phase angle. You may have also be taught that you can visualize the motion of the oscillator as the projection of a point moving along a circle onto the &amp;ldquo;x&amp;rdquo; axis (if you haven&amp;rsquo;t seen this, you will soon!) We&amp;rsquo;d like to take this idea one step further. Because, a Fourier series is like a sum of an infinite number of SHO, each oscillating with a different frequency.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s condier the Fourier series we defined above, which we write down again here:
$$\begin{align}
f(t) &amp;amp;= \sum_{n=0}^{\infty}c_{n}\cos(nt + \phi_{n})
\end{align}$$
The first term (the $n=0$ term) is just a constant shift. The second term is where things start to get interesting, $c_{1}\cos(t+\phi_1)$. If you remember back to the &amp;ldquo;unit-circle&amp;rdquo;, this is the horizontal component of a line from the center of a circle of radius $c_{1}$ to the edge of the circle. The angle this line makes with the horizontal axis is $t + \phi_1$. Similarly, the third term, $c_{2}\cos(2t+\phi_2)$ is again the horizontal component of a line, but of a circle of radius $c_2$ and with an angle $2t+\phi_2$. Now, if we add the first three terms:
$$\begin{align}
c_0 + c_1\cos(t+\phi_1) + c_2\cos(2t+\phi_2)
\end{align}$$
what we get can be interpreted as follows. Consider the following figure:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fourier series of step function&#34; srcset=&#34;
               /post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_aa4d27ace328e06fcfb1048d85c9dec1.webp 400w,
               /post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_87f05ac6cbebc08f2fea4f80d399c19d.webp 760w,
               /post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_aa4d27ace328e06fcfb1048d85c9dec1.webp&#34;
               width=&#34;760&#34;
               height=&#34;592&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This figure contains a set of circles to guide the eye along with a set of line connecting the centers of the circles. Here we have only drawn three circles, but one can imagine continuing drawing more and more. Each line drawn in this figure has a length equal to the radius of the corresponding circle, $c_n$, and makes an angle with respect to the verticle axis of $nt + \phi_n$. Consider now, the final height of the tip of the final line. It is simply
$$\begin{align}
c_0 + c_1\cos(t+\phi_1) + c_2\cos(2t+\phi_2) + c_3\cos(3t+\phi_3) + \cdots
\end{align}$$
which is exactly the Fourier series. What we have done is gave a geometric interpretation of the Fourier series: the Fourier series is just an inifinte set of circles arranged in a funny way. We take a circle centered at ($x=0$,$y=c_0$) of radius $c_1$, then add another circle of radius $c_2$ centered at the edge of the first at an angle $t + \phi_1$, etc.. Then, the height of the center of the final circle represents the Fourier series. Note that the angles here depend on time. Therefore, all of the circles will rotate as time evolves.&lt;/p&gt;
&lt;p&gt;This is cute and all, but let&amp;rsquo;s see it in action:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./fourier_square_wave.gif&#34; alt=&#34;Alt Text&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Now, I&amp;rsquo;d like to explain how this was made. We will use a slightly different example just so we can see more pretty pictures. In order to make the above gif, what we need to do is first construct the &lt;code&gt;FourierSeries&lt;/code&gt; object. Let&amp;rsquo;s do this for a function that is:
$$\begin{align}
f(t) &amp;amp;= \begin{cases}
t + \pi &amp;amp; t &amp;lt; 0\
\pi &amp;amp; t &amp;gt; 0\
\end{cases}
\end{align}$$
To construct this object, we use:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;f(t) = t &amp;lt; 0 ? t + π : π
fs = FourierSeries(f)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will want to make a gif. This is done by using the &lt;code&gt;@gif&lt;/code&gt; macro in &lt;code&gt;Julia&lt;/code&gt; (in &lt;code&gt;python&lt;/code&gt; you can use matplotlib and its &lt;code&gt;animation&lt;/code&gt; module. See &lt;a href=&#34;https://jakevdp.github.io/blog/2012/08/18/matplotlib-animation-tutorial/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; for a good explaination). The &lt;code&gt;@gif&lt;/code&gt; macro takes in a &lt;code&gt;for&lt;/code&gt; loop as its argument. That is, we use:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;nframes = 1500
@gif for i = 1:nframes
    # code to make plots here...
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will make a gif for every 10 of the plots you constructed in the &lt;code&gt;for&lt;/code&gt; loop (see &lt;a href=&#34;http://docs.juliaplots.org/latest/#simple-is-beautiful-1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; for more information.) Inside our &lt;code&gt;for&lt;/code&gt; loop we&amp;rsquo;d first like to just plot the Fourier series. But we would like to evolve it through time. We can do so using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Plot window will always be -π → π
ts = range(-π, stop = π, length = 50);
@gif for i = 1:1500
    shift = i / 100 # time shift
    plot(
        ts, # horizontal plot windows
        [eval(t + shift, fs) for t in ts], # Fourier series values
        ylims = (-1.5, π + 1.5), # fix window height
        legend = false, # let&#39;s not go for legend
        xlims = (-π, 4π), # we make some extra room for later
        framestyle = :box, # because you&#39;ve got to have a frame
        aspect_ratio = 1 # so the circles look like circles and not ellipses
    )
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will draw the Fourier series as a &amp;ldquo;traveling wave&amp;rdquo; (think of a window of width ($-\pi$,$\pi$) moving to the right.) Now comes the hard part. We would like to draw the circles similar to how we drew them before. First, let&amp;rsquo;s make a circle maker:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot;&amp;quot;&amp;quot;
    circle(x, y, r)

Construct x and y positions of a cicle of radius `r` centered at (`x`, `y`).
&amp;quot;&amp;quot;&amp;quot;
function circle(x, y, r)
    θ = LinRange(0.0, 2π, 500)
    x .+ r * sin.(θ), y .+ r * cos.(θ)
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function will create $x$ and $y$ arrays for a circle centered at $(x,y)$ with radius $r$. We can draw the base circle, which is centered at $(0,c_0)$ using the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    # other code...
    x, y = (2.5π, fs.a0 / 2)
    r = sqrt(fs.ans[1]^2 + fs.bns[1]^2)
    ϕ = -atan(fs.bns[1], fs.ans[1])
    plot!(
        circle(x, y, r),
        seriestype = [:shape,],
        linecolor = :black,
        c = :white,
        legend = false
    )
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we shifted the circles center to be at $x=2.5\pi$. This is so it is out of the way of the plot of the Fourier series. Now, we would like to add on more circles. The centers of the next circle will be at $(x + c_1\sin(t + \phi_1), y + c_1\cos(t + \phi_1))$. In fact, each successive circle will be located at the previous $(x,y)$ but shifted by $(c_n\sin(nt + \phi_n), c_n\cos(nt + \phi_n))$. Let&amp;rsquo;s write an internal &lt;code&gt;for&lt;/code&gt; loop to draw all the circles:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    # other code...
    t = ts[end] + shift # get the final time
    for i = 2:length(fs.ans)
        x += r * sin((n - 1) * t + ϕ)
        y += r * cos((n - 1) * t + ϕ)
        # compute new radius and angle
        r = sqrt(fs.ans[n]^2 + fs.bns[n]^2)
        ϕ = -atan(fs.bns[n], fs.ans[n])
        plot!(
            circle(x, y, r),
            seriestype = [:shape,],
            linecolor = :black,
            c = :white,
            legend = false,
            fillalpha = 0.0
        )
    end
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will draw all of the circles. Lastly, we would like to draw a line connecting the center of the final circle to the final time of the Fourier series plot. This can be done using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    # other code...
    t = ts[end] + shift # get the final time
    for i = 2:length(fs.ans)
        # code...
    end
    x += r * sin(length(fs.ans) * (ts[end] + shift) + ϕ)
    y += r * cos(length(fs.ans) * (ts[end] + shift) + ϕ)
    interps = range(ts[end], stop = x, length = 50)
    plot!(interps, [y for _ in interps], color = :purple)
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that&amp;rsquo;s it. If we put everything together, the final code is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    shift = i / 100 #
    plot(
        ts,
        [eval(t + shift, fs) for t in ts],
        ylims = (-1.5, π + 1.5),
        legend = false,
        xlims = (-π, 4π),
        framestyle = :box,
        aspect_ratio = 1
    )
    x = 2.5π
    y = fs.a0 / 2
    r = sqrt(fs.ans[1]^2 + fs.bns[1]^2)
    ϕ = -atan(fs.bns[1], fs.ans[1])
    plot!(
        circle(x, y, r),
        seriestype = [:shape,],
        linecolor = :black,
        c = :white,
        legend = false
    )
    t = ts[end] + shift
    for n = 2:length(fs.ans)
        x += r * sin((n - 1) * t + ϕ)
        y += r * cos((n - 1) * t + ϕ)
        r = sqrt(fs.ans[n]^2 + fs.bns[n]^2)
        ϕ = -atan(fs.bns[n], fs.ans[n])
        plot!(
            circle(x, y, r),
            seriestype = [:shape,],
            linecolor = :black,
            c = :white,
            legend = false,
            fillalpha = 0.0
        )
        scatter!([x], [y], markersize = 0.3)
    end
    x += r * sin(length(fs.ans) * (ts[end] + shift) + ϕ)
    y += r * cos(length(fs.ans) * (ts[end] + shift) + ϕ)
    scatter!([x], [y], markersize = 0.1)
    interps = range(ts[end], stop = x, length = 50)
    plot!(interps, [y for _ in interps], color = :purple)
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that I have added some code to plot the centers of the circles using &lt;code&gt;scatter!([x], [y], markersize = 0.3)&lt;/code&gt;. Running the code will produce the following:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./fourier_linear_const.gif&#34; alt=&#34;Alt Text&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;As a final note, I&amp;rsquo;ll explain how I made the gif displaying &amp;ldquo;Physics 116C&amp;rdquo; at the top of this post. What I did was plot digitize the text for &amp;ldquo;Physics 116C&amp;rdquo; using &lt;a href=&#34;https://automeris.io/WebPlotDigitizer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt;. Using the data that I extracted from the webplot digitizer, I constructed linear interpolating functions for the $x$ and $y$ data. Then, I constructed Fourier series for $x$ and $y$ functions and essentially repeated what I showed above.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating Functional Determinants in a Thermal Field Theory using the Heat-Kernel</title>
      <link>https://loganamorrison.github.io/post/functional-det-heat-kernel/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/functional-det-heat-kernel/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this post, we will discuss how to compute fluctuation determinants is a
finite temperature field theory. The general form of an operator that we will
investigate is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O} &amp;amp;= -\nabla^2 + \omega_{n}^2 + m^2 + V(x)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $m$ is a zero-temperature mass, $\omega_{n} = 2\pi n T$ for bosons and
$2\pi(n+1/2)T$ for fermions and $V(x)$ is some space-dependent function. Often,
$V(x)$ will take the form of a background- or low-mass-field-dependent mass for
the fluctuation fields of the problem. For example, consider a $\phi^4$ theory at finite temperature with the following action:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
S[\phi] &amp;amp;= \int_{0}^{\beta}d\tau\int d^{3}x \dfrac{1}{2}(\partial_{\mu}\phi)^2 -\dfrac{1}{2}m^2\phi^2
+\dfrac{\lambda}{8}\phi^4
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\phi = \phi(\tau, x)$. If one expands the field $\phi$ as a Fourier series in the imaginary time coordinate $\tau$,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\phi(\tau, x) &amp;amp;= \sum_{n=-\infty}^{\infty}\phi_{n}e^{i\omega_{n}\tau}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and wishes to integrate over the heavy Matsubara modes ($n\neq0$ modes), then they will need to compute a thermal fluctuation determinant of an operator of the form:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O} &amp;amp;= -\nabla^2 + \omega_{n}^2 + m^2 + \dfrac{3}{2}\lambda\phi_{0}^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Where $\phi_{0}$ is the zero-mode ($n=0$ Matsubara mode.) In this case,
$V(x) = (3\lambda/2)\phi_{0}^2(x)$. The question we would like to answer is: how does one evaluate the following fluctuation determinant&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathrm{tr}\log\left(-\nabla^2 + \omega_{n}^2 + m^2 + V(x)\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We will answer this question in the limit as $T\to\infty$.&lt;/p&gt;
&lt;h2 id=&#34;heat-kernal-expansion&#34;&gt;Heat Kernal Expansion&lt;/h2&gt;
&lt;p&gt;The method we will employ to evaluate the fluctuation determinant of the operator $\mathcal{O} = -\nabla^2 + \omega_{n}^2 + m^2 + V(x)$ is the so called
heat-kernel expansion. The idea is to use the following identity:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\log(\lambda) = -\int_{0}^{\infty}\dfrac{ds}{s}e^{-\lambda s} + \mathrm{constant}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where the constant we left implicit is some infinite constant which will play
no role in our analysis. To derive this expression, one can consider the
following:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\int_{0}^{\infty}\dfrac{ds}{s}e^{-\lambda s} &amp;amp;=
\int_{0}^{\infty}ds\int_{\lambda}^{\infty}d\lambda&amp;rsquo;e^{-\lambda&amp;rsquo; s}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Switching the order of integration and integrating over $s$, we find:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\int_{0}^{\infty}\dfrac{ds}{s}e^{-\lambda s} &amp;amp;=
\int_{\lambda}^{\infty}d\lambda&amp;rsquo;\dfrac{1}{\lambda&amp;rsquo;} = \lim_{\lambda&amp;rsquo;\to\infty}\log(\lambda&amp;rsquo;) - \log(\lambda)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Thus, up to an infinite constant, the identity holds. Note that if we take
the trace of a log of a determinant, we are equivalently summing over the
log of the eigenvalues of the operator. Therefore, we can say that:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathrm{tr}\log(\mathcal{O}) = \sum_{\lambda}\log(\lambda) = -\int_{0}^{\infty}\dfrac{ds}{s}\sum_{\lambda}e^{-\lambda s} =
\int_{0}^{\infty}\dfrac{ds}{s}\mathrm{tr}e^{-\mathcal{O} s}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We will define the factor of $e^{-\mathcal{O}s}$ as the &lt;strong&gt;heat kernel&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
K(s, x, y) \equiv \langle x|e^{-\mathcal{O}_{x} s}|y\rangle
\end{align}$$&lt;/p&gt;
&lt;p&gt;where the subscript $x$ denotes that the derivatives and function evaluation of $\mathcal{O}$ to be evaluated with $x$. Then, the trace of $e^{-\mathcal{O} s}$ is just the integral over $x$ of $K(s,x,x)$:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\mathrm{tr}e^{-\mathcal{O} s} = \int d^{d}x K(s,x,x)
\end{align}$$&lt;/p&gt;
&lt;p&gt;The heat-kernel turns out to satisfy the heat equation (hence the name). This is
easy to see:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\partial}{\partial s}e^{-\mathcal{O}_{x} s} = -{\mathcal{O}_{x}} K(s,x,y)
\quad \implies \quad \left(\dfrac{\partial}{\partial s} + {\mathcal{O}_{x}}\right)K(s,x,y)
= 0
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The right-most equality is simply the heat equation with a source term of
$\omega_{n}^2 + m^2 + V(x)$. The boundary condition of the heat equation can be
found by setting $s=0$:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K(s=0,x,y) = \langle x|y\rangle = \delta^d(x-y)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The heat-kernel can be determined exactly if we set $V(x) = 0$. Let&amp;rsquo;s call:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{M}^2 = \omega_{n}^2 + m^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;for ease of notation. The heat-kernel for the operator:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O}_{0} = -\nabla^2 + \mathcal{M}^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;is given by the following:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K_{0}(s,x,y) = \dfrac{1}{(4\pi s)^{d/2}}\exp\left(-\dfrac{|x-y|^2}{4s}-s\mathcal{M}^2\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;This can be verified by differentiation. Additionally, one can check that this
expression satisfies the boundary condition (to do this, integrate some function
$f(x)$ by Taylor expanding the function. The results are a set of gaussian
integrals which can easily be evaluate to obtain $f(y)$.) Further more,
$K_{0}(s, x, x)$ is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K_{0}(s,x,x) = \dfrac{1}{(4\pi s)^{d/2}}e^{-s\mathcal{M}^2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We can use this result to find the general result. Recall the Zassenhaus formula (a special case of the Baker-Campbell-Hausdorff formula):&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
e^{-t(X + Y)} &amp;amp;= e^{-t X}e^{-t Y}e^{-\frac{t^2}{2}[X,Y]}
e^{-\frac{t^3}{3!}(2[Y,[X,Y]]+ [X,[X,Y]])}\cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where the $\cdots$ represent terms of order $t^{4}$ and higher. If we break up our general operator into:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O} = \mathcal{O}_{0} + V(x),
\end{align}
$$&lt;/p&gt;
&lt;p&gt;then we find that the general heat-kernel is given by:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
e^{-s\mathcal{O}} &amp;amp;= e^{-s\mathcal{O}_{0}}e^{-sV}e^{-\frac{s^2}{2}[\mathcal{O}_{0},V]}
e^{-\frac{s^3}{3!}(2[V,[\mathcal{O}_{0},V]]+ [\mathcal{O}_{0},[\mathcal{O}_{0},V]])}\cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We can easily evaluate the various commutators by considering their action on some test function $f(x)$. The results for the commutators shown are:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
[\mathcal{O}_{0},V] &amp;amp;= -\nabla^2 V\\
2[V,[\mathcal{O}_{0},V]]+ [\mathcal{O}_{0},[\mathcal{O}_{0},V]] &amp;amp;=-4V\nabla^2V+\nabla^4V
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The higher order terms can easily be evaluated as well. Thus, we have that:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K(s,x,x) &amp;amp;= e^{-s(\mathcal{M}^2 + V)}e^{\frac{s^2}{2}\nabla^2V}
e^{-\frac{s^3}{3!}\left(\nabla^4V-4V\nabla^2V\right)}\cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In order to make progress on this expression, we need to have control over which terms in the expression are important. Let&amp;rsquo;s re-introduce our original definitions:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{M}^2=\omega_{n}^2+m^2 = \tilde{\omega}_{n}^2T^2 + m^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where we defined:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\tilde{\omega}_{n}^2 = \omega_{n}^2/T^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Next, we will define a scaleless variable $z=sT^2$. In terms of $z$, our expression is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K(s,x,x) &amp;amp;= e^{-z\tilde{\omega}_{n}^2}e^{-\frac{z}{T^2}(m^2 + V)}e^{\frac{z^2}{2T^4}\nabla^2V}
e^{-\frac{z^3}{3!T^6}\left(\nabla^4V-4V\nabla^2V\right)}e^{\mathcal{O}(T^{-6})}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now it is clear how to proceed. We expand this expression in inverse powers of $T$. If we expand in inverse powers of $T$ and integrate over $s$, we find that, for bosons:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;\dfrac{T}{2}\sum_{n=-\infty}^{\infty} \mathrm{tr}\log(-{\nabla^2}+(2\pi n T)^2 + m^2 +V({x}))\\\
&amp;amp;\hspace{1cm}= -\dfrac{T}{2}\sum_{n=\infty}^{\infty} \int d^{d}{x}\left(\dfrac{T}{4\pi}\right)^{d/2}\int_{0}^{\infty}dz\dfrac{K(z,{x},{x})}{z^{d/2+1}}\notag\\
&amp;amp;\hspace{1cm}\underset{d\to3-2\epsilon}{=} \int d^{3}{x}\bigg{[}
-\frac{\pi^2 T^4}{90}+\frac{T^2(m^2 + V)}{24} -\frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{\mu^2}{4\pi T^2e^{-\gamma_{E}}})\right)}{64\pi^2}+ \mathrm{O}({T^{-2}})
\notag\\
&amp;amp;\hspace{3cm} +
\left(-\dfrac{T(m+V)^{3/2}}{12\pi} + \dfrac{T({\nabla}^2V)}{32\pi\sqrt{m^2+V}} + \dfrac{T(-4V{\nabla}^2V + {\nabla}^2V)}{192\pi(m^2+V)^{3/2}} + \cdots\right)
\bigg{]}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and for fermions:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;-\dfrac{T}{2}\sum_{n=-\infty}^{\infty} \mathrm{tr}\log(-{\nabla^2}+(2\pi (n+1/2) T)^2 + m^2 +V({x}))\\\
&amp;amp;\hspace{1cm}=\dfrac{T}{2}\sum_{n=\infty}^{\infty} \int d^{d}{x}\left(\dfrac{T}{4\pi}\right)^{d/2}\int_{0}^{\infty}dz\dfrac{K(z,{x},{x})}{z^{d/2+1}}\notag\\
&amp;amp;\hspace{1cm}\underset{d\to3-2\epsilon}{=}
\int d^{3}{x}\bigg{[} -\frac{7\pi^2 T^4}{720}
+ \frac{T^2(m^2 + V)}{48}
+ \frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{4e^{-\gamma_{E}}\mu^2}{\pi T^2})\right)}{64\pi^2}+\mathrm{O}({T^{-2}})\bigg{]}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;It is useful to note that, for bosons, the term proportional to $(m^2+V)^2$ can be written as:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;-\frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{\mu^2}{4\pi T^2e^{-\gamma_{E}}})\right)}{64\pi^2}\\
&amp;amp;\qquad= \frac{\left(m^2 + V\right)^2}{64\pi^2}\left[-\left(\frac{1}{\epsilon}+\log(4\pi e^{-\gamma})\right)+2\left(\dfrac{3}{4}+\log(4\pi)-\gamma_{E}\right)+\left(\log\left(\dfrac{T^2}{\mu^2}\right)-\dfrac{3}{2}\right)\right]\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where we&amp;rsquo;ve isolated the typical subtraction term (containing the $1/\epsilon +
\log(4\pi e^{-\gamma_{E}})$) and the Coleman-Weinberg-like potential term (the
$\log(T^2/\mu^2) - 3/2$). We can do the same for fermions, obtaining:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;\frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{4\mu^2e^{-\gamma_{E}}}{\pi T^2})\right)}{64\pi^2}\\
&amp;amp;\qquad= \frac{\left(m^2 + V\right)^2}{64\pi^2}\left[
\left(\frac{1}{\epsilon}+\log(4\pi e^{-\gamma})\right)-2\left(\dfrac{3}{4}+\log(\pi)-\gamma_{E}\right)-\left(\log\left(\dfrac{T^2}{\mu^2}\right)-\dfrac{3}{2}\right)\right]\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Even though we stopped our expansion at order $T^{0}$, one can easily see how to
include higher order term: simply cary out the expansion of the heat-kernel to
higher orders in $1/T$. For expand, the next term in the non-zero mode bosonic
expansion is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\zeta(3)}{768\pi^2 T^2}\left[\nabla^4V+2V\nabla^2V+(m^2+V)^3\right]
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and the next term in the fermionic expansion is the same thing multiplied by 7.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Effective Potential in a Scalar Field Theory</title>
      <link>https://loganamorrison.github.io/post/effective-potential-scalar-ft/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/effective-potential-scalar-ft/</guid>
      <description>&lt;h2 id=&#34;generic-form&#34;&gt;Generic Form&lt;/h2&gt;
&lt;p&gt;To derive the effective potential, we start with a couple definitions. We
define the generating function for greens functions as:
$$\begin{align}
Z[J] = \int\mathcal{D}\phi\exp(iS[\phi] + \int d^{4}x J(x)\phi(x))
\end{align}$$
This functional generates all possible Feynman diagrams. Not all of these
diagrams will be connected. To generate the connected diagrams, we
introduce the generating functional for connected diagrams:
$$\begin{align}
W[J] = -i\ln(Z[J])
\end{align}$$
Even the connected diagrams are not the most fundamental. The most
fundamental are the one-particle irreducible (1PI) diagrams. These are
generated by a functional which is the Legandre transform of $W[J]$:
$$\begin{align}
\Gamma[\phi_{\text{cl}}] = W[J] - \int d^{4}x J(x)\phi_{\text{cl}}(x)
\end{align}$$
where
$$\begin{align}
\phi_{\text{cl}}(x) = \dfrac{\delta W[J]}{\delta \phi(x)}
\end{align}$$
The effective potential will be given by
$$\begin{align}
\Gamma[\phi_{\text{cl}}] = -(VT)V_{\text{eff}}(\phi_{\text{cl}})
\end{align}$$
where $VT$ is the volume of space-time. Let&amp;rsquo;s illustrate how to compute
the effective action using the background field method. We begin by
expanding $\phi$ about the classical field, taking $\phi_{\text{cl}}$ to
be independent of space-time. That is,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\phi(x) = \phi_{\text{cl}} + \eta(x)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\eta(x)$ is a field representing the high momentum degrees of freedom of
$\phi(x)$. We now expand the action about $\phi_{\text{cl}}$:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
S[\phi(x)] &amp;amp; = S[\phi_{\text{cl}}] + \sum_{n=1}\dfrac{1}{n!}\int d^{4}x_{1}
\cdots\int d^{4}x_{n}\dfrac{\delta^{n}S[\phi(x)]}{\delta\phi(x_{1})
\cdots\delta\phi(x_{n})}\\
&amp;amp; = S[\phi_{\text{cl}}] + \int d^{4}y \dfrac{\delta S[\phi(x)]}{\delta\phi(y)}\eta(y) + \dfrac{1}{2}\int d^{4}y \int d^{4}z \dfrac{\delta^{2}S}{\delta\phi(y)\delta\phi(z)}\eta(y)\eta(z) + \cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
S[\phi] + \int d^{4}y J(y)(\phi(y) +\phi_{\text{cl}}) &amp;amp; = S[\phi_{\text{cl}}] + \int d^{4}y J(y)\phi_{\text{cl}} +
\int d^{4}y \eta(y)\left(\dfrac{\delta S[\phi]}{\delta\phi(y)} + J(y)\right)\\\
&amp;amp; \qquad + \int d^{4}y\int d^{4}z \eta(y)\dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\eta(z) + \cdots\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where all the functional derivatives are evaluated at $\phi_{\text{cl}}$. Note
that the equations of motion, which $\phi_{\text{cl}}$ satisfies, are&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\delta S[\phi]}{\delta\phi(y)}\bigg{|}&lt;em&gt;{\phi=\phi&lt;/em&gt;{\text{cl}}} + J(y) = 0
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, the term linear term in $\eta$ of the expansion of the action is zero. Now, the functional $Z[J]$ to quadratic order in $\eta$ is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Z[J] &amp;amp; = \int\mathcal{D}\phi\exp(iS[\phi] + i\int d^{4}y J(y)\phi(y))\notag\\
&amp;amp; = \exp\left(iS[\phi_{\text{cl}}] + i\int d^{4}y J(y)\phi_{\text{cl}})\right)\int\mathcal{D}\eta\exp\left(\dfrac{i}{2}\int d^{4}y\int d^{4}z \eta(y)\dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\eta(z) +\cdots\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We can explicitly evaluate the functional integral by wick rotating: $t\to i\tau$. Then,
$$\begin{align}
\int\mathcal{D}\eta\exp\left(-\dfrac{1}{2}\int d^{4}y_{E}\int d^{4}z_{E} \eta(y)\dfrac{\delta^{2} S_{E}[\phi]}{\delta\phi(y)\delta\phi(z)}\eta(z)\right) \propto \left(\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right)^{-1/2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now, using&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\left(\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right)^{-1/2} = \exp\left(-\dfrac{1}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;And thus,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Z[J] = \exp\left(iS[\phi_{\text{cl}}] + i\int d^{4}y J(y)\phi_{\text{cl}} -\dfrac{1}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right) = e^{iW[J]}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Therefore,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
W[J] = S[\phi_{\text{cl}}] + \int d^{4}y J(y)\phi_{\text{cl}} + \dfrac{i}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now, the effective action is given by&lt;/p&gt;
&lt;p&gt;$$
\begin{align}\label{effective_potential}
\Gamma[\phi_{\text{cl}}] &amp;amp; = W[J] - \int d^{4}y J(y)\phi_{\text{cl}}\                                                       &amp;amp; =S[\phi_{\text{cl}}] + \int d^{4}y J(y)\phi_{\text{cl}} + \dfrac{i}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}- \int d^{4}y J(y)\phi_{\text{cl}} \notag\
&amp;amp; =S[\phi_{\text{cl}}] + \dfrac{i}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\notag
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;specific-example-linear-sigma-model&#34;&gt;Specific Example: Linear Sigma Model&lt;/h2&gt;
&lt;h3 id=&#34;effective-potential-in-the-linear-sigma-model&#34;&gt;Effective Potential in the Linear Sigma Model&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s examine this process of computing the effective action for a simple example. Consider the linear sigma model:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{L} = \dfrac{1}{2}\left(\partial_{\mu}\mathbf{\Phi}\right)\cdot\left(\partial^{\mu}\mathbf{\Phi}\right) + \dfrac{1}{2}\mu^{2}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right) - \dfrac{\lambda}{4}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right)^{2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\mathbf{\Phi}$ is a vector containing $N$ scalar fields. We now expand these fields about the classical fields:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathbf{\Phi} = \mathbf{\Phi}_{\text{cl}} + \mathbf{\eta}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\mathbf{\Phi}_{\text{cl}}$ are space-time independent fields. Now, we would
like to take the second functional derivative with respect to the fields of the
action. Let&amp;rsquo;s first look at the derivative term:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp; \dfrac{\delta}{\delta\Phi^{i}(y)}\left(\partial_{\mu}\Phi^{k}(x)\right)\left(\partial^{\mu}\Phi^{k}(x)\right)                         \\
&amp;amp;= \lim_{\epsilon\to0}\dfrac{
\partial^{\mu}\left(\Phi^{k}(x) + \epsilon\delta^{4}(x-y)\right)\partial^{\mu}\left(\Phi^{k}(x) + \epsilon\delta^{4}(x-y)\right)
-\partial_{\mu}\Phi^{k}(x)\partial_{\mu}\Phi^{k}(x)
}{\epsilon}\\
&amp;amp; = \lim_{\epsilon\to0}\dfrac{2\partial^{\mu}\Phi^{k}(x)\epsilon\partial^{\mu}\delta^{4}(x-y)\delta^{ik} + \mathcal{O}(\epsilon^{2})}{\epsilon} \\
&amp;amp; = 2\partial^{\mu}\Phi^{k}(x)\partial^{\mu}\delta^{4}(x-y)\delta^{ik}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Taking a second functional derivative, we find
$$
\begin{align}
\dfrac{\delta^{2}}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\left(\partial_{\mu}\Phi^{k}(x)\right)\left(\partial^{\mu}\Phi^{k}(x)\right)
&amp;amp; = 2\partial_{\mu}\delta^{4}(x-z)\partial^{\mu}\delta^{4}(x-y)\delta^{ij}            \\
&amp;amp; = -2\delta^{4}(x-z)\partial^{2}\delta^{4}(x-y)\delta^{ij} + \text{total derivative}
\end{align}
$$
Note that the derivative is with respect to $x$. The $\mu$ term gives us
$$\begin{align}
\dfrac{\delta^{2}}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\Phi^{k}\Phi^{k} = 2\delta^{4}(x-z)\delta^{4}(x-y)\delta^{ij}
\end{align}$$
The $\lambda$ term gives us
$$\begin{align}
\dfrac{\delta^{2}}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\Phi^{m}\Phi^{m}\Phi^{n}\Phi^{n}
&amp;amp; = 2\dfrac{\delta}{\delta\Phi^{j}(z)}\left(\delta^{im}\Phi^{m}\Phi^{n}\Phi^{n} + \delta^{in}\Phi^{n}\Phi^{n}\Phi^{n}\right)\delta^{4}(x-y) \\
&amp;amp; = 2\left(\delta^{ij}\Phi^{n}\Phi^{n} + \delta^{ij}\Phi^{n}\Phi^{n}\right)\delta^{4}(x-y)\delta^{4}(x-z)                                   \\
&amp;amp; \qquad +4\left(\Phi^{i}\Phi^{j} + \Phi^{i}\Phi^{j}\right)\delta^{4}(x-y)\delta^{4}(x-z)\notag                                             \\
&amp;amp; = 4\delta^{ij}\Phi^{n}\Phi^{n}\delta^{4}(x-y)\delta^{4}(x-z)                                                                              \\
&amp;amp; \qquad +8\Phi^{i}\Phi^{j}\delta^{4}(x-y)\delta^{4}(x-z)\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\Phi^{i}=\Phi^{i}_{\text{cl}}}
&amp;amp; =-\delta^{4}(x-z)\partial^{2}\delta^{4}(x-y)\delta^{ij}                                                                           \\
&amp;amp; \qquad + \mu^{2}\delta^{4}(x-y)\delta^{4}(x-z)\delta^{ij} -\lambda\delta^{ij}\Phi^{n}\Phi^{n}\delta^{4}(x-y)\delta^{4}(x-z)\notag \\
&amp;amp; \qquad -2\lambda\Phi_{\text{cl}}^{i}\Phi_{\text{cl}}^{j}\delta^{4}(x-y)\delta^{4}(x-z)\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;To make things easier, let&amp;rsquo;s rotate $\Phi_{\text{cl}}^{i}$ such that&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Phi_{\text{cl}}^{i} \to (0,0,\dots,0,\Phi_{\text{cl}})
\end{align}$$&lt;/p&gt;
&lt;p&gt;Then,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Phi^{n}\Phi^{n} = \Phi_{\text{cl}}^{2} \qquad \text{and} \qquad \Phi_{\text{cl}}^{i}\Phi_{\text{cl}}^{j} =\Phi_{\text{cl}}^{2}\delta^{iN}\delta^{jN}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Denoting $\delta^{4}(x-y)$ as $\delta_{xy}$, we find that&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\mathbf{\Phi}=\mathbf{\Phi}_{\text{cl}}}
&amp;amp; =-\delta_{xz}\partial^{2}\delta_{xy}\delta^{ij}                                                                       \\
&amp;amp; \qquad + \mu^{2}\delta_{xy}\delta_{xz}\delta^{ij} -\lambda\delta^{ij}\Phi_{\text{cl}}^{2}\delta_{xy}\delta_{xz}\notag \\
&amp;amp; \qquad -2\Phi_{\text{cl}}^{2}\delta^{iN}\delta^{jN}\delta_{xy}\delta_{xz}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int\mathcal{D}\mathbf{\eta} &amp;amp; \exp(\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{i}(y)\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\mathbf{\Phi}=\mathbf{\Phi}_{\text{cl}}}\eta^{j}(z))\\\
&amp;amp; = \int\mathcal{D}\mathbf{\eta}\exp\bigg{(}-\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{1}(y)\delta_{xz}\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2} \right)\delta_{xy}\eta^{1}(z)\notag \\
&amp;amp; \qquad +\cdots\notag\\
&amp;amp; \qquad -\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{N-1}(y)\delta_{xz}\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2} \right)\delta_{xy}\eta^{N-1}(z)\notag\\
&amp;amp; \qquad -\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{N}(y)\delta_{xz}\left(\partial^{2} + 3\lambda\Phi_{\text{cl}}^{2} -\mu^{2} \right)\delta_{xy}\eta^{N}(z)\bigg{)}\notag
\end{align}$$&lt;/p&gt;
&lt;p&gt;Each of these terms in going to produce a term proportional to the inverse square root of the determinant of the operator sandwiched between the $\eta$&amp;rsquo;s:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int\mathcal{D}\mathbf{\eta} &amp;amp; \exp(-\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{i}(y)M(y,z)\eta^{j}(z)) \propto \left(\det M(y,z)\right)^{-1/2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Each of these operators has a Klein-Gordon operator: $\partial^{2} + m^{2}$. Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\left(\det M(y,z)\right)^{-1/2} = \exp(-\dfrac{1}{2}\log\det M(y,z))
\end{align}$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\log\det M(y,z) = \mathrm{tr}\log M(y,z)
\end{align}$$&lt;/p&gt;
&lt;p&gt;we have&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int\mathcal{D}\mathbf{\eta} &amp;amp; \exp(\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{i}(y)\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\mathbf{\Phi}=\mathbf{\Phi}_{\text{cl}}}\eta^{j}(z)) \\
&amp;amp; \qquad =
\exp(-\dfrac{1}{2}\mathrm{tr}\log\left(
\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{N-1}
\left(\partial^{2} + 3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)\right))\notag
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, our effective action is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Gamma[\Phi_{\text{cl}}] = S[\Phi_{\text{cl}}] + \dfrac{i}{2}\mathrm{tr}\log\left(
\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{N-1}
\left(\partial^{2} + 3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;To evaluate these determinants, we can use&lt;/p&gt;
&lt;p&gt;$$\begin{align}\label{trace_operator}
\mathrm{tr}\log
\left(\partial^{2} + m^{2}\right)
&amp;amp; = \int d^{4}x \langle{x}\log
\left(\partial^{2} + m^{2}\right)\rangle{x}\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}k}{(2\pi)^{4}}\int \dfrac{d^{4}p}{(2\pi)^{4}} \langle{x}\rangle{p}\langle{p}\log
\left(\partial^{2} + m^{2}\right)\rangle{k}\langle{k}\rangle{x}\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}k}{(2\pi)^{4}}\int \dfrac{d^{4}p}{(2\pi)^{4}} \langle{x}\rangle{p}(2\pi)^{4}\delta^{4}(k-p)\log
\left(-k^{2} + m^{2}\right)\langle{k}\rangle{x}\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}p}{(2\pi)^{4}} \left|\langle{x}\rangle{p}\right|^{2}\log
\left(-p^{2} + m^{2}\right)\\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}p}{(2\pi)^{4}} \log
\left(-p^{2} + m^{2}\right)\\\
&amp;amp; = VT\int \dfrac{d^{4}p}{(2\pi)^{4}} \log
\left(-p^{2} + m^{2}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;This last integral can be evaluated using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\log(-p^{2}+m^{2}) = -\lim_{\alpha\to0}\dfrac{\partial}{\partial\alpha}\dfrac{1}{(-p^{2}+m^{2})^{\alpha}}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using this, moving to Euclidean space and switching our integration dimension to $d$, we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int \dfrac{d^{d}p}{(2\pi)^{d}} \log
\left(-p^{2} + m^{2}\right)
&amp;amp; = -i\lim_{\alpha\to0}\dfrac{\partial}{\partial\alpha}\int \dfrac{d^{d}p_{E}}{(2\pi)^{d}}\dfrac{1}{\left(p_{E}^{2} + m^{2}\right)^{\alpha}}                                   \\
&amp;amp; =-i\lim_{\alpha\to0}\dfrac{\partial}{\partial\alpha} \dfrac{(-1)^{\alpha}}{(4\pi)^{d/2}}\dfrac{\Gamma(\alpha-d/2)}{\Gamma(\alpha)}\left(\dfrac{1}{m^{2}}\right)^{\alpha-d/2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Gamma(\alpha) = \dfrac{1}{\alpha} - \gamma + \mathcal{O}(\alpha)
\end{align}$$&lt;/p&gt;
&lt;p&gt;we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{\partial}{\partial\alpha}\dfrac{1}{\Gamma(\alpha)} = 1
\end{align}$$&lt;/p&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{align}\label{log_integral}
\int \dfrac{d^{d}p}{(2\pi)^{d}} \log
\left(-p^{2} + m^{2}\right)
&amp;amp; =-i\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(m^{2}\right)^{d/2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, we have found that,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Gamma[\Phi_{\text{cl}}] = S[\Phi_{\text{cl}}] + \dfrac{VT}{2}\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} + \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
S[\Phi_{\text{cl}}]
&amp;amp; = \int d^{4}x \dfrac{1}{2}\left(\partial_{\mu}\Phi_{\text{cl}}\right)\cdot\left(\partial^{\mu}\Phi_{\text{cl}}\right) + \dfrac{1}{2}\mu^{2}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right) - \dfrac{\lambda}{4}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right)^{2} \\
&amp;amp; = VT\left(\dfrac{1}{2}\mu^{2}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right) - \dfrac{\lambda}{4}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right)^{2}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, the effective potential is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
V_{\text{eff}}(\Phi_{\text{cl}}) &amp;amp; = -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4} \\
&amp;amp; \qquad-\dfrac{1}{2}\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} + \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}\right)\notag
\end{align}$$&lt;/p&gt;
&lt;p&gt;One will notice that this expression is divergent. The reason being that we
haven&amp;rsquo;t yet renormalized the effective potential. In the next section, we will
take care of these divergences in detail.&lt;/p&gt;
&lt;h3 id=&#34;renormalization-of-linear-sigma-model&#34;&gt;Renormalization of Linear Sigma Model&lt;/h3&gt;
&lt;p&gt;Before we can proceed, we need to renormalize the linear sigma model.
The renormalizable parameters are $Z_{a}$, the wave function
renormalizations, $\mu$, the masses and $\lambda$, the quartic
couplings. We thus augment the Lagrangian by the following counterterms:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\mathcal{L}&amp;amp; = \dfrac{1}{2}\left(\partial_{\mu}\mathbf{\Phi}\right)\cdot\left(\partial^{\mu}\mathbf{\Phi}\right) + \dfrac{1}{2}\mu^{2}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right) - \dfrac{\lambda}{4}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right)^{2}\\
&amp;amp; \qquad + \dfrac{1}{2}\delta_{Z}\left(\partial_{\mu}\mathbf{\Phi}\right)\cdot\left(\partial^{\mu}\mathbf{\Phi}\right) - \dfrac{1}{2}\delta_{\mu}\mu^{2}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right) - \dfrac{\delta_{\lambda}}{4}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right)^{2}\notag\end{aligned}$$&lt;/p&gt;
&lt;p&gt;The Feynmann rules for the vertices and there corresponding counter terms
are given by:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Vertex&lt;/th&gt;
&lt;th&gt;Rule&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2-pt&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma3.png&#34; alt=&#34;renorm_linear_sigma3&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2-pt CT&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma4.png&#34; alt=&#34;renorm_linear_sigma4&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4-pt&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma1.png&#34; alt=&#34;renorm_linear_sigma1&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4-pt CT&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma2.png&#34; alt=&#34;renorm_linear_sigma2&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;First, we will compute the mass renormalization graph. This graph is:&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma5.png&#34; alt=&#34;renorm_linear_sigma5&#34; width=&#34;300&#34;/&gt;
&lt;p&gt;Suppose that $\Phi_{b}$ is running in the loop. Then, the value of this
graph in $d=4-\epsilon$ dimensions is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Sigma = \dfrac{1}{2}(-2i\lambda)\left(\delta_{ab}\delta_{cc} + \delta_{ac}\delta_{bc}+\delta_{ac}\delta_{bc}\right)\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{i}{p^{2}+\mu^{2}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This is easily evaluated to&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Sigma = \lambda\delta_{ab}\left(N+2\right)\dfrac{(-1)i}{(4\pi)^{d/2}}\dfrac{\Gamma\left(1- \frac{d}{2}\right)}{\Gamma(1)}\left(-\dfrac{1}{\mu^{2}}\right)^{1- \frac{d}{2}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;In $d=4-\epsilon$ dimensions, the mass dimension of the fields is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\left[\Phi\right] = m^{(d-2)/2}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This means that&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
m^{d} = \left[\lambda\Phi^{4}\right] = m^{2d-4}\left[\lambda\right] \qquad \implies \qquad \left[\lambda\right] = m^{4-d} = m^{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s keep $\lambda$ dimensionless. To do this, we define&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\lambda = \left(\xi^{2}\right)^{\epsilon/2}\tilde{\lambda}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;where $\xi$ has dimensions of mass. Additionally, recall that the Gamma
function near $x=-n$ is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\Gamma(x) = \dfrac{(-1)^{n}}{n!}\left(\dfrac{1}{x+n}+1+\cdots + \dfrac{1}{n} + \mathcal{O}(x+n)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This means that&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\Gamma\left(\dfrac{\epsilon}{2}-1\right) = -\left(\dfrac{2}{\epsilon}+1-\gamma + \mathcal{O}(\epsilon)\right) = \dfrac{2}{\epsilon}\left(1+ \dfrac{2}{\epsilon}\log(e^{1-\gamma})+ \mathcal{O}(\epsilon)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Now, we have that, to order $\epsilon$,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\Sigma
&amp;amp; = -\tilde{\lambda}\delta_{ab}\left(N+2\right)\dfrac{\mu^{2}}{8\epsilon\pi^{2}}\left(1+\dfrac{\epsilon}{2}\log(4\pi)\right)\left(1-\dfrac{\epsilon}{2}\log(-\mu^{2})\right)\left(1+ \dfrac{\epsilon}{2}\log(e^{1-\gamma})\right)\left(1+\dfrac{\epsilon}{2}\log(\xi^{2})\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;And thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\boxed{\Sigma = -\tilde{\lambda}\delta_{ab}\left(N+2\right)\dfrac{\mu^{2}}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon}\left(1+\dfrac{\epsilon}{2}\log(\dfrac{4\pi\xi^{2}e^{1-\gamma}}{-\mu^{2}})\right)}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;The divergent piece is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\boxed{\Sigma = -\tilde{\lambda}\mu^{2}\delta_{ab}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s evaluate the other divergences. The source of the rest of the
divergences are from the following graphs:&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma6.png&#34; alt=&#34;renorm_linear_sigma6&#34; width=&#34;300&#34;/&gt;
&lt;p&gt;Let&amp;rsquo;s start by evaluating graph $a$. To avoid clutter, define
$C_{abcd} = \delta_{ab}\delta_{cd} + \delta_{ac}\delta_{bd} + \delta_{ad}\delta_{cb}$.
Then, the four-pt graph is:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = \dfrac{1}{2}\sum_{e,f}(-2i\lambda C_{abef})(-2i\lambda C_{efcd})\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{i}{(p_{s}+k)^{2}-m_{e}^{2}}\dfrac{i}{k^{2}-m_{f}^{2}} \\
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{1}{[(p_{s}+k)^{2}-m_{e}^{2}][k^{2}-m_{f}^{2}]}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;To evaluate this integral, we introduce Feynman parameters of the form:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\dfrac{1}{AB} = \int_{0}^{1}dx\int_{0}^{1}dy \dfrac{\delta(1-x-y)}{\left(Ax+By\right)^{2}} = \int_{0}^{1}dx\dfrac{1}{\left(B + (A-B)x\right)^{2}}\end{aligned}$$
Let&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
A &amp;amp; = (p_{s}+k)^{2}-m_{e}^{2} = k^{2} + 2p_{s}k + p_{s}^{2} -m_{e}^{2} \\
B &amp;amp; = k^{2}-m_{f}^{2}\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Then,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
B + (A-B)x
&amp;amp; = k^{2}-m_{f}^{2} + (k^{2} + 2p_{s}k + p_{s}^{2} -m_{e}^{2} - k^{2}+m_{f}^{2})x  \\
&amp;amp; = \left[k+x p_{s}k\right]^{2}+x(1-x)p_{s}^{2}-m_{f}^{2} + (m_{f}^{2}-m_{e}^{2})x
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Define&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\ell_a = k+x p_{s}k \qquad \text{and}\qquad \Delta = -x(1-x)p_{s}^{2}+m_{f}^{2} - (m_{f}^{2}-m_{e}^{2})x
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Then, switching integration variables to $\ell_{a}$,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{1}{\left(\ell_{a}^{2}-\Delta\right)^{2}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This can quickly be integrated to&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx \dfrac{(-1)^{2}i}{(4\pi)^{d/2}}\dfrac{\Gamma\left(2- \frac{d}{2}\right)}{\Gamma(2)}\left(\dfrac{1}{\Delta}\right)^{2-d/2}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Using $d=4-\epsilon$, this becomes&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx \dfrac{2i}{16\epsilon\pi^{2}}\left(1+ \dfrac{\epsilon}{2}\log(4\pi)\right)\left(1+ \dfrac{\epsilon}{2}\log(e^{-\gamma})\right)\left(1- \dfrac{\epsilon}{2}\log(\Delta)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\lambda = \tilde{\lambda}\left(\xi^{2}\right)\epsilon^{\epsilon/2}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This becomes&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx \dfrac{2i}{16\epsilon\pi^{2}}\left(1+ \dfrac{\epsilon}{2}\log(\dfrac{4\pi\xi^{4}e^{-\gamma}}{\Delta})\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Using $m_{e}=m_{f}=\mu$, we find&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\left((N+4)\delta_{ab}\delta_{cd}+2\delta_{ac}\delta_{bd} + 2\delta_{ad}\delta_{bc}\right)\int_{0}^{1} dx \dfrac{2i}{16\epsilon\pi^{2}}\left(1+ \dfrac{\epsilon}{2}\log(\dfrac{4\pi\xi^{4}e^{-\gamma}}{\mu^{2}-x(1-x)p_{s}^{2}})\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;The divergence goes like&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\left((N+4)\delta_{ab}\delta_{cd}+2\delta_{ac}\delta_{bd} +
2\delta_{ad}\delta_{bc}\right)\dfrac{2i}{16\epsilon\pi^{2}} + \text{finite}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This is exactly what we would get if we did the other diagrams, but with
the indices swapped. Adding everything up, we find&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\boxed{\Gamma
= 2\lambda^{2}\left(\delta_{ab}\delta_{cd}+\delta_{ac}\delta_{bd} + \delta_{ad}\delta_{bc}\right)(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon} + \text{finite}}\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We can now determine $\delta_{\mu},\delta_{Z}$ and $\delta_{\lambda}$.
For the self-energy graph, we require that, at $p^{2}=\mu^{2}$, the sum
of 1PI diagrams be zero. Diagramatically, this looks like:&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma7.png&#34; alt=&#34;renorm_linear_sigma7&#34; width=&#34;500&#34;/&gt;
&lt;p&gt;where the one-particle-irreducible diagrams. The sum in is given by&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\dfrac{i}{p^{2}+\mu^{2}} &amp;amp; = \dfrac{1}{Z}\left(\dfrac{i}{p^{2}+\mu_{0}^{2}} + \dfrac{i}{p^{2}+\mu_{0}^{2}}i\Sigma\dfrac{i}{p^{2}+\mu_{0}^{2}} + \dfrac{i}{p^{2}+\mu_{0}^{2}}i\Sigma\dfrac{i}{p^{2}-\mu_{0}^{2}}i\Sigma\dfrac{i}{p^{2}+\mu_{0}^{2}} + \cdots\right) \\
&amp;amp; = \dfrac{1}{Z}\dfrac{i}{p^{2}+\mu_{0}^{2}}\dfrac{1}{1 + \frac{\Sigma}{p^{2}+\mu_{0}^{2}}}\\
&amp;amp; = \dfrac{1}{Z}\dfrac{i}{p^{2}+\mu_{0}^{2} + \Sigma}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;where $Z = 1 + \delta_{Z}$ and $\mu_{0}^{2} = \left(1+\delta_{\mu}\right)\mu_{R}^{2}$.
The denominator is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
Z(p^{2}-\mu_{0}^{2} + \Sigma) = p^{2} +\mu_{R}^{2} -
\delta_{Z}p^{2}+\mu_{R}^{2}\left(\delta_{Z}+\delta_{\mu}\right) + \Sigma(p^{2})
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Our renormalization condition will require that this quantity is equal
to $p^{2} -\mu_{R}^{2}$ at $p^{2} = \mu_{R}^{2}$. That is, the pole is
at $\mu_{R}^{2}$. This requires that&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
0=-\tilde{\lambda}_{R}\mu^{2}_{R}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon} + \mu_{R}^{2}\delta_{\mu}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Thus, $\delta_{Z} = 0$ and&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\delta_{\mu} =-\tilde{\lambda}\mu^{2}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We also require the amplitude of&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\mathcal{M}(\Phi_{a}\Phi_{b}\to\Phi_{c}\Phi_{d}) = -2i\lambda\left(\delta_{ab}\delta_{cd} +
\delta_{ac}\delta_{bd} + \delta_{ad}\delta_{cb}\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;at $p^{2}=4m^{2}$.&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma8.png&#34; alt=&#34;renorm_linear_sigma8&#34; width=&#34;500&#34;/&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma9.png&#34; alt=&#34;renorm_linear_sigma9&#34; width=&#34;500&#34;/&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
0 &amp;amp; =-2i\delta_{\lambda}\left(\delta_{ab}\delta_{cd} + \delta_{ac}\delta_{bd} + \delta_{ad}\delta_{cb}\right)                                                   \\
&amp;amp; \qquad + 2i\lambda^{2}\left(\delta_{ab}\delta_{cd}+\delta_{ac}\delta_{bd} + \delta_{ad}\delta_{bc}\right)(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon}\notag\end{aligned}$$&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\delta_{\lambda} = \lambda^{2}(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s now return to the effective potential. The divergent part came from&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
-\dfrac{1}{2}\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} + \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Letting $d=4-\epsilon$, we have that&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}  &amp;amp; = \left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\left(1- \dfrac{\epsilon}{2}\log(\lambda\Phi_{\text{cl}}^{2} -\mu^{2})\right)   \\
\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} &amp;amp; = \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\left(1- \dfrac{\epsilon}{2}\log(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2})\right) \\
\Gamma(-d/2) &amp;amp; = \dfrac{1}{\epsilon}\left(1- \dfrac{\epsilon}{2}\left(\gamma- \dfrac{3}{2}\right)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Now,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
&amp;amp; (N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} +
\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}                                                                                                 \\
&amp;amp; = (N-1)\left(\lambda^{2}\Phi_{\text{cl}}^{4} -2\lambda\mu^{2}\Phi_{\text{cl}}^{2} + \mu^{4}\right) + \left(9\lambda^{2}\Phi_{\text{cl}}^{4}
-6\lambda\mu^{2}\Phi_{\text{cl}}^{2} + \mu^{4}\right) + \mathcal{O}(\epsilon)\notag \\
&amp;amp; = (N+8)\lambda^{2}\Phi_{\text{cl}}^{4} -2(N+2)\lambda\mu^{2}\Phi_{\text{cl}}^{2} + N\mu^{4} +\mathcal{O}(\epsilon)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Therefore, the divergent part of the effective potential, before adding in the
counterterms, is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
V_{\text{eff}} = -\dfrac{1}{32\epsilon\pi^{2}}\left((N+8)\lambda^{2}\Phi_{\text{cl}}^{4} -2(N+2)\lambda\mu^{2}\Phi_{\text{cl}}^{2} + N\mu^{4} \right) + \cdots
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;To add in the counterterms, we let&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\mu^{2} &amp;amp; \to \mu^{2}+\lambda\mu^{2}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon} \\
\lambda &amp;amp; \to\lambda + \lambda^{2}(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We only make these changes to terms of order&lt;/p&gt;
&lt;p&gt;$\mathcal{O}(\epsilon^{0})$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
-\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4} \to -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4} -\lambda\mu^{2}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{1}{\epsilon}\Phi_{\text{cl}}^{2} + \lambda^{2}(N+8)\dfrac{1}{32\pi^{2}}\dfrac{1}{\epsilon}\Phi_{\text{cl}}^{4}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Miraculously, we can see that the infinities attached to
$\Phi_{\text{cl}}^{2}$ and $\Phi_{\text{cl}}^{4}$ cancel! Our potential is now&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
V_{\text{eff}} &amp;amp; = -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4}\\
&amp;amp; \qquad +\dfrac{1}{4}\dfrac{1}{16\pi^{2}}\bigg{[}
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(\lambda\Phi_{\text{cl}}^{2} -\mu^{2})\notag\\
&amp;amp; \qquad +\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}) + \gamma- \dfrac{3}{2} - \log(4\pi)\bigg{]}\notag
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We can modify our subtraction scheme in order to get rid of the annoying
constants and make the log dimensionless. Doing so, we obtain&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
V_{\text{eff}} &amp;amp; = -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4}                                                      \\
&amp;amp; \qquad +\dfrac{1}{4}\dfrac{1}{16\pi^{2}}\bigg{[}
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(\dfrac{\lambda\Phi_{\text{cl}}^{2} -\mu^{2}}{\xi^{2}})\notag\\
&amp;amp; \qquad +\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(\dfrac{3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}}{\xi^{2}})\bigg{]}
\notag
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Where $\xi$ is a parameter with dimensions of mass.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Solving the Boltzmann Equation</title>
      <link>https://loganamorrison.github.io/post/solving-boltzman-equation/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/solving-boltzman-equation/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this notebook, we will investigate how to solve the Boltzmann equation in
order to determine the relic abundance of a species. Our focus will be on
a species which represents a dark matter (DM) particle. We will assume that the
dark matter interacts with the standard model (SM) through a massive mediator
with interactions that look like
$\bar{\chi}\chi\to \mathrm{SM}_{1} + \mathrm{SM}_{2}$, i.e. through a $2\to2$
interaction. For these types of interactions, the Boltzmann equation takes the
form of:
$$\begin{align}
\dfrac{dn}{dt} + 3Hn = -\langle\sigma v\rangle(n^2 - n_{\mathrm{eq}}^2)
\end{align}$$
where $n$ is the DM number density, $n_{\mathrm{eq}}$ is the DM equilibrium
number density, $H$ is the hubble constant and $\langle\sigma v\rangle$ is the
annihilation cross section for DM into SM particles. As is, this equation is
in poor form. We will make several changes to bring it into a more suitible
form for numerically solving.&lt;/p&gt;
&lt;p&gt;Our first change will be to define the so called comoving number density, $Y$.
This will be defined as:
$$\begin{align}
Y = \dfrac{n}{s}
\end{align}$$
where $s$ is the SM entropy density. Note that the total SM entropy is
conserved, i.e. $a^3s = \mathrm{constant}$ with $a$ being the scale factor of
the universe. This implies that:
$$\begin{align}
\dfrac{d}{dt}a^3s = 3\dfrac{da}{dt}a^2s + a^3\dfrac{ds}{dt} = 0
\end{align}$$
If we rearange this equation and recall that $d\log(a)/dt = H$, we find that:
$$\begin{align}
\dfrac{ds}{dt} = -3\dfrac{1}{a}\dfrac{da}{dt}s = -3Hs
\end{align}$$
This relation will allow us to determine $dY/dt$:
$$\begin{align}
\dfrac{1}{s}\dfrac{dn}{dt} &amp;amp;= \dfrac{dY}{dt} - 3HY
\end{align}$$
Therefore, the Boltzmann equation for $Y$ is:
$$\begin{align}
\dfrac{dY}{dt} = -s\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)
\end{align}$$
where we defined $Y_{\mathrm{eq}} = n_{\mathrm{eq}}/s$. Next, we will change
independent variables from time to temperature. To do this, we again us
$\dot{s}/s = -3H$. Using the explict form $s=2\pi^2/45 hT^3$
($h$ being the number of d.o.f. in entropy),
one finds that:
$$\begin{align}
-3H = \dfrac{1}{s}\dfrac{ds}{dt} =
\dfrac{3}{T}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\dfrac{dT}{dt}
\end{align}$$
Therefore,
$$\begin{align}
\dfrac{dt}{dT} =-\dfrac{1}{HT}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\end{align}$$
We can use this relationship to determine $dY/dT$:
$$\begin{align}
\dfrac{dY}{dT} = \dfrac{dt}{dT}\dfrac{dY}{dt} =
\dfrac{s}{HT}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)
\end{align}$$
Another change people usually make is again changing the indepednent variable
from $T\to x = m/T$ where $m$ is the mass of the DM particle. If we make this
change, we find that:
$$\begin{align}
\dfrac{dY}{dx} =-
\dfrac{s}{Hx}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)
\end{align}$$
We can expand out the definitions of $s$ and $H=\sqrt{8\pi\rho/3}/M_{\mathrm{pl}}$
$$\begin{align}
H = \sqrt{\dfrac{8\pi G}{3}\rho} =
\sqrt{\dfrac{8\pi^3}{90}}\sqrt{g}\dfrac{T^2}{M_{\mathrm{pl}}}
\end{align}$$
to obtain:
$$\begin{align}
\boxed{\dfrac{dY}{dx} =-
\sqrt{\dfrac{\pi}{45}}\dfrac{m M_{\mathrm{pl}}}{x^2}g^{1/2}_{\star}
\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)}
\end{align}$$
where we defined:
$$\begin{align}
g^{1/2}_{\star} \equiv \left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\dfrac{h}{\sqrt{g}}
\end{align}$$
This is typically how people quote the Boltzmann equation. However, one final
set of modifications needs to be made for numerical purposes. $Y$ can vary
over many orders of magnitude. Thus, it is very useful to define
$W\equiv\log(Y)$. Then, $W$ only undergoes order $1$ changes. Additionally, it
is useful to work with the $\log(x)$ instead of $x$. Making these changes
we find that:
$$\begin{align}
\boxed{\dfrac{dW}{d\log(x)} =-
\sqrt{\dfrac{\pi}{45}}\dfrac{m M_{\mathrm{pl}}}{x}g^{1/2}_{\star}
\langle\sigma v\rangle(e^{W} - e^{2W_{\mathrm{eq}}-W})}
\end{align}$$
In the next sections, we will solve this equation.&lt;/p&gt;
&lt;h2 id=&#34;simple-model&#34;&gt;Simple Model&lt;/h2&gt;
&lt;p&gt;In many cases, the thermally averaged annihilation cross section can be brought
into the form:
$$\begin{align}
\langle\sigma v\rangle = \langle\sigma v\rangle_{0}x^{-n} +
\mathrm{O}(x^{-n-1})
\end{align}$$
In this form, we can simplify the Boltzmann equation to:
$$\begin{align}
\dfrac{dW}{d\log(x)} =-
\sqrt{\dfrac{\pi}{45}}\dfrac{m M_{\mathrm{pl}}}{x^{n+1}}g^{1/2}_{\star}
\langle\sigma v\rangle_{0}(e^{W} - e^{2W_{\mathrm{eq}}-W})
\end{align}$$&lt;/p&gt;
&lt;h4 id=&#34;evolution-of-w--logns&#34;&gt;Evolution of $W = \log(n/s)$&lt;/h4&gt;
&lt;p&gt;Now, let&amp;rsquo;s define a model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DarkSUN

mutable struct DarkMatterModel
  χ::ThermodynamicFermion
  n::Int64
  sm::StandardModel
  σ0::Float64
end

&amp;quot;&amp;quot;&amp;quot;
  DarkMatterModel(m::Float64, n::Int64, σ0::Float64)

Default constructor for DM model

# Arguments
- `m::Float64`: DM mass
- `n::Int64`: interaction order - 0: s-wave, 1: p-wave and so on.
- `σ0::Float64`: thermal cross section coefficient
&amp;quot;&amp;quot;&amp;quot;
function DarkMatterModel(m::Float64, n::Int64, σ0::Float64)
  χ = ThermodynamicFermion(m, 2.0)
  DarkMatterModel(χ, n, StandardModel(), σ0)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To solve the Boltzmann equation, we will use &lt;code&gt;DifferentialEquantions.jl&lt;/code&gt;
(for solving the differential equation) and &lt;code&gt;DarkSUN&lt;/code&gt; (for thermal functions
such as $g^{1/2}_{\star}$ and $n_{\mathrm{eq}}$.) Let&amp;rsquo;s define the Boltzmann
equation:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DifferentialEquations

const Mpl = 1.220910e19

&amp;quot;&amp;quot;&amp;quot;
  boltzmann(w, p, logx)

Boltzmann equation in `DifferentialEquations.jl` format.

# Arguments
- `dW::Array{Float64, 1}`: derivative of log of number density over SM entropy density
- `W::Array{Float64, 1}`: log of number density over SM entropy density
- `model::DarkMatterModel`: model
- `logx::Float64`: log of mass over temperature
&amp;quot;&amp;quot;&amp;quot;
function boltzmann!(dW::Array{Float64, 1}, W::Array{Float64, 1},
                   model::DarkMatterModel, logx::Float64)
  x::Float64 = exp(logx)
  # update the temperature
  model.χ.T = model.χ.mass / x
  model.sm.T = model.χ.mass / x
  pf::Float64 = (-sqrt(π/45) * model.σ0 * model.χ.mass * Mpl * sqrt_gstar(model.sm) / x^(model.n+1))
  Weq::Float64 = log_neq(model.χ) - log_entropy_density(model.sm)
  dW[1] = pf * (exp(W[1]) - exp(2Weq - W[1]))
end


&amp;quot;&amp;quot;&amp;quot;
  jacobian(w, p, logx)

Jacobian of the boltzmann equation in `DifferentialEquations.jl` format.

# Arguments
- `J::Array{Float64, 2}`: derivative of log of number density over SM entropy density
- `W::Array{Float64, 1}`: log of number density over SM entropy density
- `model::DarkMatterModel`: model
- `logx::Float64`: log of mass over temperature
&amp;quot;&amp;quot;&amp;quot;
function jacobian!(J::Array{Float64, 2}, W::Array{Float64, 1},
                   model::DarkMatterModel, logx::Float64)
  x::Float64 = exp(logx)
  # update the temperature
  model.χ.T = model.χ.mass / x
  model.sm.T = model.χ.mass / x
  pf::Float64 = (-sqrt(π/45) * model.σ0 * model.χ.mass * Mpl * sqrt_gstar(model.sm) / x^(model.n+1))
  Weq::Float64 = log_neq(model.χ) - log_entropy_density(model.sm)
  J[1,1] = pf * (exp(W[1]) + exp(2Weq - W[1]))
end;

&amp;quot;&amp;quot;&amp;quot;
  solve(model, logxspan)

Solve the Boltzmann equation for the given model.

# Arguments
- `model::DarkMatterModel`: DM model
- `logxspan::Tuple{Float64}`: range of log(x)
&amp;quot;&amp;quot;&amp;quot;
function solve!(model::DarkMatterModel, logxspan::Tuple{Float64, Float64})
  # Initialize temperatures
  model.χ.T = model.χ.mass * exp(-logxspan[1])
  model.sm.T = model.χ.mass * exp(-logxspan[1])
  # Initial value for W
  W0 = log_neq(model.χ) - log_entropy_density(model.sm)
  # Create ODE problem
  ff = ODEFunction(boltzmann!;jac=jacobian!)
  prob = ODEProblem(ff,[W0],logxspan, model)
  # Solve it!
  solve(prob, Rodas5(autodiff=false));
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s solve for various values of $\sigma_{0}$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Values for logx
logxspan = (log(1), log(500))
σ0s = [1e-7, 1e-8, 1e-9, 1e-10]
models = [DarkMatterModel(100.0, 0, σ0) for σ0 in σ0s]
sols = [solve!(model, logxspan) for model in models];
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can plot the solution:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

plt.figure(dpi=100)
for (i, sol) in enumerate(sols)
  plt.plot(sol.t, sol[1,:], label=L&amp;quot;$\sigma_{0} = $&amp;quot;*string(σ0s[i]))
end
plt.ylabel(L&amp;quot;$W$&amp;quot;, fontsize=16)
plt.xlabel(L&amp;quot;$\log(x)$&amp;quot;, fontsize=16)
plt.xlim([logxspan[1], logxspan[2]])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_10147bd2bacfaa1aa815628983cdfff4.webp 400w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_56d2474567ca18be94e709899cdf0bb6.webp 760w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_10147bd2bacfaa1aa815628983cdfff4.webp&#34;
               width=&#34;578&#34;
               height=&#34;442&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;relic-densities&#34;&gt;Relic Densities&lt;/h4&gt;
&lt;p&gt;Recall that the relic density is computed using:
$$\begin{align}
\Omega_{\chi} h^2 = \dfrac{s_{0}}{\rho_{c}}m_{\chi}Y(x=\infty)
\end{align}$$
where $s_{0} = 2891.2 \mathrm{cm}^{-3}$ and
$\rho_{c} =1.05375\times10^{-5}\mathrm{h}^2\mathrm{GeV}\mathrm{cm}^{-3}$. Let&amp;rsquo;s
perform the excercise of computing the relic density for values values of
$m_{\chi}$ and $\langle\sigma v\rangle_{0}$. We will then plot the contours
for which the combination $(m_{\chi}, \langle\sigma v\rangle_{0})$ gives the
correct observed relic density, which is $\Omega_{\chi}h^2=0.1198$. First,
let&amp;rsquo;s write a function to solve the Boltzmann equantion and compute the relic
density:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;const ρc = 1.05375e-5
const s₀ = 2891.2

function relic_density(model::DarkMatterModel)
  sol = solve!(model, (log(1), log(1000)))
  s₀ / ρc * model.χ.mass * exp(sol[1, end])
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&amp;rsquo;s compute the relic density for DM masses between $10$ and
$10^4\mathrm{GeV}$ with cross sections between $10^{-12}$ and
$10^{-7} \mathrm{GeV}^{-2}$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;mχs = 10 .^(range(-1, stop=4, length=150))
σ0s = 10 .^(range(-12, stop=-7, length=150))
models = [DarkMatterModel(mχ, 0, σ0) for mχ in mχs, σ0 in σ0s]
Ωh²s = [relic_density(model) for model in models];
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&amp;rsquo;s plot the contours of correct relic density:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Contour
const Ωh²cdm = 0.1198

cs = contour(mχs, σ0s, Ωh²s, Ωh²cdm)

plt.figure(dpi=100)
for line in lines(cs)
  xs, ys = coordinates(line)
  plt.plot(xs, ys .* 1.16733e-17 * 1e26) # convert units to 10^-26 cm^3/s
end
plt.xscale(&amp;quot;log&amp;quot;)
plt.ylabel(L&amp;quot;$\langle\sigma v\rangle_{0} \ (10^{-26}\mathrm{cm}^{3}/\mathrm{s})$&amp;quot;, fontsize=16)
plt.xlabel(L&amp;quot;$m_{\chi} \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.ylim([0, 6])
plt.xlim([minimum(mχs),maximum(mχs)])
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_83f099ab6a750d7c7e3358d385183d5e.webp 400w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_412cf33d3a1dd3cf0474bbce2a0fddf1.webp 760w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_83f099ab6a750d7c7e3358d385183d5e.webp&#34;
               width=&#34;571&#34;
               height=&#34;444&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Temperature Evolution of a Decoupled Dark Sector</title>
      <link>https://loganamorrison.github.io/post/temp-evolution-decoupled/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/temp-evolution-decoupled/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this document, we will invesigate how to compute the temperature and
evolution of temperature of a species which is decoupled from the standard
model. For simplicity, we will consider a set of particles which are decoupled
from the standard model but are coupled in their own sector. If a species
or set of species is completely decoupled from the standard model, then there
should be no entropy exchange between the standard model and the secluded
sector. Let&amp;rsquo;s denote the secluded sector as the &amp;ldquo;dark&amp;rdquo; sector. Then, the entropy
density of the dark sector, denoted by $s_{d}$, is conserved in totality, i.e.,
$\frac{d}{dt}(a^3s_{d}) = 0$ ($a$ is the scale factor of the universe.) This
implies that the ratio of entropy densities of the dark and standar model is
a constant:
$$\begin{align}
\mathrm{constant} = \dfrac{a^3s_{d}(T_{d})}{a^3s(T)} = \dfrac{s_{d}(T_{d})}{s(T)}
\end{align}$$
where $s$ is the standard model entropy density, $T_{d}$ is the dark sector
temperature and $T$ is the standard model temperature. Since this ratio is a
constant, we can evaluate the ratio at different temperature and still have
equality. i.e.:
$$\begin{align}
\dfrac{s_{d}(T_{d,1})}{s(T_1)} = \dfrac{s_{d}(T_{d,2})}{s(T_2)}
\end{align}$$
Let&amp;rsquo;s parameterize the entropy densities in terms of their repsective
relativistic degrees of freedom:
$$\begin{align}
s_{d}(T_{d}) &amp;amp;= \dfrac{2\pi^2}{45}h_{d}(T_{d})T_{d}^3\
s(T) &amp;amp;= \dfrac{2\pi^2}{45}h(T)T^3
\end{align}$$
Then, the ratio of entropy densities becomes:
$$\begin{align}
\dfrac{s_{d}(T_{d})}{s(T)} = \dfrac{h_{d}(T_{d})}{h(T)}\left(\dfrac{T_{d}}{T}\right)^3
\end{align}$$
We will define the ratio of dark to standard model temperatures as
$\xi\equiv T_{d}/T$. Now, our conservation equation reads:
$$\begin{align}
\dfrac{h_{d}(T_{d,1})}{h(T_1)}\xi_{1}^3 = \dfrac{h_{d}(T_{d,2})}{h(T_2)}\xi_{2}^3
\end{align}$$
Suppose that in the very early universe, the ratio of temperatures is known.
Let&amp;rsquo;s call it $\xi_{\infty} = T_{d,\infty}/T_{\infty}$. Then, at lower
temperatures, the ratio will be given by:
$$\begin{align}
\xi^3 = \dfrac{h(T)}{h_{d}(T_{d})}\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})}\xi_{\infty}^3
= \dfrac{h(T)}{h_{d}(T_{d})} C_{\infty}
\end{align}$$
where we defined $C_{\infty} = \xi_{\infty}^3h_{d}(T_{d,\infty})/h(T_{\infty})$.
Thus, the evolution of the dark sector temperature is governed by the evolution
of its own d.o.f. and the standard model d.o.f. In principle, if the ratio at
very large temperatures is known, then the ratio at lower temperatures can be
computed numerically. In the next sections, we will figure out how to
numerically determine the ratio at lower temperatures. We will do so for two
cases: one case where all dark sector particles are massive and two where there
is at least one massless species. The reason for the distinction can be seen
from the above equation. For massive particles, the entropy density drops off
exponentially once the temperature drops bellow its mass. Therefore, if all
particles are massive, the dark temperature will increase exponentially
compared to the standard model as long as the massive particles are in kinetic
equilibrium. If there is at least one massless particle, the temperature never
undergoes an exponetial increase.&lt;/p&gt;
&lt;h2 id=&#34;approximate-form-of-dof-in-entropy&#34;&gt;Approximate Form of D.O.F in Entropy&lt;/h2&gt;
&lt;p&gt;Here we give results for the general form of $h_{d}(T_{d})$. It is:
$$\begin{align}
h_{d}(T_{d}) = \dfrac{45}{4\pi^4}\sum_{i}\left(\dfrac{T_{i}}{T_{d}}\right)^3
g_{i}x_{i}^3\sum_{m=1}^{\infty}\dfrac{(\mp1)^{m+1}}{m}K_{3}(mx_{i})
\end{align}$$
where the sum runs over all particles in the sector, $g_{i}$ is the number
of internal d.o.f. in species $i$, $T_{i}$ is the temperature of species $i$,
and $x_{i} = m_{i}/T_{i}$. Typically, it is
sufficient to keep only the $m=1$ term in the series, yielding:
$$\begin{align}
h_{d}(T_{d}) = \dfrac{45}{4\pi^4}\sum_{i}\left(\dfrac{T_{i}}{T_{d}}\right)^3
g_{i}x_{i}^3K_{3}(x_{i}) =
\dfrac{45}{4\pi^4 T_{d}^3}\sum_{i}g_{i}m_{i}^3K_{3}(m_{i}/T_{i})
\end{align}$$
For a massless species, one finds that:
$$\begin{align}
m_{i}^3K_{3}(m_{i}/T_{i}) \to 8T_{i}^3
\end{align}$$
Therefore, the general expression is:
$$\begin{align}
h_{d}(T_{d}) =
\dfrac{90}{\pi^4}\sum_{m_{i}=0}g_{i} +
\dfrac{45}{4\pi^4}\sum_{m_{i}\neq0}g_{i}x_{i}^3K_{3}(x_{i}) + \cdots
\end{align}$$
where the $\cdots$ represent terms that are decoupled.&lt;/p&gt;
&lt;h2 id=&#34;case-1-all-massive-dark-sector-particles&#34;&gt;Case 1: All Massive Dark Sector Particles&lt;/h2&gt;
&lt;p&gt;The equation that we wish to solve is the following:
$$\begin{align}
\xi^3h_{d}(\xi T) = h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})}\xi_{\infty}^3
\end{align}$$
where, in this expression, one should consider $T$ as being fixed and $\xi$
being a function of $T$. Our goal will be to find upper and lower bounds on
the LHS of this equation. Note that
$$\begin{align}
\dfrac{45}{4\sqrt{2}\pi^{7/2}}\sum_{i}x_{i}^{5/2}e^{-x_{i}}
&amp;lt;
h_{d}(\xi T) &amp;lt; \sum_{i,b}g_{i} + \dfrac{7}{8}\sum_{i,f}g_{i}
\end{align}$$
where the sum over $b$ is for bosons and $f$ for fermions and
$x_{i} = m_{i} / T_{d} = m_{i} / \xi T$. We can therefore see a concrete
lower bound on $\xi$ from the upper inequality:
$$\begin{align}
\left(h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})
\sum_{i}\eta_{i}g_{i}}\right)^{1/3}\xi_{\infty} &amp;lt; \xi
\end{align}$$
Here we defined $\eta_{i} = 1$ for bosons and $7/8$ for fermions. To get the
upper bound on $\xi$, we need to work a bit harder. First, we notice the the
lower bound on $\xi^3h_{d}$ is a sum of positive terms. Thus, we can simply
take one of the terms and retain the inequality. Let&amp;rsquo;s take the term with the
smallest mass. Let $x_{\ell}$ denote the term with the smallest mass.
Additionally, let $\tilde{x}_{\ell} = \xi x_{\ell} = m_{\ell}/T$. Then,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{45}{4\sqrt{2}\pi^{7/2}}g_{\ell}\tilde{x}_{\ell}^{5/2}\sqrt{\xi}e^{-\tilde{x}_{\ell}/\xi}
&amp;lt; h(T) \dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})}\xi_{\infty}^3
\end{align}$$
The solution to this inequality is a product-log, or the Lambert-W function:
$$\begin{align}
\xi &amp;lt;
\dfrac{2\tilde{x}_{\ell}}{W\left(\dfrac{2025 g_{\ell}^2 h(T_{\infty})^2 \tilde{x_{\ell}}^6}
{16 h_{d}(T_{d,\infty})^2 h(T)^2 \pi^7 \xi_{\infty}^2}\right)}
\end{align}$$&lt;/p&gt;
&lt;p&gt;For example&amp;rsquo;s sake let&amp;rsquo;s suppose that we have a two-component dark sector with
particles $\eta$ and $\Delta$ which have masses $m_{\eta}$ and $m_{\Delta}$. Let
$\Delta$ be a fermion and $\eta$ be a scalar. Suppose these particles interact
with eachother but not with the standard model. Assume that these particles are
in kinetic equilibrium with a temperature $T_{d}$. We would like to determine
$T_{d}$ given a standard model temperature $T$. Let the masses be given by:
$$\begin{align}
m_{\eta} &amp;amp;= \Lambda / \sqrt{N}\
m_{\Delta} &amp;amp;= \Lambda N
\end{align}$$
We will take from the &lt;code&gt;DarkSUN&lt;/code&gt; package the functions for thermodynamic
particles and the SM thermal functions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DarkSUN

mutable struct ToyModel
  η::ThermodynamicParticle
  Δ::ThermodynamicParticle
  sm::StandardModel
  ξ::Float64
  N::Float64
  Λ::Float64

  function ToyModel(Λ::Float64, N::Float64)
    η = ThermodynamicBoson(Λ/sqrt(N), 1.0)
    Δ = ThermodynamicFermion(Λ*sqrt(N), 1.0)
    sm = StandardModel()
    new(η, Δ, sm, NaN, N, Λ)
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, $\xi$ will be given by $T_{d}/T$. We will assume that the value of $\xi$
at large temperatures is 1. i.e., perhaps the dark and SM sectors we coupled at
very large temperatures but decoupled at some point. Given this model,
let&amp;rsquo;s write functions to compute the d.o.f. stored in entropy of the dark
sector:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function dark_dof_entropy(model::ToyModel)
  hη = dof_entropy(model.η)
  hΔ = dof_entropy(model.Δ)
  h::Float64 = isfinite(hη) ? hη : 0.0
  h += isfinite(hΔ) ? hΔ : 0.0
  h
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s now write a function to find the temperature of the dark sector using
a bisection routine:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Roots
using LambertW

function ξ_lower_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1);
  ξinf::Float64 = 1.0
  sumg::Float64 = model.η.g + model.Δ.g * 7/8
  cbrt(hsm * hdinf * ξinf^3 / (hsminf * sumg))
end

function ξ_upper_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1)
  ξinf::Float64 = 1.0
  xl::Float64 = model.η.mass / T
  gl::Float64 = model.η.g
  lw_arg_num::Float64 = 2025gl^2 * hsminf^2 * xl^6
  lw_arg_den::Float64 = 16hdinf^2 * hsm^2 * π^7 * ξinf^2
  2xl / lambertw(lw_arg_num / lw_arg_den)
end

function compute_ξ(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7/8 * 4model.N + 2.0 * (model.N^2 - 1)
  ξinf::Float64 = 1.0
  function residual(ξ::Float64)
    model.η.T = ξ * T
    model.Δ.T = ξ * T
    res::Float64 = dark_dof_entropy(model)*ξ^3 -hsm*hdinf*ξinf^3/hsminf
    return res
  end
  lb::Float64 = ξ_lower_bound(T, model)
  ub::Float64 = ξ_upper_bound(T, model)

  ξsol::Float64 = find_zero(residual, (lb*0.99, ub*1.01), Bisection())
  model.ξ = ξsol
  ξsol
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&amp;rsquo;s pick various values of $T$ and solve for $T_{d}$:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

model = ToyModel(10.0, 1.0)

Ts = 10 .^(range(-2, stop=2.0, length=100))
ξs = [compute_ξ(T, model) for T in Ts]
ξs_ub = [ξ_upper_bound(T, model) for T in Ts]
ξs_lb = [ξ_lower_bound(T, model) for T in Ts]

plt.figure(dpi=100)
plt.title(L&amp;quot;Evolution of $\xi$ With All Massive Species&amp;quot;)
plt.plot(Ts, ξs)
plt.plot(Ts, ξs_ub, &amp;quot;--&amp;quot;, label=&amp;quot;upper-bound&amp;quot;)
plt.plot(Ts, ξs_lb, &amp;quot;--&amp;quot;, label=&amp;quot;lower-bound&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$T \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.ylabel(L&amp;quot;$\xi(T)$&amp;quot;, fontsize=16)
plt.ylim([1e-1,1e2])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_465648c16ff17f05d638cef1b8af5af8.webp 400w,
               /post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_19c79573a4dd3bc451b4a5400efea480.webp 760w,
               /post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_ad933b263457463d2c623440241d445c.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_465648c16ff17f05d638cef1b8af5af8.webp&#34;
               width=&#34;584&#34;
               height=&#34;459&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We can therefore see that our bounds are correct and the root finding routine
correctly finds values of $\xi$ between these bounding curves. Additionally,
the value of $\xi$ is asymptotic to these bounding curves in the limits as
$T\to 0$ and $T\to\infty$. It is interesting to note the behavior of $\xi$ in
the limit as $T\to0$. We can see that $\xi$ exponentially grows, implies that
the dark sector becomes exponentially hot compared to the standard model. This
behavior does not continue forever, however. Once all of the dark sector
particles have left kinetic equilibrium, their temperatures will begin to drop
and simply red-shift away.&lt;/p&gt;
&lt;h2 id=&#34;case-2-one-massless-dark-sector-particle&#34;&gt;Case 2: One Massless Dark Sector Particle&lt;/h2&gt;
&lt;p&gt;The senario in which there exists at least on massless species is a bit simpler
than the case of all massive species. This is because the lower bound on
$\xi^3h_{d}$ is much simpler. In this case, the bounds on $\xi$ are:
$$\begin{align}
\left(h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})
\sum_{i}\eta_{i}g_{i}}\right)^{1/3}\xi_{\infty} &amp;lt; \xi &amp;lt;
\left(h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})
g_{\ell}}\right)^{1/3}\xi_{\infty}
\end{align}$$
Here we&amp;rsquo;ve take $g_{\ell}$ to be one of the massless species. If we have many
massless species, we can strengthen the lower bound by replacing $g_{\ell}$
with a sum over all massles species. Let&amp;rsquo;s modify our previous model by adding
in a massless particle.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function dark_dof_entropy(model::ToyModel)
  hη = dof_entropy(model.η)
  hΔ = dof_entropy(model.Δ)
  h::Float64 = isfinite(hη) ? hη : 0.0
  h += isfinite(hΔ) ? hΔ : 0.0
  h += 2.0 # massles vector boson
  h
end

function ξ_lower_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1) + 2.0;
  ξinf::Float64 = 1.0
  sumg::Float64 = model.η.g + model.Δ.g * 7/8 + 2.0
  cbrt(hsm * hdinf * ξinf^3 / (hsminf * sumg))
end

function ξ_upper_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1) + 2.0;
  ξinf::Float64 = 1.0
  sumg::Float64 = 2.0
  cbrt(hsm * hdinf * ξinf^3 / (hsminf * sumg))
end

function compute_ξ(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7/8 * 4model.N + 2.0 * (model.N^2 - 1) + 2.0
  ξinf::Float64 = 1.0
  function residual(ξ::Float64)
    model.η.T = ξ * T
    model.Δ.T = ξ * T
    res::Float64 = dark_dof_entropy(model)*ξ^3 -hsm*hdinf*ξinf^3/hsminf
    return res
  end
  lb::Float64 = ξ_lower_bound(T, model)
  ub::Float64 = ξ_upper_bound(T, model)

  ξsol::Float64 = find_zero(residual, (lb*0.99, ub*1.01), Bisection())
  model.ξ = ξsol
  ξsol
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s plot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

model = ToyModel(10.0, 1.0)

Ts = 10 .^(range(-2, stop=2.0, length=100))
ξs = [compute_ξ(T, model) for T in Ts]
ξs_ub = [ξ_upper_bound(T, model) for T in Ts]
ξs_lb = [ξ_lower_bound(T, model) for T in Ts]

plt.figure(dpi=100)
plt.title(L&amp;quot;Evolution of $\xi$ With a Massless Species&amp;quot;)
plt.plot(Ts, ξs)
plt.plot(Ts, ξs_ub, &amp;quot;--&amp;quot;, label=&amp;quot;upper-bound&amp;quot;)
plt.plot(Ts, ξs_lb, &amp;quot;--&amp;quot;, label=&amp;quot;lower-bound&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$T \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.ylabel(L&amp;quot;$\xi(T)$&amp;quot;, fontsize=16)
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_1cfafb771cd77b42bf735bd6eb1b3d44.webp 400w,
               /post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_e899de8ac5b52ef75346b2468ca2caf5.webp 760w,
               /post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_e8e876b2eb307f920c9ab8f1684cfe5a.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_1cfafb771cd77b42bf735bd6eb1b3d44.webp&#34;
               width=&#34;606&#34;
               height=&#34;459&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The behavior that we are seeing shouldn&amp;rsquo;t be too surprising. Our bounding
curves for $\xi$ are both proportional to $h(T)$. Therefore, $\xi$ simply
interpolates bewteen to different scalings of $h(T)$.&lt;/p&gt;
&lt;h2 id=&#34;case-3-sm-temperature-from-the-dark-temperature&#34;&gt;Case 3: SM Temperature from the Dark Temperature&lt;/h2&gt;
&lt;p&gt;Suppose we want to compute the tempertature of the SM in given the a dark
sector temperature. Then, we need to solve the following equation:
$$\begin{align}
\xi^3(T_{d}) = \dfrac{T_{d}^3}{T^3} = \dfrac{h(T)}{h_{d}(T_{d})}C_{\infty}
\end{align}$$
In this case, one should think of $T_{d}$ as a fixed number and $T$ being a
function of $T_{d}$. Isolating the constant pieces, we find:
$$\begin{align}
h(T)T^3 = \dfrac{T_{d}^3h_{d}(T_{d})}{C_{\infty}}
\end{align}$$
The LHS of this equation is constant. Let&amp;rsquo;s look at a plot $h(T)$ for the
SM.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DelimitedFiles
import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

sm_data = readdlm(string(@__DIR__) * &amp;quot;assets/data/smdof.csv&amp;quot;, &#39;,&#39;, skipstart=1)
sm_data_ts = sm_data[:, 1];
sm_data_hs = sm_data[:, 3];

plt.figure(dpi=100)
plt.plot(sm_data_ts, sm_data_hs)
plt.plot(sm_data_ts, [sm_data_hs[end] for _ in 1:length(sm_data_ts)], &amp;quot;k--&amp;quot;)
plt.plot(sm_data_ts, [sm_data_hs[1] for _ in 1:length(sm_data_ts)], &amp;quot;k--&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.ylabel(L&amp;quot;$h_{\mathrm{eff}}(T)$&amp;quot;, fontsize=16)
plt.xlabel(L&amp;quot;$T \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_0ee9f2531fadfe6013936d7924b40a12.webp 400w,
               /post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_d97dddc04d7e5e12feb3e8f9011b965c.webp 760w,
               /post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_c7838c58a55715770b7a77a8e37d4bc4.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_0ee9f2531fadfe6013936d7924b40a12.webp&#34;
               width=&#34;576&#34;
               height=&#34;442&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;From this plot, we can see that $h(T)$ is bounded from above and below. The
bounding values are:
$$\begin{align}
h_{\mathrm{min}} \approx 3.93 &amp;lt; h(T) &amp;lt; 106.83  \approx h_{\mathrm{max}}
\end{align}$$
It is therefore straight forward to find bounds on $T$:
$$\begin{align}
\dfrac{T_{d}^3h_{d}(T_{d})}{C_{\infty}h_{\mathrm{max}}} &amp;lt; T &amp;lt; \dfrac{T_{d}^3h_{d}(T_{d})}{C_{\infty}h_{\mathrm{min}}}
\end{align}$$
Given these bounds, one can use a bisection method to solve for $T$ given a
value for $T_{d}$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thermal Distribution Functions</title>
      <link>https://loganamorrison.github.io/post/thermal-distributions/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/thermal-distributions/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this notebook we wish to compute the thermal distribution functions for
fermions and bosons. The functions we wish to compute are the equilibirium
number, energy, pressure and entropy densities. In full form, these are given by:
$$\begin{align}
n(T) &amp;amp;= g\int\dfrac{d^3k}{(2\pi)^2}f(\mathbf{k})\\\
\rho(T) &amp;amp;= g\int\dfrac{d^3k}{(2\pi)^2}E(\mathbf{k})f(\mathbf{k})\\\
P(T) &amp;amp;= g\int\dfrac{d^3k}{(2\pi)^2}\dfrac{|\mathbf{k}|^2}{3E(\mathbf{k})}f(\mathbf{k})
\end{align}$$
with $g$ representing the number of internal degrees of freedom (d.o.f),
$E^2 = k^2 + m^2$ and $f(\mathbf{k})$ is the phase-space distribution
function. For a species in kinetic equilibirium, the phase space distribution
is given by:
$$\begin{align}
f(\mathbf{k}) &amp;amp;= \dfrac{1}{e^{E/T}\pm1}
\end{align}$$
where one takes the $+$ for fermions and $-$ for bosons. Note that we have
ignored the chemical potential in writing down $f$. Since $f(\mathbf{k})$ is
independent of angles, we can integrate of the solid angle and obtain:
$$\begin{align}
n(T) &amp;amp;= \dfrac{g}{2\pi^2}\int_{m}^{\infty} dE \dfrac{E\sqrt{E^2-m^2}}{e^{E/T}\pm1}\\
\rho(T) &amp;amp;= \dfrac{g}{2\pi^2}\int_{m}^{\infty} dE \dfrac{E^2\sqrt{E^2-m^2}}{e^{E/T}\pm1}\\
P(T) &amp;amp;= \dfrac{g}{6\pi^2}\int_{m}^{\infty} dE \dfrac{(E^2-m^2)^{3/2}}{e^{E/T}\pm1}
\end{align}$$
We can further simplify these functions by defining: $z = E / T$ and
$x = m / T$. Doing so, we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
n(T) &amp;amp;= gT^3\bar{n}_{\pm}(x)\\\
\rho(T) &amp;amp;= gT^4\bar{\rho}_{\pm}(x)\\\
P(T) &amp;amp;= gT^4\bar{P}_{\pm}(x)
\end{align}$$&lt;/p&gt;
&lt;p&gt;where we defined the &amp;lsquo;barred&amp;rsquo; quantities as:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\int_{x}^{\infty} dz \dfrac{z\sqrt{z^2-x^2}}{e^{z}\pm1}\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\int_{x}^{\infty} dz \dfrac{z^2\sqrt{z^2-x^2}}{e^{z}\pm1}\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{1}{6\pi^2}\int_{x}^{\infty} dz \dfrac{(z^2-x^2)^{3/2}}{e^{z}\pm1}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define functions for these quantities. We will negelect $g$ and factors
of $T$ for now since they only contribute scaling.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using QuadGK

&amp;quot;&amp;quot;&amp;quot;
  nbar(x, stats)

Integral representation of n̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function nbar(x::Float64, stats::Symbol)
  pf::Float64 = 1 / (2π^2)
  function integrand(z::Float64)
    if stats == :boson
      return z * sqrt(z^2 - x^2) / (exp(z) - 1)
    elseif stats == :fermion
      return z * sqrt(z^2 - x^2) / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  ρbar(x, stats)

Integral representation of ρ̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function ρbar(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return z^2 * sqrt(z^2 - x^2) / (exp(z) - 1)
    elseif stats == :fermion
      return z^2 * sqrt(z^2 - x^2) / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  pbar(x, stats)

Integral representation of p̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function pbar(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return (z^2 - x^2)^1.5 / (exp(z) - 1)
    elseif stats == :fermion
      return (z^2 - x^2)^1.5 / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return quadgk(integrand, x, Inf)[1] / (6π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s plot the results of these functions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

xs = 10 .^(range(-1, stop=1, length=100))
nbar_fermions = [nbar(x, :fermion) for x in xs]
ρbar_fermions = [ρbar(x, :fermion) for x in xs]
pbar_fermions = [pbar(x, :fermion) for x in xs]

nbar_bosons = [nbar(x, :boson) for x in xs]
ρbar_bosons = [ρbar(x, :boson) for x in xs]
pbar_bosons = [pbar(x, :boson) for x in xs]

plt.figure(dpi=100)
plt.plot(xs, nbar_fermions, label=L&amp;quot;$\bar{n}$ fermions&amp;quot;)
plt.plot(xs, ρbar_fermions, label=L&amp;quot;$\bar{\rho}$ fermions&amp;quot;)
plt.plot(xs, pbar_fermions, label=L&amp;quot;$\bar{P}$ fermions&amp;quot;)

plt.plot(xs, nbar_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ bosons&amp;quot;)
plt.plot(xs, ρbar_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ bosons&amp;quot;)
plt.plot(xs, pbar_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ bosons&amp;quot;)

plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
plt.ylim([1e-3, 1])
plt.xlim([1e-1, 1e1])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_0c5be179540cb710060d55ca9a1a83da.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_f2025a9262cabb33e865e6d373e033aa.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_0c5be179540cb710060d55ca9a1a83da.webp&#34;
               width=&#34;563&#34;
               height=&#34;440&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;There are a few things to take away from this plot. The first is that the
asymptotic behaviour as $x\to\infty$ is independent of statistics. The reseason
for this is clear: as $x\to\infty$, the integrand starts off with a very large
value of $z$ and hence, $e^{z} \gg \pm1$. The second thing to notice is that
the asymptotic behavior of $\bar{n}$ and $\bar{P}$ are identical, but they
differer from the asymptotic behavior of $\bar{\rho}$. The third thing to
notice is that the differences between fermions and bosons is small. We will
show why that&amp;rsquo;s the case later on.&lt;/p&gt;
&lt;h2 id=&#34;asymptotic-forms&#34;&gt;Asymptotic forms&lt;/h2&gt;
&lt;p&gt;The integrals for the number, energy and pressure densities can be evaluated
exactly for $x\ll 1$ and $x\gg1$. If we set $x = 0$, then the results are:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}(x) &amp;amp;= \dfrac{\zeta(3)}{\pi^2}
\begin{cases}
1 &amp;amp; \text{bosons}\\
3/4 &amp;amp; \text{fermions}
\end{cases}\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{\pi^2}{30}
\begin{cases}
1 &amp;amp; \text{bosons}\\
7/8 &amp;amp; \text{fermions}
\end{cases}\\
\bar{P}_{\pm}(x) &amp;amp;= \bar{\rho}/3
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In the opposite limit, we can simply ignore the statistics factors in the
denominators of the integral, obtaining:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}(x) &amp;amp;= e^{-x}\left(\frac{x}{2\pi}\right)^{3/2}\\
\bar{\rho}_{\pm}(x) &amp;amp;= xe^{-x}\left(\frac{x}{2\pi}\right)^{3/2}\\
\bar{P}_{\pm}(x) &amp;amp;= e^{-x}\left(\frac{x}{2\pi}\right)^{3/2}\\
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s check that these are correct:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using SpecialFunctions
nbar_small_x_b = zeta(3)/π^2
nbar_small_x_f = 3/4 * zeta(3)/π^2
ρbar_small_x_b = π^2/30
ρbar_small_x_f = 7/8 * π^2/30
pbar_small_x_b = π^2/90
pbar_small_x_f = 7/8 * π^2/90

nbar_large_x(x::Float64) = exp(-x) * (x/(2π))^1.5
ρbar_large_x(x::Float64) = x * exp(-x) * (x/(2π))^1.5
pbar_large_x(x::Float64) = exp(-x) * (x/(2π))^1.5
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=0, length=100))
nbar_fermions = [nbar(x, :fermion) for x in xs]
ρbar_fermions = [ρbar(x, :fermion) for x in xs]
pbar_fermions = [pbar(x, :fermion) for x in xs]

nbar_bosons = [nbar(x, :boson) for x in xs]
ρbar_bosons = [ρbar(x, :boson) for x in xs]
pbar_bosons = [pbar(x, :boson) for x in xs]

plt.figure(dpi=100)
plt.subplot(2, 2, 1)
plt.title(&amp;quot;Fermions&amp;quot;)
plt.plot(xs, nbar_fermions)
plt.plot(xs, ρbar_fermions)
plt.plot(xs, pbar_fermions)

plt.plot(xs, [nbar_small_x_f for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ small x&amp;quot;)
plt.plot(xs, [ρbar_small_x_f for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ small x&amp;quot;)
plt.plot(xs, [pbar_small_x_f for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ small x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.legend()

plt.subplot(2, 2, 2)
plt.title(&amp;quot;Bosons&amp;quot;)
plt.plot(xs, nbar_bosons)
plt.plot(xs, ρbar_bosons)
plt.plot(xs, pbar_bosons)
plt.plot(xs, [nbar_small_x_b for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ small x&amp;quot;)
plt.plot(xs, [ρbar_small_x_b for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ small x&amp;quot;)
plt.plot(xs, [pbar_small_x_b for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ small x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.legend()

xs = 10 .^(range(0, stop=1, length=100))
nbar_fermions = [nbar(x, :fermion) for x in xs]
ρbar_fermions = [ρbar(x, :fermion) for x in xs]
pbar_fermions = [pbar(x, :fermion) for x in xs]

nbar_bosons = [nbar(x, :boson) for x in xs]
ρbar_bosons = [ρbar(x, :boson) for x in xs]
pbar_bosons = [pbar(x, :boson) for x in xs]

plt.subplot(2, 2, 3)
plt.plot(xs, nbar_fermions)
plt.plot(xs, ρbar_fermions)
plt.plot(xs, pbar_fermions)
plt.plot(xs, [nbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ large x&amp;quot;)
plt.plot(xs, [ρbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ large x&amp;quot;)
plt.plot(xs, [pbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ large x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
plt.legend()

plt.subplot(2, 2, 4)
plt.plot(xs, nbar_bosons)
plt.plot(xs, ρbar_bosons)
plt.plot(xs, pbar_bosons)
plt.plot(xs, [nbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ large x&amp;quot;)
plt.plot(xs, [ρbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ large x&amp;quot;)
plt.plot(xs, [pbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ large x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
plt.legend()

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_c9684bc50574191847c61ad29ae76059.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_72e88b499117f4f3a991d3e1580dd733.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_c9684bc50574191847c61ad29ae76059.webp&#34;
               width=&#34;629&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;bessel-function-series-of-thermal-functions&#34;&gt;Bessel Function Series of Thermal Functions&lt;/h2&gt;
&lt;p&gt;The integrals for $\bar{n}(x), \bar{\rho}(x)$ and $\bar{P}(x)$ can be evaluated
exactly if one ignores the $\pm1$ in the denomiator of the integrands. This
suggests that one may be able to perform a series expansion of the denominator
in powers of $e^{-z}$ and evaluate the integrals exactly. This turns our to be
true. Note that:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{1}{e^{z}\pm1} &amp;amp;= \sum_{n=1}^{\infty}(\mp1)^{n+1}e^{-nz}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, the functions $\bar{n}(x), \bar{\rho}(x)$ and $\bar{P}(x)$ can be
written as:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}\int_{x}^{\infty} dz e^{-nz}z\sqrt{z^2-x^2}\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}\int_{x}^{\infty} dz e^{-nz}z^2\sqrt{z^2-x^2}\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{1}{6\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}\int_{x}^{\infty} dz e^{-nz}(z^2-x^2)^{3/2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;These integrals can be represented as modified bessel functions of the second
kind:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\dfrac{(\mp 1)^{n+1}}{n}K_{2}(nx)\\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp 1)^{n+1}}{n^2}\left[n x K_{1}(nx)+3K_{2}(nx)\right]\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp 1)^{n+1}}{n^2}K_{2}(nx)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s make functions for these sums:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using SpecialFunctions

&amp;quot;&amp;quot;&amp;quot;
  nbar_bessel(x, stats, order)

Sum-of-bessel function representation of n̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
-`order::Int64`: number of terms in series to keep
&amp;quot;&amp;quot;&amp;quot;
function nbar_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n * besselk(2, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n * besselk(2, n*x) for n in 1:order])
  end
  bsum * x^2 / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  ρbar_bessel(x, stats, order)

Sum-of-bessel function representation of ρ̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
-`order::Int64`: number of terms in series to keep
&amp;quot;&amp;quot;&amp;quot;
function ρbar_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n^2 * (n * x * besselk(1, n*x) +
                3 * besselk(2, n*x)) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n^2 * (n * x * besselk(1, n*x) +
                3 * besselk(2, n*x)) for n in 1:order])
  end
  bsum * x^2 / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  pbar_bessel(x, stats, order)

Sum-of-bessel function representation of p̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
-`order::Int64`: number of terms in series to keep
&amp;quot;&amp;quot;&amp;quot;
function pbar_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n^2 * besselk(2, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n^2 * besselk(2, n*x) for n in 1:order])
  end
  bsum * x^2 / (2π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s plot these functions and see that they are correct:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=log10(3), length=100))

nrows = 2
ncols = 3

plt.figure(dpi=100)
for nrow in 1:nrows
  stats = (nrow == 1) ? :boson : :fermion
  for ncol in 1:ncols
    plt.subplot(nrows, ncols, ncols * (nrow - 1) + ncol)
    if ncol == 1
      plt.title(L&amp;quot;$\bar{n}$ &amp;quot; * string(stats))
      exact = [nbar(x, stats) for x in xs]
      approx1 = [nbar_bessel(x, stats, 1) for x in xs]
      approx5 = [nbar_bessel(x, stats, 5) for x in xs]
    elseif ncol == 2
      plt.title(L&amp;quot;$\bar{p}$ &amp;quot; * string(stats))
      exact = [pbar(x, stats) for x in xs]
      approx1 = [pbar_bessel(x, stats, 1) for x in xs]
      approx5 = [pbar_bessel(x, stats, 5) for x in xs]
    elseif ncol == 3
      plt.title(L&amp;quot;$\bar{\rho}$ &amp;quot; * string(stats))
      exact = [ρbar(x, stats) for x in xs]
      approx1 = [ρbar_bessel(x, stats, 1) for x in xs]
      approx5 = [ρbar_bessel(x, stats, 5) for x in xs]
    end
    plt.plot(xs, exact, lw=3, alpha=0.6, label=&amp;quot;exact&amp;quot;)
    plt.plot(xs, approx1, &amp;quot;r--&amp;quot;, label=&amp;quot;n=1&amp;quot;)
    plt.plot(xs, approx5, &amp;quot;k--&amp;quot;, label=&amp;quot;n=1:5&amp;quot;)
    plt.yscale(&amp;quot;log&amp;quot;)
    plt.xscale(&amp;quot;log&amp;quot;)
    plt.xlim([minimum(xs), maximum(xs)])
    if ncol == 3 &amp;amp;&amp;amp; nrow == 2
      plt.legend()
    end
  end
end

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_20c01f773be2813f7de88a4d1b0c8d9c.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_ed9902173e7629aee4a42ec6c3bceba7.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_20c01f773be2813f7de88a4d1b0c8d9c.webp&#34;
               width=&#34;629&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;From these plots, we can see that even just the first term approximates the
thermal functions quite well. In practice, it is a good approximation to take:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}K_{2}(x)\\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\left[xK_{1}(x)+3K_{2}(x)\right]\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}K_{2}(x)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;These approximations have the added benifit of being independent of statistics.
The corrections for statistics come in when we include the second terms in the
sums. Let&amp;rsquo;s plot the percent errors when only including the first and second
terms in the series:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=log10(3), length=100))

nrows = 2
ncols = 3

plt.figure(dpi=100)
for nrow in 1:nrows
  stats = (nrow == 1) ? :boson : :fermion
  for ncol in 1:ncols
    plt.subplot(nrows, ncols, ncols * (nrow - 1) + ncol)
    if ncol == 1
      plt.title(L&amp;quot;$\bar{n}$ &amp;quot; * string(stats))
      exact = [nbar(x, stats) for x in xs]
      approx1 = [nbar_bessel(x, stats, 1) for x in xs]
      approx2 = [nbar_bessel(x, stats, 2) for x in xs]
      approx3 = [nbar_bessel(x, stats, 3) for x in xs]
    elseif ncol == 2
      plt.title(L&amp;quot;$\bar{p}$ &amp;quot; * string(stats))
      exact = [pbar(x, stats) for x in xs]
      approx1 = [pbar_bessel(x, stats, 1) for x in xs]
      approx2 = [pbar_bessel(x, stats, 2) for x in xs]
      approx3 = [pbar_bessel(x, stats, 3) for x in xs]
    elseif ncol == 3
      plt.title(L&amp;quot;$\bar{\rho}$ &amp;quot; * string(stats))
      exact = [ρbar(x, stats) for x in xs]
      approx1 = [ρbar_bessel(x, stats, 1) for x in xs]
      approx2 = [ρbar_bessel(x, stats, 2) for x in xs]
      approx3 = [ρbar_bessel(x, stats, 3) for x in xs]
    end
    if ncol == 1
      plt.ylabel(L&amp;quot;$\%$ error&amp;quot;)
    end
    plt.plot(xs, abs.(exact .- approx1) ./ exact .* 100, label=&amp;quot;n=1&amp;quot;)
    plt.plot(xs, abs.(exact .- approx2) ./ exact .* 100, label=&amp;quot;n=1:2&amp;quot;)
    plt.plot(xs, abs.(exact .- approx3) ./ exact .* 100, label=&amp;quot;n=1:3&amp;quot;)
    plt.xscale(&amp;quot;log&amp;quot;)
    #plt.yscale(&amp;quot;log&amp;quot;)
    plt.xlim([minimum(xs), maximum(xs)])
    plt.ylim([0, 20])
    if ncol == 1 &amp;amp;&amp;amp; nrow == 2
      plt.legend()
    end
  end
end

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_9f9bc5b6ead32807a3136cd0af00ccf8.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_7678a102ffa0784075419c1ca6b30629.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_9f9bc5b6ead32807a3136cd0af00ccf8.webp&#34;
               width=&#34;629&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;From these plots, we can see that we are always within 20% of the actual value
even when only including the first term in the series. We see rapid global
convergence when we begin including higher order terms.&lt;/p&gt;
&lt;h2 id=&#34;entropy-density&#34;&gt;Entropy Density&lt;/h2&gt;
&lt;p&gt;In addition to the number, pressure and energy density, one also typical cares
about the entropy density. It can be shown that the entropy density is given
by:
$$\begin{align}
s(T) &amp;amp;= \dfrac{\rho(T) + P(T)}{T} = gT^3(\bar{\rho}(x) + \bar{P}(x))
\end{align}$$
In integral form, this is:
$$\begin{align}
s(T) &amp;amp;= gT^3\bar{s}(x)
\end{align}$$
where&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{s}(x) &amp;amp;=  \bar{\rho}(x) + \bar{P}(x) = \dfrac{1}{6\pi^2}\int_{x}^{\infty} dz \dfrac{(4z^2-x^2)\sqrt{z^2-x^2}}{e^{z}\pm1}\
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In terms of bessel functions, this is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{s}(x) &amp;amp;= \dfrac{x^3}{2\pi^2}\sum_{n=1}^{\infty}\dfrac{(\mp1)^{n+1}}{n}K_{3}(nx)
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;degrees-of-freedom-stored-in-energy-and-entropy&#34;&gt;Degrees of Freedom Stored in Energy and Entropy&lt;/h2&gt;
&lt;p&gt;When dealing with many species of particles, it is often useful to define the
energy and entropy density in terms of a single function:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\rho(T) &amp;amp;= \sum_{i}\rho_{i}(T) = T^4\sum_{i}g_{i}\bar{\rho}_{i}(x) \equiv \dfrac{\pi^2}{30}g_{\mathrm{eff}}(T)T^4\\
s(T) &amp;amp;= \sum_{i}s_{i}(T) = T^3\sum_{i}g_{i}\bar{s}_{i}(x) \equiv \dfrac{2\pi^2}{45}h_{\mathrm{eff}}(T)T^3
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where the sum runs over all particles and the effective number of relativistic
d.o.f. stored in energy and entropy $g_{\mathrm{eff}}$, $h_{\mathrm{eff}}$ are:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
g_{\mathrm{eff}}(T) &amp;amp;= \dfrac{30}{\pi^2}\sum_{i}g_{i}\bar{\rho}_{i}(x)\\\
h_{\mathrm{eff}}(T) &amp;amp;= \dfrac{45}{2\pi^2}\sum_{i}g_{i}\bar{s}_{i}(x)
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;derivatives-of-thermal-functions&#34;&gt;Derivatives of Thermal Functions&lt;/h2&gt;
&lt;p&gt;Lastly, let&amp;rsquo;s investigate the derivatives of the various functions. The
derivatives are:
$$\begin{align}
\dfrac{dn}{dT} &amp;amp;= gT^2\left(3T\bar{n}(x)-x\dfrac{d\bar{n}}{dx}\right)\\\
\dfrac{d\rho}{dT} &amp;amp;= gT^3\left(4T\bar{\rho}(x)-x\dfrac{d\bar{\rho}}{dx}\right)\\\
\dfrac{dP}{dT} &amp;amp;= gT^3\left(4T\bar{P}(x)-x\dfrac{d\bar{P}}{dx}\right)\\\
\dfrac{ds}{dT} &amp;amp;= gT^2\left(3T\bar{s}(x)-x\dfrac{d\bar{s}}{dx}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;We will want to compute derivatives of the barred quantities. All of the barred
quantities are of the form:
$$\begin{align}
\int_{x}^{\infty}f(x,z)dz
\end{align}$$
Using Leibniz&amp;rsquo;s rule for differentiating integrals, one finds that:
$$\begin{align}
\dfrac{d}{dx}\int_{x}^{\infty}f(x,z)dz =
\int_{x}^{\infty}\dfrac{\partial f}{\partial x}dz - f(x, x)
\end{align}$$
Notice that all the integrand for our function evaluated at $z=x$ are zero.
Thus, we only need the integrate the derivative of the integrand w.r.t $x$. The
derivatives are:
$$\begin{align}
\dfrac{d\bar{n}}{dx} &amp;amp;= -\dfrac{x}{2\pi^2}\int_{x}^{\infty}\dfrac{z}{(e^{z}-1)\sqrt{z^2-x^2}}\\
\dfrac{d\bar{\rho}}{dx} &amp;amp;= -\dfrac{x}{2\pi^2}\int_{x}^{\infty}\dfrac{z^2}{(e^{z}-1)\sqrt{z^2-x^2}}\\
\dfrac{d\bar{P}}{dx} &amp;amp;= -\dfrac{x}{2\pi^2}\int_{x}^{\infty}\dfrac{\sqrt{z^2-x^2}}{(e^{z}-1)}
\end{align}$$
Let&amp;rsquo;s make some function for these and then invesigate how the look&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot;&amp;quot;&amp;quot;
  nbar_deriv(x, stats)

Derivative of the integral representation of n̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function nbar_deriv(x::Float64, stats::Symbol)
  pf::Float64 = 1 / (2π^2)
  function integrand(z::Float64)
    if stats == :boson
      return z / (exp(z) - 1) / sqrt(z^2 - x^2)
    elseif stats == :fermion
      return z / (exp(z) + 1) / sqrt(z^2 - x^2)
    else
      return 0.0
    end
  end
  return -x * quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  ρbar_deriv(x, stats)

Derivative of the integral representation of ρ̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function ρbar_deriv(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return z^2 / (exp(z) - 1) / sqrt(z^2 - x^2)
    elseif stats == :fermion
      return z^2 / (exp(z) + 1) / sqrt(z^2 - x^2)
    else
      return 0.0
    end
  end
  return -x * quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  pbar_deriv(x, stats)

Derivative of the integral representation of p̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function pbar_deriv(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return sqrt(z^2 - x^2) / (exp(z) - 1)
    elseif stats == :fermion
      return sqrt(z^2 - x^2) / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return -x * quadgk(integrand, x, Inf)[1] / (2π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s plot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=1, length=100))
nbar_deriv_fermions = [nbar_deriv(x, :fermion) for x in xs]
ρbar_deriv_fermions = [ρbar_deriv(x, :fermion) for x in xs]
pbar_deriv_fermions = [pbar_deriv(x, :fermion) for x in xs]

nbar_deriv_bosons = [nbar_deriv(x, :boson) for x in xs]
ρbar_deriv_bosons = [ρbar_deriv(x, :boson) for x in xs]
pbar_deriv_bosons = [pbar_deriv(x, :boson) for x in xs]

plt.figure(dpi=100)
plt.plot(xs, nbar_deriv_fermions, label=L&amp;quot;$d\bar{n}/dx$ fermions&amp;quot;)
plt.plot(xs, ρbar_deriv_fermions, label=L&amp;quot;$d\bar{\rho}/dx$ fermions&amp;quot;)
plt.plot(xs, pbar_deriv_fermions, label=L&amp;quot;$d\bar{P}/dx$ fermions&amp;quot;)

plt.plot(xs, nbar_deriv_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$d\bar{n}/dx$ bosons&amp;quot;)
plt.plot(xs, ρbar_deriv_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$d\bar{\rho}/dx$ bosons&amp;quot;)
plt.plot(xs, pbar_deriv_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$d\bar{P}/dx$ bosons&amp;quot;)

#plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
#plt.ylim([1e-3, 1])
plt.xlim([minimum(xs), maximum(xs)])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_4231ed3c7c141cc5856c48e0230a7515.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_7a917f034b7d92cb16be111d8f88bd80.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_4231ed3c7c141cc5856c48e0230a7515.webp&#34;
               width=&#34;570&#34;
               height=&#34;439&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Next, let&amp;rsquo;s investigate the sum-over-bessel function representation of the
derivatives. These are:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= -\dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}K_{1}(nx)\\\
\bar{\rho}_{\pm}(x) &amp;amp;= -\dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp1)^{n+1}}{n}\left[nxK_{0}(nx)+K_{1}(nx)\right]\\
\bar{P}_{\pm}(x) &amp;amp;= -\dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp1)^{n+1}}{n}K_{1}(nx)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s make functions for these:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using SpecialFunctions

function nbar_deriv_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) * besselk(1, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([besselk(1, n*x) for n in 1:order])
  end
  -bsum * x^2 / (2π^2)
end

function ρbar_deriv_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n * (n * x * besselk(0, n*x) +
                besselk(1, n*x)) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n * (n * x * besselk(0, n*x) +
                besselk(1, n*x)) for n in 1:order])
  end
  -bsum * x^2 / (2π^2)
end

function pbar_deriv_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n * besselk(1, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n * besselk(1, n*x) for n in 1:order])
  end
  -bsum * x^2 / (2π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s plot to compare:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-2, stop=1, length=100))

nrows = 2
ncols = 3

plt.figure(dpi=100)
for nrow in 1:nrows
  stats = (nrow == 1) ? :boson : :fermion
  for ncol in 1:ncols
    plt.subplot(nrows, ncols, ncols * (nrow - 1) + ncol)
    if ncol == 1
      plt.title(L&amp;quot;$\bar{n}$ &amp;quot; * string(stats))
      exact = [nbar_deriv(x, stats) for x in xs]
      approx1 = [nbar_deriv_bessel(x, stats, 1) for x in xs]
      approx5 = [nbar_deriv_bessel(x, stats, 5) for x in xs]
    elseif ncol == 2
      plt.title(L&amp;quot;$\bar{p}$ &amp;quot; * string(stats))
      exact = [pbar_deriv(x, stats) for x in xs]
      approx1 = [pbar_deriv_bessel(x, stats, 1) for x in xs]
      approx5 = [pbar_deriv_bessel(x, stats, 5) for x in xs]
    elseif ncol == 3
      plt.title(L&amp;quot;$\bar{\rho}$ &amp;quot; * string(stats))
      exact = [ρbar_deriv(x, stats) for x in xs]
      approx1 = [ρbar_deriv_bessel(x, stats, 1) for x in xs]
      approx5 = [ρbar_deriv_bessel(x, stats, 5) for x in xs]
    end
    plt.plot(xs, exact, lw=3, alpha=0.6, label=&amp;quot;exact&amp;quot;)
    plt.plot(xs, approx1, &amp;quot;r--&amp;quot;, label=&amp;quot;n=1&amp;quot;)
    plt.plot(xs, approx5, &amp;quot;k--&amp;quot;, label=&amp;quot;n=1:5&amp;quot;)
    #plt.yscale(&amp;quot;log&amp;quot;)
    plt.xscale(&amp;quot;log&amp;quot;)
    plt.xlim([minimum(xs), maximum(xs)])
    if ncol == 3 &amp;amp;&amp;amp; nrow == 2
      plt.legend()
    end
  end
end

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_c4c4aab3029047290b566181e1f27c16.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_abc42e1d5887aa3a7bd57b7b77d60670.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_c4c4aab3029047290b566181e1f27c16.webp&#34;
               width=&#34;630&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Melanopogenesis: dark matter of (almost) any mass and baryonic matter from the evaporation of primordial black holes weighing a ton (or less)</title>
      <link>https://loganamorrison.github.io/publication/melanopogenesis-2019/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/melanopogenesis-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://loganamorrison.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rutherford Scattering</title>
      <link>https://loganamorrison.github.io/post/rutherford-scattering/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/rutherford-scattering/</guid>
      <description>&lt;h2 id=&#34;classical-calculation&#34;&gt;Classical Calculation&lt;/h2&gt;
&lt;p&gt;$\require{cancel}$
$\newcommand{\bra}[1]{\left&amp;lt; #1 \right|}$
$\newcommand{\ket}[1]{\left| #1 \right&amp;gt;}$
$\newcommand{\bk}[2]{\left&amp;lt; #1 \middle| #2 \right&amp;gt;}$
$\newcommand{\bke}[3]{\left&amp;lt; #1 \middle| #2 \middle| #3 \right&amp;gt;}$
$\newcommand{\Tr}{\mathrm{Tr}}$&lt;/p&gt;
&lt;p&gt;We consider a charged particle of mass $m$ scattering off a heavy
nucleus. Let the impact parameter be $b$ and the energy of the impinging
particle be $E$. The classical Lagrangian for a particle with charge $e$
scattering off a heavy nucleus of charge $eZ$ is:
$$\begin{align}
\mathcal{L}= T - V = \dfrac{1}{2}m \left(\dfrac{d\mathbf{r}}{dt}\right)^2 - V(r)
\end{align}$$
with
$$\begin{align}
V(r) = \dfrac{e^2Z}{4\pi r}
\end{align}$$
In the plane of scattering, we need only to consider two variables - $|\mathbf{r}| = r$ and $\theta$. We can write the derivative of $\mathbf{r}$ as:
$$\begin{align}
\dfrac{d\mathbf{r}}{dt} = \dfrac{dr}{dt}\hat{\mathbf{r}} + r \dfrac{d\theta}{dt}\hat{\mathbf{\theta}}
\end{align}$$
Our Lagrangian then reads:
$$\begin{align}
\mathcal{L}= \dfrac{1}{2}m \left(\left(\dfrac{dr}{dt}\right)^2 + r^2 \left(\dfrac{d\theta}{dt}\right)^2\right) - \dfrac{e^2Z}{4\pi r}
\end{align}$$
The Euler-Lagrange equation of $\theta$ reads:
$$\begin{align}
0 = \dfrac{\partial\mathcal{L}}{d\theta} = \dfrac{d}{dt}\dfrac{\partial\mathcal{L}}{\partial\dot{\theta}} = \dfrac{d}{dt}mr^2\dot{\theta}
\end{align}$$
Hence, $mr^2\dot{\theta}$ is a constant, which is the angular momentum,
$L = b\sqrt{2mE}$. Therefore,
$$\begin{align}
\dfrac{d\theta}{dt} = \dfrac{L}{mr^2}
\end{align}$$
By energy conservation, we can write
$$\begin{align}
E = \dfrac{1}{2}m \left(\left(\dfrac{dr}{dt}\right)^2 + r^2 \left(\dfrac{d\theta}{dt}\right)^2\right) + \dfrac{e^2Z}{4\pi r}
\end{align}$$
We can readily solve this equation for the time derivative of $r$,
obtaining:
$$\begin{align}
\dfrac{dr}{dr} = \dfrac{1}{mr}\sqrt{2mEr^2 - \dfrac{e^2Zm}{2\pi}r - L^2}
\end{align}$$
We can write
$$\begin{align}
\dfrac{d\theta}{dt} = \dfrac{d\theta}{dr}\dfrac{dr}{dt} = \dfrac{L}{mr^2}
\end{align}$$
Therefore,
$$\begin{align}
\dfrac{d\theta}{dr} = \dfrac{L}{mr^2}\left(\dfrac{dr}{dt}\right)^{-1} = \dfrac{L}{r\sqrt{2mEr^2 - \dfrac{e^2Zm}{2\pi}r - L^2}}
\end{align}$$
This equation can be integrated to obtain the final value of $\theta$.
We would want to integrate this equation over $\infty\to\infty$. We can
instead integrate this equation over $r_{0}\to\infty$ where $r_0$ is the
minimum value of $r$. The minimum value of $r$ will occur when
$dr/dt = 0$, which happens when
$$\begin{align}
2mEr^2 - \dfrac{e^2Zm}{2\pi}r - L^2 = 0
\end{align}$$
We can solve this equation by completing the square:
$$\begin{align}
r_0 = \dfrac{e^2Z}{8\pi E} + \sqrt{\dfrac{L^2}{2mE} + \dfrac{e^4Z^2}{64\pi^2 E^2}} = A + \sqrt{A^2 + b^2}
\end{align}$$
where
$$\begin{align}
A &amp;amp; = \dfrac{e^2Z}{8\pi E}
\end{align}$$
Given these definitions,
$$\begin{align}
\theta(\infty)-\theta(r_{0}) = \int_{r_{0}}^{\infty}dr \dfrac{b}{r\sqrt{(r-A)^2-A^2-b^2}}
\end{align}$$
Integrating this give us:
$$\begin{align}
\theta(\infty)-\theta(r_{0}) = -\dfrac{\pi}{2} - i\log(\dfrac{-b+iA}{\sqrt{A^2+b^2}})
\end{align}$$
If we rotate our system such that $\theta(r_0) = \pi/2$ (which sends
$\theta\to\theta/2$), then we find that
$$\begin{align}
\sin(\theta/2) = \dfrac{A}{\sqrt{A^2+b^2}}
\end{align}$$
We thus find that
$$\begin{align}
b = A\cot(\theta/2)
\end{align}$$
This implies that the impact parameter as a function of $\theta$ is
$$\begin{align}
b = \dfrac{e^2Z}{8\pi E\tan(\theta/2)}
\end{align}$$
Recall that the differential scattering cross-sections is
$$\begin{align}
\dfrac{d\sigma}{d\Omega} = \dfrac{b}{\sin\theta}\dfrac{db}{d\theta}
\end{align}$$
we find that
$$\begin{align}
\dfrac{d\sigma}{d\Omega} = \dfrac{e^4Z^2}{256\pi^2E^2\sin^4(\theta/2)} = \dfrac{\alpha^2Z^2}{16E^2\sin^4(\theta/2)} = \dfrac{\alpha^2Z^2}{4m^2v_i^2\sin^4(\theta/2)}
\end{align}$$
where $\alpha = e^2/4\pi$.&lt;/p&gt;
&lt;h2 id=&#34;quantum-field-theory-calculation&#34;&gt;Quantum Field Theory Calculation&lt;/h2&gt;
&lt;p&gt;In this section, we will investigate Rutherford Scattering through the
point of view of quantum field theory. We will consider the electron and
positron as dynamic fields and the photon field as static. The
Lagrangian we will consider is
$$\begin{align}
\mathcal{L}= \overline{\Psi}\left(i\cancel{\partial}-m\right)\Psi
-eA_{\mu}\overline{\Psi}\gamma^{\mu}\Psi
\end{align}$$
Our goal will be to calculate the differential cross-section
$\dfrac{d\sigma}{d\Omega}$ for an electron scattering of the static
potential. The $T$ matrix element for this process, to first order in
the electromagnetic coupling constant, is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p}
&amp;amp; = \bra{p&amp;rsquo;,s&amp;rsquo;}T\exp\left[-i\int d^4x \mathcal{L}_{I}(x)\right]\ket{p,s} \\
&amp;amp; = ie\int d^4x \bra{p&amp;rsquo;,s&amp;rsquo;}A_{\mu}(x)\overline{\Psi}(x)\gamma^{\mu}\Psi(x)\ket{p,s}+
\mathcal{O}(e^2)\\\
&amp;amp; = ie\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)
\int d^4xA_{\mu}(x)e^{i(p&amp;rsquo;-p)x}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now Fourier transform the photon field:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
A_{\mu}(x) = \int \dfrac{d^4q}{(2\pi)^4}\tilde{A}_{\mu}(q)e^{-iqx}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Inserting this into the expression for the $T$-matrix element, we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p}
&amp;amp; = ie\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)
\int d^4x\int \dfrac{d^4q}{(2\pi)^4}
\tilde{A}_{\mu}(q)e^{i(p&amp;rsquo;-p-q)x}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Integrating over $x$ will produce a factor of $(2\pi)^4\delta^4(p&amp;rsquo;-p-q)$. We can then integrate over $q$ using this delta function, producing&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p}
&amp;amp; = ie\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)\tilde{A}_{\mu}(p&amp;rsquo;-p)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, suppose the photon field is time-independent. Then, the fourier
transform of the photon field is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\tilde{A}_{\mu}(p&amp;rsquo;-p) &amp;amp; = \int d^3zA_{\mu}(\mathbf{z}) e^{i(\mathbf{p}&amp;rsquo;-\mathbf{p})\cdot\mathbf{z}}\int_{-\infty}^{\infty}dt&amp;rsquo;e^{i(E_{p&amp;rsquo;}-E_{p})t&amp;rsquo;}\\
&amp;amp; = (2\pi)\delta(E_{p&amp;rsquo;}-E_{p})\int d^3zA_{\mu}(\mathbf{z})
e^{i(\mathbf{p}&amp;rsquo;-\mathbf{p})\cdot\mathbf{z}}
\end{align}$$&lt;/p&gt;
&lt;p&gt;We now define the matrix element as&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p} = (2\pi)i\delta(E_{p&amp;rsquo;}-E_{p})\mathcal{M}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Through this definition, we can see that $\mathcal{M}$ is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\mathcal{M}= e\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)
\tilde{A}_{\mu}(\mathbf{p}&amp;rsquo;-\mathbf{p})
\end{align}$$&lt;/p&gt;
&lt;p&gt;where it is understood that $E_{p&amp;rsquo;} = E_{p}$. Let&amp;rsquo;s square this matrix element and average over the initial spin and sum over final spin of the electron:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\sum_{s,s&amp;rsquo;}\left|\mathcal{M}\right|^2
&amp;amp; =\dfrac{1}{2}e^2\tilde{A}_{\mu}\tilde{A}_{\nu}
\Tr\left[\left(\cancel{p}&amp;rsquo;+m\right)\gamma^{\mu}
\left(\cancel{p}+m\right)\gamma^{\nu}\right]\\
&amp;amp; =\dfrac{1}{2}e^2\tilde{A}_{\mu}\tilde{A}_{\nu}
\left(\Tr\left[\cancel{p}&amp;rsquo;\gamma^{\mu}\cancel{p}\gamma^{\nu}\right]
+m^2\Tr\left[\gamma^{\mu}\gamma^{\nu}\right]\right)\\\
&amp;amp; = 2e^2\tilde{A}_{\mu}\tilde{A}_{\nu}
\left(p&amp;rsquo;^{\mu}p^{\nu}+p&amp;rsquo;^{\nu}p^{\mu}-(p&amp;rsquo;\cdot p)g^{\mu\nu}
+m^2g^{\mu\nu}\right)\\\
&amp;amp; = 2e^2\left[2\left(\tilde{A}\cdot p&amp;rsquo;\right)\left(\tilde{A}\cdot p\right)
+(m^2-p&amp;rsquo;\cdot p)\left(\tilde{A}\cdot\tilde{A}\right)\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s assume that the four-potential is generated by a charged
particle of charge $Ze$. Then, the vector potential is given by&lt;/p&gt;
&lt;p&gt;$$\begin{align}
A^0(\mathbf{x}) = \dfrac{Ze}{4\pi r} \qquad \text{and}\qquad\mathbf{A}(\mathbf{x}) = 0
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $r = \left|\mathbf{x}\right|$. Now, let&amp;rsquo;s compute the fourier transform of
this potential. To do so, we need to regulate the integrate. We modify
it in the following way:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
A^0(\mathbf{x}) = \dfrac{Ze}{4\pi r}e^{-\lambda r}
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $\lambda$ will be taken to zero at the end of the calculation. The
Fourier transform of this vector potential is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\tilde{A}^0(k)
&amp;amp;= \int d^3\mathbf{x}\dfrac{Ze}{4\pi r}e^{-\lambda r}e^{i k r\cos(\theta)}\\
&amp;amp;= \dfrac{Ze}{2}\int_{0}^{\infty}dr\int_{-1}^{1}d(\cos\theta)re^{-\lambda r}
e^{i k r\cos(\theta)}\\
&amp;amp;= \dfrac{Ze}{2ik}\left[\dfrac{e^{(ik-\lambda) r}}{ik-\lambda}+
\dfrac{e^{(-ik-\lambda) r}}{ik+\lambda}\right]_{0}^{\infty}\\
&amp;amp;= -\dfrac{Ze}{2ik}\left[\dfrac{(-ik-\lambda)+(-ik+\lambda)}{k^2+\lambda^2}\right]\\
&amp;amp; = \dfrac{Ze}{k^2+\lambda^2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $k = |\mathbf{p}&amp;rsquo;-\mathbf{p}|$. Taking $\lambda$ to zero, we obtain&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\tilde{A}^0(\mathbf{p}&amp;rsquo;-\mathbf{p}) = \dfrac{Ze}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s use this to simplify the matrix element. The matrix element is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\sum_{s,s&amp;rsquo;}\left|\mathcal{M}\right|^2
&amp;amp; = 2e^2
\left[2 \dfrac{Z^2e^2E_iE_f}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}
+(m^2-E_iE_f+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;)
\dfrac{Z^2e^2}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}\right]\\
&amp;amp; =  \dfrac{2Z^2e^4}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}
\left[E_iE_f+m^2+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;We are now ready to compute the differential cross section. The
differential cross section is given by&lt;/p&gt;
&lt;p&gt;$$\begin{align}
d\sigma = \dfrac{1}{2E_iv_i}\dfrac{d^3p_f}{(2\pi)^3(2E_f)}
(2\pi)\delta(E_f-E_i)\left|\mathcal{M}\right|^2
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
p_f^2 dp_fd\Omega = p_fE_fdE_fd\Omega
\end{align}$$&lt;/p&gt;
&lt;p&gt;(where $p_f$ and $p_i$ are the magnitude of the initial and final momentum
respectively,) and integrating over $E_f$, we obtain $E_f=E_i=E$ and
$p_f = p_i$. Thus, the differential cross section is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{d\sigma}{d\Omega}
= \dfrac{1}{4Ev_i(2\pi)^2}
\dfrac{2Z^2e^4}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}p_f
\left[E^2+m^2+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let $\theta$ be the angle between $\mathbf{p}&amp;rsquo;$ and $\mathbf{p}$. Then,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4 &amp;amp; = \left(p_i^2+p_f^2-2p_fp_i\cos\theta\right)^2 \\
&amp;amp; = \left(2p_i^2-2p_i^2\cos\theta\right)^2       \\
&amp;amp; = 4p_i^4\left(1-\cos\theta\right)^2            \\
&amp;amp; = 16p_i^4\sin^4(\theta/2)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, in the non-relativistic limit, the momentum is $p_i=mv_i$ and $E=m$.
Hence, the differential cross section is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{d\sigma}{d\Omega}
&amp;amp; = \dfrac{1}{4mv_i(2\pi)^2}
\dfrac{2Z^2e^4mv_i}{(16)m^4v_i^4\sin^4(\theta/2)}
\left[E^2+m^2+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;\right]\\
&amp;amp; = \dfrac{1}{8\pi^2}
\dfrac{Z^2e^4}{(16)m^4v_i^4\sin^4(\theta/2)}
\left[2m^2+m^2v_i^2\cos\theta\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;Since $v_i\ll 1$, we find that&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{d\sigma}{d\Omega}
&amp;amp; =\dfrac{Z^2\alpha^2}{4m^2v_i^4\sin^4(\theta/2)}
\end{align}$$&lt;/p&gt;
&lt;p&gt;where we used $e^2=4\pi\alpha$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Project</title>
      <link>https://loganamorrison.github.io/project/example/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/project/example/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>High performance organic field-effect transistors using ambient deposition of tetracene single crystals</title>
      <link>https://loganamorrison.github.io/publication/ovls-2016/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/publication/ovls-2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://loganamorrison.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
