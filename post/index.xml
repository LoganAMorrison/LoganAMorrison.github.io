<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Logan A. Morrison</title>
    <link>https://loganamorrison.github.io/post/</link>
      <atom:link href="https://loganamorrison.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 11 Mar 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://loganamorrison.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://loganamorrison.github.io/post/</link>
    </image>
    
    <item>
      <title>Using jax to integrate N-body phase space</title>
      <link>https://loganamorrison.github.io/post/jax-phase-space/</link>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/jax-phase-space/</guid>
      <description>&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-algorithm-rambo&#34;&gt;The algorithm: RAMBO&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#1-generate-qmu_i&#34;&gt;(1) Generate $q^{\mu}_{i}$&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#2-boost-generate-pmu_i&#34;&gt;(2) Boost: generate $p^{\mu}_{i}$&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#3-correct-the-masses-generate-kmu_i&#34;&gt;(3) Correct the masses: generate $k^{\mu}_{i}$&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#4-computing-the-weight&#34;&gt;(4) Computing the weight&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-jax-implementation&#34;&gt;The Jax implementation&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#example-muon-decay-mupm-to-epm--nu_mu--nu_e&#34;&gt;Example: Muon decay $\mu^{\pm} \to e^{\pm} + \nu_{\mu} + \nu_{e}$&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In phenomenological studies of quantum field theory, it is very common compute
cross sections or decay widths of some annihilation or decay process. These computations
require evaluation of an integral over phase space. For a process with an initial state
of momentum $P$ and transitioning into a final state with $N$ particles with momenta
$p_{1},\dots,p_{N}$, the phase space integral is:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \mathrm{LIPS} &amp;= \qty(\prod_{i=1}^{N}\int\frac{\dd[3]{\boldsymbol{p}_{i}}}{(2\pi)^{3}2E_{i}})\qty(2\pi)^{4}\delta^{4}
    \qty(P-\sum_{i=1}^{N}p_{i})\abs{\mathcal{M}}^{2}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;with $E_{i}$ being the energy of the $i^{\mathrm{th}}$ final state particle, and
$\mathcal{M}$ the matrix element for the process. When the process includes more
than two or three particles in the final state, computing the cross section or
width becomes difficult. In these cases, we often need to resort to numerical
integration. However, standard quadrature techniques are often much too slow.
The standard approach is to use Monte Carlo integration (often with importance
sampling, stratified sampling or other techniques.) For these integration to be
reasonably fast, the code needs to be written is a compiled (or just-in-time
compiled) language.&lt;/p&gt;
&lt;p&gt;In this post, we will investigate how well the &lt;code&gt;jax&lt;/code&gt; library does in performing this
integration. We will compare the &lt;code&gt;jax&lt;/code&gt; implementation to an equivalent &lt;code&gt;numpy&lt;/code&gt;
implementation as well as a multi-threaded &lt;code&gt;c++&lt;/code&gt; implementation. This post is organized
as follows. First, we introduce the algorithm used to perform the integration. We then
present the &lt;code&gt;jax&lt;/code&gt; implemenation of the algorithm and demonstate with a simple example.
Lastly, we show some simple benchmarks between &lt;code&gt;jax&lt;/code&gt;, &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-algorithm-rambo&#34;&gt;The algorithm: RAMBO&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;RAMBO&lt;/code&gt; algorithm is rather simple. At a high-level, the algorithm is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generate $N$ massless, isotropic momenta $q_{i}$ with energy components distributed according to $q^{0}_{i} \exp(-q^{0}_{i})$.&lt;/li&gt;
&lt;li&gt;Lorentz boost the $q_{i}$, producing new massless momenta $p_{i}$ which conserve momenta and have the correct center-of-mass energy.&lt;/li&gt;
&lt;li&gt;Rescale the $p_{i}$, producing new momenta $k_{i}$ which have correct masses.&lt;/li&gt;
&lt;li&gt;Compute the weight of the phase-space point.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In our first step, we enforce the energies to be distributed according to
$q^{0}_{i} \exp(-q^{0}_{i})$ simply because it results in a simple measure,
making the calculation of the phase space density easy. Steps two and three are
done in such a way that the calculation of the phase space density in the final
step is straight forward.&lt;/p&gt;
&lt;p&gt;Without much explanation, we will give the detailed algorithm.&lt;/p&gt;
&lt;h3 id=&#34;1-generate-qmu_i&#34;&gt;(1) Generate $q^{\mu}_{i}$&lt;/h3&gt;
&lt;p&gt;To generate the $q_{i}$, choose $4N$ random numbers:
$\rho^{(1)}_{i}, \rho^{(2)}_{i}, \rho^{(3)}_{i}, \rho^{(4)}_{i}$. The $q_{i}$&amp;rsquo;s
are then:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    q^{0}_{i} &amp;= e_{i}, &amp; 
    q^{1}_{i} &amp;= e \cos(\phi_{i}) \sqrt{1 - z_{i}^{2}}, &amp;
    q^{2}_{i} &amp;= e \sin(\phi_{i}) \sqrt{1 - z_{i}^{2}}, &amp;
    q^{3}_{i} &amp;= e \cos(\theta_{i}).\\
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;with $e$, $z_{i}$ and $\phi_{i}$ given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    e &amp;= -\log(\rho^{(3)}_{i} \rho^{(4)}_{i}), &amp;
    z_{i} &amp;= 2\rho^{(1)}_{i}-1, &amp;
    \phi &amp;= 2\pi \rho^{(2)}_{i}
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;2-boost-generate-pmu_i&#34;&gt;(2) Boost: generate $p^{\mu}_{i}$&lt;/h3&gt;
&lt;p&gt;The boosted momenta are:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    p^{0}_{i} &amp;= x \qty(\gamma q^{0}_{i} + \boldsymbol{b}\cdot\boldsymbol{q}_{i}), &amp;
    \boldsymbol{p}_{i} &amp;= x \qty(\qty(a \boldsymbol{b}\cdot\boldsymbol{q}_{i} + q_{i}^{0}) \boldsymbol{b} + \boldsymbol{q}_{i}). 
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where the various undeclared variables are:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    x &amp;= E\_{\mathrm{cme}} / M, &amp;
    \gamma &amp; = Q^{0} / M, &amp;
    a &amp;= \frac{1}{1+\gamma}, \\
    Q &amp;= \sum_{j=1}^{N}q_{i}, &amp; 
    M &amp;= \sqrt{Q\cdot Q}, &amp;
    \boldsymbol{b} &amp;= -\frac{1}{M}\mqty(Q^{1} &amp; Q^{2} &amp; Q^{3}).
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;3-correct-the-masses-generate-kmu_i&#34;&gt;(3) Correct the masses: generate $k^{\mu}_{i}$&lt;/h3&gt;
&lt;p&gt;The $k^{\mu}_{i}$ are computed using:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    k^{0}_{i} &amp;= \sqrt{\qty(\xi p^{0}_{i})^2 + m_{i}^{2}}, &amp;
    \boldsymbol{k}_{i} &amp;= \xi \boldsymbol{p}_{i}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where $\xi$ is the solution to:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    0 = E_{\mathrm{cm}} - \sum_{j=1}^{N}\sqrt{m_{j}^{2} + \qty(\xi p_{j}^{0})^{2}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;This equation can be solved using Newton or Halley iterations. Typically it converges in a few steps.&lt;/p&gt;
&lt;h3 id=&#34;4-computing-the-weight&#34;&gt;(4) Computing the weight&lt;/h3&gt;
&lt;p&gt;The weight is computed using&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    w &amp;= \frac{\qty(\frac{\pi}{2})^{N-1} \qty(E_{\mathrm{cm}})^{2N-3} \qty(2\pi)^{4-3N}}{(N-1)! (N-2)!}
    {\qty(\sum_{j=1}^{N}\frac{\abs{\boldsymbol{k}_{j}}}{E_{\mathrm{cm}}})}
    {\qty(\sum_{j=1}^{N}\frac{\abs{\boldsymbol{k}_{j}}^{2}}{k^{0}_{i}})}^{-1}
    {\qty(\prod_{j=1}^{N}\frac{\abs{\boldsymbol{k}_{j}}}{k^{0}_{i}})}
\end{align}
$$
&lt;/p&gt;
&lt;h2 id=&#34;the-jax-implementation&#34;&gt;The Jax implementation&lt;/h2&gt;
&lt;p&gt;Implementing the aforementioned algorithm using &lt;code&gt;jax&lt;/code&gt; is definitely a learning
experience on how to use &lt;code&gt;jax&lt;/code&gt;. If you&amp;rsquo;re familiar with &lt;code&gt;jax&lt;/code&gt;, the
implementation is a breeze. We will be writing a few function that will make the
functions we need to implement the algorithm. Before we get into it, let&amp;rsquo;s explain
the general structure of the function we will make.&lt;/p&gt;
&lt;p&gt;Each function we will construct will work on a tensor of shape $(4, N, M)$,
where $N$ is the number of final state particles and $M$ is the size of a batch
to be worked on. If &lt;code&gt;p&lt;/code&gt; is the tensor, then &lt;code&gt;p[0,:,:]&lt;/code&gt; holds the energies while
&lt;code&gt;p[1,:,:], p[3,:,:], p[4,:,:]&lt;/code&gt; hold the $x,y$ and $z$ component&amp;rsquo;s of the
3-momentum. The &lt;code&gt;p[:,0,:],...,p[:,N-1,:]&lt;/code&gt; are the moment for particles &lt;code&gt;1-N&lt;/code&gt;.
The last dimension contains the batch.&lt;/p&gt;
&lt;p&gt;All we will need to import is &lt;code&gt;jax&lt;/code&gt; and the &lt;code&gt;math&lt;/code&gt; module.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import jax
import jax.numpy as jnp
import math
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate the $q^{\mu}_{i}$, we will create a function that takes in the
number of final state particles and the batch size and return the function to
compute the momenta.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_momenta_initializer(n: int, batch_size: int):
    def init(key):
        keys = jax.random.split(key, 4)
        rho1 = jax.random.uniform(keys[0], shape=(n, batch_size))
        rho2 = jax.random.uniform(keys[1], shape=(n, batch_size))
        rho3 = jax.random.uniform(keys[2], shape=(n, batch_size))
        rho4 = jax.random.uniform(keys[3], shape=(n, batch_size))

        ctheta = 2 * rho1 - 1.0
        stheta = jnp.sqrt(1.0 - ctheta ** 2)
        phi = 2.0 * jnp.pi * rho2
        e = -jnp.log(rho3 * rho4)

        return jnp.array(
            [e, e * stheta * jnp.cos(phi), e * stheta * jnp.sin(phi), e * ctheta]
        )

    return jax.jit(init)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we write a function to make the boosting function. We given the center-of-mass energy,
this is a simple translation of the expressions given above.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_momenta_boost(cme):
    def boost(ps):
        sum_ps = jnp.sum(ps, axis=1)
        inv_mass = jnp.sqrt(
            sum_ps[0] ** 2 - sum_ps[1] ** 2 - sum_ps[2] ** 2 - sum_ps[3] ** 2
        )
        inv_mass = 1.0 / inv_mass

        bx = -inv_mass * sum_ps[1]
        by = -inv_mass * sum_ps[2]
        bz = -inv_mass * sum_ps[3]

        x = cme * inv_mass
        g = sum_ps[0] * inv_mass
        a = 1.0 / (1.0 + g)

        bdotp = bx * ps[1] + by * ps[2] + bz * ps[3]
        fact = a * bdotp + ps[0]

        return jnp.array(
            [
                x * (g * ps[0] + bdotp),
                x * (fact * bx + ps[1]),
                x * (fact * by + ps[2]),
                x * (fact * bz + ps[3]),
            ]
        )

    return jax.jit(boost)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we can make the function to correct the masses, we need a function to solve
$f(\xi) = 0 = \sum\sqrt{m_{i}^{2} + \qty(\xi p_{i}^{0})^{2}} - E_{\mathrm{cm}}$.
We will solve this using Newton iterations. Note that the derivative of $f(\xi)$ is
given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{f}{\xi} = \sum_{j=1}^{N} \frac{\xi\qty(p_{j}^{0})^{2} }{\sqrt{m_{j}^{2} + \qty(\xi p_{j}^{0})^{2}}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Defining $f_{i} = \sqrt{m_{i}^{2} + \qty(\xi e_{i})^{2}}$, $e_{i} = p_{i}^{0}$, we have:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    f(\xi) &amp;= \sum_{i} f_{i} - E_{\mathrm{cm}}, &amp; \dv{f}{\xi} &amp;= \sum_{i} \frac{\xi e_{i}^{2}}{f_{i}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Recall that the Newton iteration requires us to update $\xi$ using
$\xi_{j+1} = \xi_{j}-f(\xi_{j})/f&amp;rsquo;(\xi_{j})$, starting from $\xi_{0}$. We will take
$\xi_{0}$ to be $\xi_{0} = \sqrt{1 - \qty(M/E_{\mathrm{cm}})^{2}}$ with $M = \sum_{i}m_{i}$.
Note that we can also use &lt;code&gt;jax.jvp&lt;/code&gt; to automatically perform the derivative for us. We will show
both method. For similicity, we will use a fixed number of iterations. Usually 10 is more than enough.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_correct_masses(cme, masses, iterations):
    n = len(masses)
    ms = jnp.array(masses).reshape((n, 1))
    xi0 = math.sqrt(1.0 - (sum(masses) / cme) ** 2)

    def compute_scale_factor(ps):
        shape = ps.shape[1:]
        e = ps[0]
        xi = xi0 * jnp.ones((shape[-1],))
        for _ in range(iterations):
            # Using jax.jvp:
            def func(xi_):
                return jnp.sum(jnp.hypot(e * xi_, ms), axis=0) - cme

            f, df = jax.jvp(func, (xi,), (jnp.ones_like(xi),))
            # by hand:
            # deltaf = jnp.hypot(e * xi, ms)
            # f = jnp.sum(deltaf, axis=0) - cme
            # df = jnp.sum(xi * e ** 2 / deltaf, axis=0)
            xi = xi - f / df

        return xi

    def correct_masses(ps):
        xi = compute_scale_factor(ps)
        return jnp.array(
            [
                jnp.hypot(xi * ps[0], ms),
                xi * ps[1],
                xi * ps[2],
                xi * ps[3],
            ]
        )

    return jax.jit(correct_masses)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we write our function to compute the weights.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_compute_weights(n, cme):
    pi = jnp.pi
    fact_nm2 = math.factorial(n - 2)
    fact = 1.0 / ((n - 1) * fact_nm2 ** 2)
    base_wgt = (
        fact * (0.5 * pi) ** (n - 1) * cme ** (2 * n - 4) * (0.5 / pi) ** (3 * n - 4)
    )

    def weight_rescale_factor(ps):
        modsqr = jnp.sum(ps[1:] ** 2, axis=0)
        mod = jnp.sqrt(modsqr)
        inveng = 1.0 / ps[0]

        t1 = jnp.sum(mod / cme, axis=0) ** (2 * n - 3)
        t2 = 1.0 / jnp.sum(modsqr * inveng, axis=0)
        t3 = jnp.prod(mod * inveng, axis=0)

        return t1 * t2 * t3 * cme

    def compute_weights(ps):
        return weight_rescale_factor(ps) * base_wgt

    return jax.jit(compute_weights)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lastly, we put it all together, constructing a function that takes in a key and
returns the weights and momenta.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_generator(cme, masses, iterations, batch_size):
    n = len(masses)
    init = make_momenta_initializer(n, batch_size)
    boost = make_momenta_boost(cme)
    correct_masses = make_correct_masses(cme, masses, iterations)
    compute_weights = make_compute_weights(n, cme)

    def generator(key):
        ps = init(key)
        ps = boost(ps)
        ps = correct_masses(ps)
        ws = compute_weights(ps)
        return ps, ws

    return jax.jit(generator)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;example-muon-decay-mupm-to-epm--nu_mu--nu_e&#34;&gt;Example: Muon decay $\mu^{\pm} \to e^{\pm} + \nu_{\mu} + \nu_{e}$&lt;/h3&gt;
&lt;p&gt;For an example, we will use our new code to compute the decay width for a muon
decaying into an electron and two neutrinos. The analytic expression for the
width is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \Gamma &amp;= \frac{G_{F}^{2}m_{\mu}^{5}}{192 \pi^{3}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see if we can obtain this result using our &lt;code&gt;jax&lt;/code&gt; code. The below code will
generate weights and momenta for a batch, then compute the average and standard
deviation.  After we obtain our results, we divide by $1/(2m_{\mu})$ to obtain
the width $\Gamma$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_compute_decay_width(msqrd, m, fsp_masses, batch_size):

    generator = make_generator(m, fsp_masses, 10, batch_size)

    def compute_decay_width(key):
        ps, ws = generator(key)
        ws = ws * msqrd(ps)
        avg = jnp.average(ws)
        std = jnp.std(ws) / math.sqrt(batch_size)
        return avg / (2 * m), std / (2 * m)

    return jax.jit(compute_decay_width)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last piece of the puzzle we need is a function to compute the integrand of
the decay width.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;MMU = 1.056584e-01 # Mass of the muon in GeV
GF = 1.166379e-05  # Fermi constant in GeV^-2

@jax.jit
def lnorm_sqr(p):
    &amp;quot;&amp;quot;&amp;quot;
    Compute the squared Lorenzian norm of a four-vector.
    &amp;quot;&amp;quot;&amp;quot;
    return p[0, :] ** 2 - p[1, :] ** 2 - p[2, :] ** 2 - p[3, :] ** 2

@jax.jit
def msqrd_mu_to_e_nu_nu(ps):
    &amp;quot;&amp;quot;&amp;quot;
    Compute the squared matrix element for muon decay into an electron
    and two neutrinos.
    &amp;quot;&amp;quot;&amp;quot;
    t = lnorm_sqr(ps[:, 0, :] + ps[:, 2, :])
    return 16.0 * GF**2 * t * (MMU**2 - t)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s test it out and make sure things are working correctly:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cme = MMU
masses = [0.0, 0.0, 0.0]
width = GF2 * MMU**5 / (192.0 * jnp.pi**3)

compute_decay_width_jax = make_compute_decay_width(msqrd_mu_to_e_nu_nu, cme, masses, 1 &amp;lt;&amp;lt; 19)
percent_error = abs((compute_decay_width_jax(jax.random.PRNGKey(1234)) - width) / width)
print(percent_error)
# output: DeviceArray(0.1358793, dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we do some benchmarks against &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;c++&lt;/code&gt;, let&amp;rsquo;s show the amount of time it takes
for this operation. First, the amount of time for the jit and a single evaluation is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def compile_and_eval():
    compute_decay_width = make_compute_decay_width(msqrd_mu_to_e_nu_nu, MMU, masses, 1 &amp;lt;&amp;lt; 19)
    compute_decay_width(jax.random.PRNGKey(1234))

%timeit compile_and_eval()
# output: 685 ms ± 7.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the time for a single evaluation (after jit) is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;compute_decay_width = make_compute_decay_width(msqrd_mu_to_e_nu_nu, MMU, masses, 1 &amp;lt;&amp;lt; 19)
%timeit compute_decay_width(jax.random.PRNGKey(1234))
# output: 3.01 ms ± 7.46 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s take a look at some benchmarks. We will benchmark a pure &lt;code&gt;numpy&lt;/code&gt;
version, two &lt;code&gt;jax&lt;/code&gt; versions (one on the CPU and another on the GPU), and two
&lt;code&gt;C++&lt;/code&gt; versions, a single-threaded version and a mutli-threaded version (compiled
with &lt;code&gt;-O3 -march=native&lt;/code&gt;). All of these computations are taking place on a
machine with a Ryzen 3900X 12-core, 24-thread CPU and a GeForce 2060 6GB GPU. We
use between 1 and $2^{22}$ for our &lt;code&gt;batch_size&lt;/code&gt;. We set the center-of-mass
energy to $100$ and use a 5-body final state with masses $[1,2,3,4,5]$.
Additionally, we use a flat matrix element $\mathcal{M} = 1$.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img width=&#34;600&#34; height=&#34;450&#34; src=&#34;./benchmarks.png&#34;&gt;
&lt;/p&gt;
&lt;p&gt;Unsurprisingly, the &lt;code&gt;C++&lt;/code&gt; versions dominate for small numbers of points ($n \lesssim 500$).
However, we begin to see the power of jax when we cross $n\sim 5000$. The GPU version seems
to be limited only by the data transfer time to the GPU up until 100,000 points, after which
we begin to see the computation cost come into play. Clearly the GPU is the winner in this
case. Interestingly, the jax CPU version is on par with the single-threaded &lt;code&gt;C++&lt;/code&gt; version,
demonstrating that jax is useful even if one doesn&amp;rsquo;t have a GPU.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Boosting your spectra</title>
      <link>https://loganamorrison.github.io/post/boosting/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/boosting/</guid>
      <description>&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#starting-from-rest-frame&#34;&gt;&lt;strong&gt;Starting from Rest Frame&lt;/strong&gt;&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#boost-integral-in-terms-of-scaleless-varibles&#34;&gt;Boost Integral in terms of Scaleless Varibles&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#examples&#34;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#dirac-delta-function-spectrum&#34;&gt;&lt;em&gt;Dirac-Delta Function Spectrum&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#muon-decay&#34;&gt;&lt;em&gt;Muon Decay&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;starting-from-rest-frame&#34;&gt;&lt;strong&gt;Starting from Rest Frame&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Suppose we know the energy spectrum \(\dv*{N_{f}}{E_{1}}\) of some product \(f\)
from the decay of a state \(I\) in the rest frame of \(I\).
From this spectum,
we would like to obtain the corresponding spectrum, \(\dv*{N_{f}}{E_{2}}\) in a
boosted frame. First, assume that the
four-momentum of \(f\) in the initial
frame is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
p^{\mu}_{1} &amp;amp; = (E_{1}; \mathbf{p}_{1})
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where \(\mathbf{p}_{1}\) is the three-momentum of \(f\). without loss of generality,
let&amp;rsquo;s assume that \(\mathbf{p}_{1}\) lies in the \(xz\)-plane:&lt;/p&gt;
&lt;p&gt;$$
\mathbf{p}_{1} = (|{\mathbf{p}_{1}}| \tilde{z}_{1}, 0, |\mathbf{p}_{1}|z_{1}),
$$&lt;/p&gt;
&lt;p&gt;with \(z_{1}\) equal to the cosine of the angle \(\mathbf{p}_{1}\) makes with the \(z\) axis and
\(\tilde{z}_{1} = \sqrt{1-z_{1}^2}\). Assume we boost along the \(z\)-axis, we can translate this four-momentum
in the new frame using \(p^{\mu}_{2} = {\Lambda}{^\mu_\nu}p^{\nu}_{1}\) with&lt;/p&gt;
&lt;p&gt;$$
{\Lambda}{^\mu_\nu} = \begin{pmatrix}
\gamma &amp;amp; 0 &amp;amp; 0 &amp;amp; \gamma\beta \\
0&amp;amp;1&amp;amp;0&amp;amp;0\\
0&amp;amp;0&amp;amp;1&amp;amp;0\\
\beta\gamma&amp;amp;0&amp;amp;0&amp;amp;\gamma
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Explicity, \(p^{\mu}_{2}\) is given by:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
p^{\mu}_{2} &amp;amp; = (E_{2}; \mathbf{p}_{2})                         \\
E_{2}       &amp;amp; = \gamma E_{1} + \beta\gamma|{\mathbf{p}_{1}}|z_{1} \\
\mathbf{p}_{2}  &amp;amp; =
(|{\mathbf{p}_{1}}|\tilde{z}_{1}, 0, \beta\gamma E_{1} + \gamma|{\mathbf{p}_{1}}|z_{1})
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Notice that \(E_{2}\) explicity depends on \(z_{1}\), which we have integrated over in obtaining \(\dv*{N_{f}}{E_{1}}\). To
reintroduce \(z_{1}\), we use:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
{\dv{N_{f}}{E_{1}}}(E_{1}) &amp;amp; = \int_{-1}^{1}\dd{z} \pdv{N_{f}}{E_{1}}{z_{1}}, &amp;amp;
\pdv{N_{f}}{E_{1}}{z_{1}}  &amp;amp; = \frac{1}{2} \dv{N_{f}}{E_{1}}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In order to translate this expression into \(\dv*{N_{f}}{E_{2}}\), we have two options. The first is to introduce a \(\delta\)-function enforcing the
correct relation between \(E_{2}\) and \(E_{1}\) and integrate over \(E_{1}\) in addition to \(z_{1}))&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
. The trick is to
first use:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
N_{f} = \int\dd{z_{1}}\dd{E_{1}}\pdv{N_{f}}{E_{1}}{z_{1}}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and insert:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
1 &amp;amp; = \int\dd{E_{2}}\delta(E_{2} - E_{2}(E_{1}, z_{1}))
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where \(E_{2}(E_{1},z_{1}) = \gamma E_{1} + \beta\gamma|{\mathbf{p}_{1}}|z_{1}\)
Inserting this factor of unity, we obtain:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
N_{f}
= \int\dd{E_{2}}\int\dd{z_{1}}\int\dd{E_{1}}\pdv{N_{f}}{E_{1}}{z_{1}} \delta(E_{2} - E_{2}(E_{1}, z_{1}))
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Differentiating with respect to \(E_{2}\), we find:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dv{N_{f}}{E_{2}}
= \int\dd{z_{1}}\int\dd{E_{1}}\pdv{N_{f}}{E_{1}}{z_{1}} \delta(E_{2} - E_{2}(E_{1}, z_{1}))
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The second method is to use one of the following (which is equivalent; see &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;)&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dd[2]{N}
= \pdv{N_{f}}{E_{1}}{z_{1}}\dd{E_{1}}\dd{z_{1}}
= \pdv{N_{f}}{E_{1}}{z_{1}} \mathcal{J} \dd{E_{2}}\dd{z_{2}}
= \pdv{N_{f}}{E_{1}}{z_{1}} \tilde{\mathcal{J}} \dd{E_{2}}\dd{z_{1}}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;with the Jacobians, \(\mathcal{J}\) or \(\tilde{\mathcal{J}}\), given by:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{J}               &amp;amp; =
\mqty| \pdv{E_{1}}{E_{2}} &amp;amp; \pdv{E_{1}}{z_{2}}             \ \pdv{z_{1}}{E_{2}} &amp;amp; \pdv{z_{1}}{z_{2}} |, &amp;amp;
\tilde{\mathcal{J}}       &amp;amp; =  \mqty| \pdv{E_{1}}{E_{2}} |
\end{align}
$$&lt;/p&gt;
&lt;p&gt;depending on if one wishes to convert \(z_{1}\) into \(z_{2}\) (since the
angular varibles will ultimately be integrated over, either choice is fine.) We
will focus on the \(\delta\)-function approach since it is easiest to deal with.&lt;/p&gt;
&lt;p&gt;In computing \(\dv*{N_{f}}{E_{2}}\), we need to perform one integration. But we
have the choice of either integration over \(E_{1}\) or \(z_{1}\). The differences
in the two will appear in the limits of integration. Suppose we integrate over
\(z_{1}\). Then, the \(\delta\)-function can be casted to&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \delta(\gamma E\_{1} + \beta\gamma|{\mathbf{p}_{1}}|z_{1} - E_{2})
     &amp; = 
    \frac{1}{\gamma\beta\abs{\mathbf{p}_{1}}}\delta(z_{1} - z^{0}_{1}), 
     &amp; 
    z^{0}_{1}
     &amp; =
    \frac{E_{2}-\gamma E_{1}}{\gamma\beta\abs{\mathbf{p}_{1}}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;As a side note, if we used the Jacobian for $ (E_{1},z_{1}) \to (E_{1},E_{2})$, which is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dd{E_{1}}\dd{z_{1}} = \mqty|\pdv{z_{1}}{E_{2}}|\dd{E_{1}}\dd{E_{2}} = 
    \frac{1}{\gamma\beta\abs{\mathbf{p}}_{1}}\dd{E_{1}}\dd{E_{2}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;then we get the same factor of $ 1/\gamma\beta\abs{\mathbf{p}_{1}}$.&lt;/p&gt;
&lt;p&gt;Since $ -1 &amp;lt; z_{1} &amp;lt; 1$, the $ \delta$-function only has support if&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    -1 &lt; \frac{E_{2}-\gamma E_{1}}{\gamma\beta\abs{\mathbf{p}_{1}}} &lt; 1
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \gamma\qty(E_{2}-\beta\sqrt{E_{2}^{2}-m_{f}^{2}}) &lt; E_{1} &lt; 
    \gamma\qty(E_{2}+\beta\sqrt{E_{2}^{2}-m_{f}^{2}})
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Defining $E^{\pm}_{1} = \gamma\qty(E_{2}\pm\beta\abs{\mathbf{p}_{2}})$ with $\abs{\mathbf{p}_{2}} = \sqrt{E_{2}^{2}-m_{f}^{2}}$, we find:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\boxed{
    \dv{N_{f}}{E_{2}}
    = \frac{1}{2\gamma\beta}\int^{E^{+}_{1}}_{E^{-}_{1}} \frac{\dd{E_{1}}}{\abs{\mathbf{p}_{1}}} \dv{N_{f}}{E_{1}}
    = \frac{1}{2\gamma\beta}\int^{E^{+}_{1}}_{E^{-}_{1}} \frac{\dd{E_{1}}}{\sqrt{E_{1}^{2}-m^2_{f}}} \dv{N_{f}}{E_{1}}
    }
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Note that the bounds may be different that $E^{\pm}_{1}$, depending on $E_{2}$. The function $\dv*{N_{f}}{E_{1}}$ itself has
limits $E^{\mathrm{min}}_{1}$ and $E^{\mathrm{max}}_{1}$. Thus, the actual limits of integration are:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \mathrm{max}(E^{\mathrm{min}}_{1}, E^{-}_{1}) \leq E_{1} \leq \mathrm{min}(E^{\mathrm{max}}_{1}, E^{+}_{1})
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;boost-integral-in-terms-of-scaleless-varibles&#34;&gt;Boost Integral in terms of Scaleless Varibles&lt;/h3&gt;
&lt;p&gt;It is sometimes advantagous to deal with scaleless varibles when working with
spectra. For example, it is common to define $x_{i} \equiv 2E_{i}/Q_i$, where
$Q_i$ is the center-of-mass energy. If, in addition, we define a scaleless mass
$\mu_i = 2m_{f}/Q_i$, then we can write:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{x_{i}} &amp; = \frac{Q_{i}}{2}\dv{N_{f}}{E_{i}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;and hence:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{x_{i}} &amp; 
    = \frac{Q_{2}}{2}\frac{1}{2\gamma\beta}\int^{x^{+}_{1}}_{x^{-}_{1}} \frac{(Q_{1}/2)\dd{x_{1}}}{\sqrt{(Q_{1}^2/4)x_{1}^{2}-(Q_{1}^2/4)\mu^2_{f}}} 
    \frac{2}{Q_{1}}\dv{N_{f}}{x_{1}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Simplifying and using $ Q_{2} = \gamma Q_{1}$, we find:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
\boxed{
    \dv{N_{f}}{x_{2}}  
    = \frac{1}{2\beta}\int^{x^{+}_{1}}_{x^{-}_{1}} \frac{\dd{x_{1}}}{\sqrt{x_{1}^{2}-\mu^2_{1}}} 
    \dv{N_{f}}{x_{1}}
    }
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;In this case, the integration bounds are given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    x^{-}_{1} &amp; \equiv \mathrm{max}\qty(x^{\mathrm{min}}_{1}, \gamma^{2}\qty(x_{2}-\beta\sqrt{x_{2}^2-\mu_{2}^2})) \\
    x^{+}_{1} &amp; \equiv \mathrm{min}\qty(x^{\mathrm{max}}_{1}, \gamma^{2}\qty(x_{2}+\beta\sqrt{x_{2}^2-\mu_{2}^2}))
\end{align}
$$
&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;dirac-delta-function-spectrum&#34;&gt;&lt;em&gt;Dirac-Delta Function Spectrum&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;In the case where $\dv*{N_{f}}{E_{1}} = N \delta(E_{1}-\bar{E})$, we can
exactly perform the integral in \EqnRef{eqn:boost_e}. In this case, we find&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{E_{2}}
    = \frac{1}{2\gamma\beta}\int^{E^{+}_{1}}_{E^{-}_{1}} \frac{\dd{E_{1}}}{\sqrt{E_{1}^{2}-m^2_{f}}} N \delta(E_{1} - \bar{E})
    = \frac{1}{2\gamma\beta}\frac{N}{\sqrt{\bar{E}^{2}-m^2_{f}}} 
    \begin{cases}
        1 &amp; \qq*{if} E^{+}_{1}\leq \bar{E} \leq E^{+}_{1}, \\
        0 &amp; \mathrm{otherwise}
    \end{cases}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;As an example, take $ \pi^{0} \to \gamma + \gamma$. In this case,
$ \dv*{N_{f}}{E_{1}} = 2\delta(E_{1} - m_{\pi^{0}}/2)$, and the spectrum is&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{E_{2}}
    = \frac{2}{\gamma\beta m_{\pi^{0}}}
    \begin{cases}
        1 &amp; \qq*{if} \gamma E_{2}(1-\beta)\leq m_{\pi^{0}}/2 \leq \gamma E_{2}(1+\beta), \\
        0 &amp; \mathrm{otherwise}
    \end{cases}
\end{align}
$$
&lt;/p&gt;
&lt;h3 id=&#34;muon-decay&#34;&gt;&lt;em&gt;Muon Decay&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The muon decays via $ \mu^{\pm} \to e^{\pm} + \nu_{e} + \nu_{\mu}$. This decay
can also proceed radiatively. The result has been worked out in &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.
The result for an unpolarized muon is:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N}{x} &amp; = \frac{\alpha}{3\pi}\sum_{n=0}^{4}\qty(a_{n} + b_{n}L(y))x^{n-1}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;where $ x\equiv 2E_{\gamma}/m_{\mu}$, $ L(x) \equiv \log((1-x)/r)$, $ r = (m_{e}/m_{\mu})^2$ and&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    a_0 &amp; = -\frac{17}{2},     &amp; 
    a_1 &amp; = \frac{37}{3},      &amp; 
    a_2 &amp; = -\frac{49}{4},     &amp; 
    a_3 &amp; = 13,                &amp; 
    a_4 &amp; = -\frac{55}{12}        \\
    b_0 &amp; = 3,                 &amp; 
    b_1 &amp; = -5,                &amp; 
    b_2 &amp; = 6,                 &amp; 
    b_3 &amp; = -6,                &amp; 
    b_4 &amp; = 2                 
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Note the limits on $ x$ are $ 0 \leq x \leq 1 - r$. Since the photon is
massless, \EqnRef{eqn:boost_x} takes the form:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \dv{N_{f}}{x_{2}} &amp; 
    = \frac{1}{2\beta}\int^{x^{+}}_{x^{-}} \frac{\dd{x_{1}}}{x_{1}}
    \dv{N_{f}}{x_{1}}
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    x^{-} &amp; \equiv \gamma^{2}x_{2}\qty(1 - \beta),                       &amp; 
    x^{+} &amp; \equiv \mathrm{min}\qty(1-r, \gamma^{2}x_{2}\qty(1 + \beta))
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;First, the integral of the polynomial part of $ \dv*{N}{x}$ is given by:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \frac{1}{2\beta}\sum_{n=0}^{4}a_{n}\int^{x^{+}}_{x^{-}} \dd{x_{1}}x_{1}^{n-2}
    =
    \frac{1}{2\beta}\qty[
    a_0\frac{x^{+} - x^{-}}{x^{+}x^{-}} + 
    a_1\log(\frac{x^{+}}{x^{-}}) + \sum_{n=2}^{4}a_n \frac{  \qty(x^{+})^{n} - \qty(x^{-})^{n}  }{n}]
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;The log terms have the form:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \int^{x^{+}_{1}}_{x^{-}_{1}} \dd{x_{1}}x_{1}^{n-2} L(x_1)
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;To integrate, we use:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
    \int\dd{x}x^{-2}L(x) &amp; = \log(1-x) - log(x) - \frac{1}{x}L(x)                                          \\
    \int\dd{x}x^{-1}L(x) &amp; = L(x)\log(x) + \mathrm{Li}_{2}(1-x)                                            \\
    \int\dd{x}L(x)       &amp; = -x - (1-x) L(x)                                                               \\
    \int\dd{x}x L(x)     &amp; = \frac{1}{4}x (2 + x) -\frac{1}{2}\log(1-x) + \frac{1}{2}x^2 L(x)              \\
    \int\dd{x}x^2L(x)    &amp; = -\frac{1}{18}x (6 + 3 x + 2 x^2) - \frac{1}{3}\log(1-x) + \frac{1}{3}x^3 L(x)
\end{align}
$$
&lt;/p&gt;
&lt;p&gt;Using the definitions of $ b_{n}$, we find:&lt;/p&gt;
&lt;p&gt;
$$
\begin{align}
     &amp; \frac{1}{2\beta}\sum_{n=0}^{4}b_{n}\int^{x^{+}_{1}}_{x^{-}_{1}} \dd{x_{1}}x_{1}^{n-2} L(x_1)                                              \\
     &amp; \quad = \frac{1}{2\beta}\bigg{[} -3\log(x) + \frac{16}{3}\log(1-x) - \frac{1}{18} x (66 - 21 x + 4 x^2) - 5 \mathrm{Li}_{2}(1-x)          \\   
     &amp; \hspace{2cm}    \log(\frac{1-x}{r})\qty(-6 - \frac{3}{x} + 6 x - 3 x^2 + \frac{2}{3}x^3 - 5\log(x))\bigg{]}\notag\bigg{|}^{x^{+}}_{x^{-}}
\end{align}
$$
&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Elor, G., Rodd, N. L., &amp;amp; Slatyer, T. R. (2015). Multistep cascade annihilations of dark matter and the Galactic Center Excess. Physical Review D, 91(10). &lt;a href=&#34;https://doi.org/10.1103/physrevd.91.103531&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1103/physrevd.91.103531&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Kim, D., Ee, J.-H., Yu, C., &amp;amp; Lee, J. (2021). Derivation of jacobian formula with Dirac delta function. European Journal of Physics, 42(3), 035006. &lt;a href=&#34;https://doi.org/10.1088/1361-6404/abdca9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1088/1361-6404/abdca9&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Kuno, Y., &amp;amp; Okada, Y. (2001). Muon decay and physics beyond the standard model. Reviews of Modern Physics, 73(1), 151–202. &lt;a href=&#34;https://doi.org/10.1103/revmodphys.73.151&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1103/revmodphys.73.151&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Fourier Series</title>
      <link>https://loganamorrison.github.io/post/visualizing-fourier-series/</link>
      <pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/visualizing-fourier-series/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./fourier_physics_116C.gif&#34; alt=&#34;Alt Text&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Its fall again and I&amp;rsquo;m TAing PHYS 116C (for the third time). The first topic of PHYS 116C is Fourier series. So, naturally, I thought I&amp;rsquo;d make a post about Fourier series. At some point, I stumbled acrossed &lt;a href=&#34;https://www.youtube.com/watch?v=Mm2eYfj0SgA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; video by &lt;code&gt;The Coding Train&lt;/code&gt;. In this post, I&amp;rsquo;d like to replicate what the &lt;code&gt;The Coding Train&lt;/code&gt; did, but in more generality, i.e. for a general Fourier series. I will focus on periodic functions on the interval $(-\pi, \pi)$ for simplicity (one can easily modify what I write to accomidate more general intervals). I will also be using &lt;code&gt;Julia&lt;/code&gt;, but the code can be easily adapted to any language (but at some put you&amp;rsquo;ll need a plotting library, so I&amp;rsquo;d say &lt;code&gt;Julia&lt;/code&gt;, &lt;code&gt;python&lt;/code&gt; or &lt;code&gt;Mathematica&lt;/code&gt; is the way to go.)&lt;/p&gt;
&lt;h1 id=&#34;fourier-series&#34;&gt;Fourier Series&lt;/h1&gt;
&lt;p&gt;The concept of Fourier series is incredibly useful for many fields in science,
ranging from math, to physics, to engineering. As a physicist, I use Fourier
series almost every day (mostly in infinite period limit, i.e. the Fourier
transform, but thats a topic for a later day.) The goal of a Fourier series is
to decompose a periodic function into a countably infinite number of sines and
cosines with varying frequencies. This can be done for any piecewise continuous
function over the real or complex numbers. Given some piecewise continuous
function, $f(t)$, over the real numbers, which is periodic over the interval
$(-\pi,\pi)$, we can write down its Fourier series as:
$$
\begin{align}
f(t) &amp;amp;= \dfrac{a_{0}}{2} + \sum_{n=1}^{\infty}a_{n}\cos(nt)  + \sum_{n=1}^{\infty}b_{n}\sin(nt)
\end{align}
$$
where $a_{0}, a_{n}$ and $b_{n}$ are the &lt;strong&gt;Fourier&lt;/strong&gt; coefficients. It is
straight forward to compute these coefficients using a technique known as
&lt;em&gt;Fourier&amp;rsquo;s trick&lt;/em&gt;. The idea is to realize that sine and cosines with different
frequencies are orthogonal over the interval $(-\pi,\pi)$ (i.e. if you integrate
the product of a sine and/or cosine of different frequencies of ($-\pi,\pi$) you
get zero). For example,
$$
\dfrac{1}{\pi}\int_{-\pi}^{\pi}\cos(nt)\cos(mt) = \begin{cases} 0 &amp;amp; n\neq m\\
1 &amp;amp; n=m
\end{cases}
$$
Similar identities hold for other combinations of sines and cosines. If we use this orthogonality of sines and cosines, we can integrate both sides of the definition of the Fourier series to isolate the $a_{n}$&amp;rsquo;s and $b_{n}$&amp;rsquo;s. The results are:
$$\begin{align}
a_{n} &amp;amp;= \dfrac{1}{\pi}\int_{-\pi}^{\pi}f(t)\cos(nt)dt, &amp;amp;
b_{n} &amp;amp;= \dfrac{1}{\pi}\int_{-\pi}^{\pi}f(t)\sin(nt)dt
\end{align}$$
Given these simple formulas, we can then easily compute Fourier series of any function we might like. Before doing so, I&amp;rsquo;d like to present an alternate form of the real Fourier series consisting of just cosines (which will be useful for us later on). To get rid of the sines, one can make use of the following identity:
$$\begin{align}
c_{n}\cos(nt + \phi_{n}) &amp;amp;= a_{n}\cos(nt) + b_{n}\sin(nt)\\\
c_{n} &amp;amp;= \sqrt{a_{n}^2 + b_{n}^2}\\
\phi_{n} &amp;amp;= -\tan^{-1}(b_{n}/a_{n})
\end{align}$$
(this is easiest to prove using complex exponentials.) Then, we can write down the Fourier series as:
$$\begin{align}
f(t) &amp;amp;= \sum_{n=0}^{\infty}c_{n}\cos(nt + \phi_{n})
\end{align}$$
with $c_{0} = a_{0} / 2$ and $\phi_{0} = 0$.&lt;/p&gt;
&lt;p&gt;Before moving onto the main topic, let&amp;rsquo;s write some code to compute Fourier series. I will be using &lt;code&gt;Julia&lt;/code&gt; (since its the best), but the reader can easily adapt the code to their favorite programing language.&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s create a Julia &lt;code&gt;struct&lt;/code&gt; for representing the Fourier series of a function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;struct FourierSeries
    a0::Float64
    ans::Array{Float64, 1}
    bns::Array{Float64, 1}
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s also create a constructor that will take in a function and return a filled &lt;code&gt;FourierSeries&lt;/code&gt; object. To do this, we will need to compute some integrals. We will use the &lt;code&gt;QuadGK&lt;/code&gt; library to do this (you can install via &lt;code&gt;Pkg.add(&amp;quot;QuadGK&amp;quot;)&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using QuadGK

&amp;quot;&amp;quot;&amp;quot;
    FourierSeries(f; N=10)

Generate a FourierSeries object containing the the first `N` (excluding a0)
Fourier coefficients of the function `f` over the interval (-π, π).
&amp;quot;&amp;quot;&amp;quot;
function FourierSeries(f::Function; N::Int=10)
    a0::Float64 = quadgk(t-&amp;gt; f(t), -π, π)[1] / π
    ans = Array{Float64, 1}(undef, N)
    bns = Array{Float64, 1}(undef, N)
    for n in 1:N
        ans[n] = quadgk(t-&amp;gt; f(t) * cos(n * t), -π, π)[1] / π
        bns[n] = quadgk(t-&amp;gt; f(t) * sin(n * t), -π, π)[1] / π
    end
    FourierSeries(f, a0, ans, bns)
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calling &lt;code&gt;FourierSeries(f)&lt;/code&gt; will return a &lt;code&gt;FourierSeries&lt;/code&gt; object with the first 10 Fourier coefficients computed. Likewise, &lt;code&gt;FourierSeries(f; N=100)&lt;/code&gt; would compute the first 100 Fourier coefficients. We will also what to be able to evaluate the Fourier series at a given time. Thus, to avoid explicitly writing the sum everytime, let&amp;rsquo;s write a function to do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot;&amp;quot;&amp;quot;
    eval(t, fs::FourierSeries)

Evaluate the Fourier series `fs` at the time `t`.
&amp;quot;&amp;quot;&amp;quot;
function eval(t::Float64, fs::FourierSeries)
    fs.a0 / 2 + sum(fs.ans[n] * cos(n * t) + fs.bns[n] * sin(n * t)
                    for n in 1:length(fs.ans))
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For convinience, we also make a vectorized function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function eval(ts::AbstractRange, fs::FourierSeries)
    [eval(t, fs) for t in ts]
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which can take in a range of times and return an array of the Fourier series evaluated at those times. Now, we can go nuts and compute the Fourier series for any function we wish. For example, we can compute the Fourier series of the step function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# step function: zero for t &amp;lt; 0 and π for t &amp;gt; 0.
f(t) = t &amp;lt; 0 ? 0.0 : π;
fs = FourierSeries(f)
# Plot it!
using Plots;
ts = LinRange(-π, π, 100);
plot(ts, eval(ts, fs), linewidth=1.5, label=&amp;quot;Fourier&amp;quot;, framestyle=:box)
plot!(ts, [f(t) for t in ts], linewidth=2, label=&amp;quot;f&amp;quot;)
ylabel!(&amp;quot;f(t)&amp;quot;)
xlabel!(&amp;quot;t&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;../../../assets/img/fs_step_function.svg&#34; alt=&#34;Fourier series of step function&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;epicycles&#34;&gt;Epicycles&lt;/h1&gt;
&lt;p&gt;If you&amp;rsquo;ve ever taken a physics course, you&amp;rsquo;ve likely encountered the simple harmonic oscillator (SHO). The motion of a SHO is described by the form $x(t) = A\cos(\omega t + \phi_{0})$, where $A$ is the amplitude of the oscillator, $\omega$ is the angular frequency and $\phi_{0}$ is the initial phase angle. You may have also be taught that you can visualize the motion of the oscillator as the projection of a point moving along a circle onto the &amp;ldquo;x&amp;rdquo; axis (if you haven&amp;rsquo;t seen this, you will soon!) We&amp;rsquo;d like to take this idea one step further. Because, a Fourier series is like a sum of an infinite number of SHO, each oscillating with a different frequency.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s condier the Fourier series we defined above, which we write down again here:
$$\begin{align}
f(t) &amp;amp;= \sum_{n=0}^{\infty}c_{n}\cos(nt + \phi_{n})
\end{align}$$
The first term (the $n=0$ term) is just a constant shift. The second term is where things start to get interesting, $c_{1}\cos(t+\phi_1)$. If you remember back to the &amp;ldquo;unit-circle&amp;rdquo;, this is the horizontal component of a line from the center of a circle of radius $c_{1}$ to the edge of the circle. The angle this line makes with the horizontal axis is $t + \phi_1$. Similarly, the third term, $c_{2}\cos(2t+\phi_2)$ is again the horizontal component of a line, but of a circle of radius $c_2$ and with an angle $2t+\phi_2$. Now, if we add the first three terms:
$$\begin{align}
c_0 + c_1\cos(t+\phi_1) + c_2\cos(2t+\phi_2)
\end{align}$$
what we get can be interpreted as follows. Consider the following figure:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fourier series of step function&#34; srcset=&#34;
               /post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_aa4d27ace328e06fcfb1048d85c9dec1.webp 400w,
               /post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_87f05ac6cbebc08f2fea4f80d399c19d.webp 760w,
               /post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/visualizing-fourier-series/fourier_circles_helper_hu2ec12bafdc3e893713cfab343dc50d47_87793_aa4d27ace328e06fcfb1048d85c9dec1.webp&#34;
               width=&#34;760&#34;
               height=&#34;592&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This figure contains a set of circles to guide the eye along with a set of line connecting the centers of the circles. Here we have only drawn three circles, but one can imagine continuing drawing more and more. Each line drawn in this figure has a length equal to the radius of the corresponding circle, $c_n$, and makes an angle with respect to the verticle axis of $nt + \phi_n$. Consider now, the final height of the tip of the final line. It is simply
$$\begin{align}
c_0 + c_1\cos(t+\phi_1) + c_2\cos(2t+\phi_2) + c_3\cos(3t+\phi_3) + \cdots
\end{align}$$
which is exactly the Fourier series. What we have done is gave a geometric interpretation of the Fourier series: the Fourier series is just an inifinte set of circles arranged in a funny way. We take a circle centered at ($x=0$,$y=c_0$) of radius $c_1$, then add another circle of radius $c_2$ centered at the edge of the first at an angle $t + \phi_1$, etc.. Then, the height of the center of the final circle represents the Fourier series. Note that the angles here depend on time. Therefore, all of the circles will rotate as time evolves.&lt;/p&gt;
&lt;p&gt;This is cute and all, but let&amp;rsquo;s see it in action:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./fourier_square_wave.gif&#34; alt=&#34;Alt Text&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Now, I&amp;rsquo;d like to explain how this was made. We will use a slightly different example just so we can see more pretty pictures. In order to make the above gif, what we need to do is first construct the &lt;code&gt;FourierSeries&lt;/code&gt; object. Let&amp;rsquo;s do this for a function that is:
$$\begin{align}
f(t) &amp;amp;= \begin{cases}
t + \pi &amp;amp; t &amp;lt; 0\
\pi &amp;amp; t &amp;gt; 0\
\end{cases}
\end{align}$$
To construct this object, we use:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;f(t) = t &amp;lt; 0 ? t + π : π
fs = FourierSeries(f)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will want to make a gif. This is done by using the &lt;code&gt;@gif&lt;/code&gt; macro in &lt;code&gt;Julia&lt;/code&gt; (in &lt;code&gt;python&lt;/code&gt; you can use matplotlib and its &lt;code&gt;animation&lt;/code&gt; module. See &lt;a href=&#34;https://jakevdp.github.io/blog/2012/08/18/matplotlib-animation-tutorial/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; for a good explaination). The &lt;code&gt;@gif&lt;/code&gt; macro takes in a &lt;code&gt;for&lt;/code&gt; loop as its argument. That is, we use:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;nframes = 1500
@gif for i = 1:nframes
    # code to make plots here...
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will make a gif for every 10 of the plots you constructed in the &lt;code&gt;for&lt;/code&gt; loop (see &lt;a href=&#34;http://docs.juliaplots.org/latest/#simple-is-beautiful-1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; for more information.) Inside our &lt;code&gt;for&lt;/code&gt; loop we&amp;rsquo;d first like to just plot the Fourier series. But we would like to evolve it through time. We can do so using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Plot window will always be -π → π
ts = range(-π, stop = π, length = 50);
@gif for i = 1:1500
    shift = i / 100 # time shift
    plot(
        ts, # horizontal plot windows
        [eval(t + shift, fs) for t in ts], # Fourier series values
        ylims = (-1.5, π + 1.5), # fix window height
        legend = false, # let&#39;s not go for legend
        xlims = (-π, 4π), # we make some extra room for later
        framestyle = :box, # because you&#39;ve got to have a frame
        aspect_ratio = 1 # so the circles look like circles and not ellipses
    )
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will draw the Fourier series as a &amp;ldquo;traveling wave&amp;rdquo; (think of a window of width ($-\pi$,$\pi$) moving to the right.) Now comes the hard part. We would like to draw the circles similar to how we drew them before. First, let&amp;rsquo;s make a circle maker:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot;&amp;quot;&amp;quot;
    circle(x, y, r)

Construct x and y positions of a cicle of radius `r` centered at (`x`, `y`).
&amp;quot;&amp;quot;&amp;quot;
function circle(x, y, r)
    θ = LinRange(0.0, 2π, 500)
    x .+ r * sin.(θ), y .+ r * cos.(θ)
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function will create $x$ and $y$ arrays for a circle centered at $(x,y)$ with radius $r$. We can draw the base circle, which is centered at $(0,c_0)$ using the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    # other code...
    x, y = (2.5π, fs.a0 / 2)
    r = sqrt(fs.ans[1]^2 + fs.bns[1]^2)
    ϕ = -atan(fs.bns[1], fs.ans[1])
    plot!(
        circle(x, y, r),
        seriestype = [:shape,],
        linecolor = :black,
        c = :white,
        legend = false
    )
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we shifted the circles center to be at $x=2.5\pi$. This is so it is out of the way of the plot of the Fourier series. Now, we would like to add on more circles. The centers of the next circle will be at $(x + c_1\sin(t + \phi_1), y + c_1\cos(t + \phi_1))$. In fact, each successive circle will be located at the previous $(x,y)$ but shifted by $(c_n\sin(nt + \phi_n), c_n\cos(nt + \phi_n))$. Let&amp;rsquo;s write an internal &lt;code&gt;for&lt;/code&gt; loop to draw all the circles:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    # other code...
    t = ts[end] + shift # get the final time
    for i = 2:length(fs.ans)
        x += r * sin((n - 1) * t + ϕ)
        y += r * cos((n - 1) * t + ϕ)
        # compute new radius and angle
        r = sqrt(fs.ans[n]^2 + fs.bns[n]^2)
        ϕ = -atan(fs.bns[n], fs.ans[n])
        plot!(
            circle(x, y, r),
            seriestype = [:shape,],
            linecolor = :black,
            c = :white,
            legend = false,
            fillalpha = 0.0
        )
    end
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will draw all of the circles. Lastly, we would like to draw a line connecting the center of the final circle to the final time of the Fourier series plot. This can be done using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    # other code...
    t = ts[end] + shift # get the final time
    for i = 2:length(fs.ans)
        # code...
    end
    x += r * sin(length(fs.ans) * (ts[end] + shift) + ϕ)
    y += r * cos(length(fs.ans) * (ts[end] + shift) + ϕ)
    interps = range(ts[end], stop = x, length = 50)
    plot!(interps, [y for _ in interps], color = :purple)
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that&amp;rsquo;s it. If we put everything together, the final code is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@gif for i = 1:1500
    shift = i / 100 #
    plot(
        ts,
        [eval(t + shift, fs) for t in ts],
        ylims = (-1.5, π + 1.5),
        legend = false,
        xlims = (-π, 4π),
        framestyle = :box,
        aspect_ratio = 1
    )
    x = 2.5π
    y = fs.a0 / 2
    r = sqrt(fs.ans[1]^2 + fs.bns[1]^2)
    ϕ = -atan(fs.bns[1], fs.ans[1])
    plot!(
        circle(x, y, r),
        seriestype = [:shape,],
        linecolor = :black,
        c = :white,
        legend = false
    )
    t = ts[end] + shift
    for n = 2:length(fs.ans)
        x += r * sin((n - 1) * t + ϕ)
        y += r * cos((n - 1) * t + ϕ)
        r = sqrt(fs.ans[n]^2 + fs.bns[n]^2)
        ϕ = -atan(fs.bns[n], fs.ans[n])
        plot!(
            circle(x, y, r),
            seriestype = [:shape,],
            linecolor = :black,
            c = :white,
            legend = false,
            fillalpha = 0.0
        )
        scatter!([x], [y], markersize = 0.3)
    end
    x += r * sin(length(fs.ans) * (ts[end] + shift) + ϕ)
    y += r * cos(length(fs.ans) * (ts[end] + shift) + ϕ)
    scatter!([x], [y], markersize = 0.1)
    interps = range(ts[end], stop = x, length = 50)
    plot!(interps, [y for _ in interps], color = :purple)
end every 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that I have added some code to plot the centers of the circles using &lt;code&gt;scatter!([x], [y], markersize = 0.3)&lt;/code&gt;. Running the code will produce the following:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./fourier_linear_const.gif&#34; alt=&#34;Alt Text&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;As a final note, I&amp;rsquo;ll explain how I made the gif displaying &amp;ldquo;Physics 116C&amp;rdquo; at the top of this post. What I did was plot digitize the text for &amp;ldquo;Physics 116C&amp;rdquo; using &lt;a href=&#34;https://automeris.io/WebPlotDigitizer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt;. Using the data that I extracted from the webplot digitizer, I constructed linear interpolating functions for the $x$ and $y$ data. Then, I constructed Fourier series for $x$ and $y$ functions and essentially repeated what I showed above.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating Functional Determinants in a Thermal Field Theory using the Heat-Kernel</title>
      <link>https://loganamorrison.github.io/post/functional-det-heat-kernel/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/functional-det-heat-kernel/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this post, we will discuss how to compute fluctuation determinants is a
finite temperature field theory. The general form of an operator that we will
investigate is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O} &amp;amp;= -\nabla^2 + \omega_{n}^2 + m^2 + V(x)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $m$ is a zero-temperature mass, $\omega_{n} = 2\pi n T$ for bosons and
$2\pi(n+1/2)T$ for fermions and $V(x)$ is some space-dependent function. Often,
$V(x)$ will take the form of a background- or low-mass-field-dependent mass for
the fluctuation fields of the problem. For example, consider a $\phi^4$ theory at finite temperature with the following action:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
S[\phi] &amp;amp;= \int_{0}^{\beta}d\tau\int d^{3}x \dfrac{1}{2}(\partial_{\mu}\phi)^2 -\dfrac{1}{2}m^2\phi^2
+\dfrac{\lambda}{8}\phi^4
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\phi = \phi(\tau, x)$. If one expands the field $\phi$ as a Fourier series in the imaginary time coordinate $\tau$,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\phi(\tau, x) &amp;amp;= \sum_{n=-\infty}^{\infty}\phi_{n}e^{i\omega_{n}\tau}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and wishes to integrate over the heavy Matsubara modes ($n\neq0$ modes), then they will need to compute a thermal fluctuation determinant of an operator of the form:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O} &amp;amp;= -\nabla^2 + \omega_{n}^2 + m^2 + \dfrac{3}{2}\lambda\phi_{0}^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Where $\phi_{0}$ is the zero-mode ($n=0$ Matsubara mode.) In this case,
$V(x) = (3\lambda/2)\phi_{0}^2(x)$. The question we would like to answer is: how does one evaluate the following fluctuation determinant&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathrm{tr}\log\left(-\nabla^2 + \omega_{n}^2 + m^2 + V(x)\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We will answer this question in the limit as $T\to\infty$.&lt;/p&gt;
&lt;h2 id=&#34;heat-kernal-expansion&#34;&gt;Heat Kernal Expansion&lt;/h2&gt;
&lt;p&gt;The method we will employ to evaluate the fluctuation determinant of the operator $\mathcal{O} = -\nabla^2 + \omega_{n}^2 + m^2 + V(x)$ is the so called
heat-kernel expansion. The idea is to use the following identity:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\log(\lambda) = -\int_{0}^{\infty}\dfrac{ds}{s}e^{-\lambda s} + \mathrm{constant}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where the constant we left implicit is some infinite constant which will play
no role in our analysis. To derive this expression, one can consider the
following:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\int_{0}^{\infty}\dfrac{ds}{s}e^{-\lambda s} &amp;amp;=
\int_{0}^{\infty}ds\int_{\lambda}^{\infty}d\lambda&amp;rsquo;e^{-\lambda&amp;rsquo; s}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Switching the order of integration and integrating over $s$, we find:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\int_{0}^{\infty}\dfrac{ds}{s}e^{-\lambda s} &amp;amp;=
\int_{\lambda}^{\infty}d\lambda&amp;rsquo;\dfrac{1}{\lambda&amp;rsquo;} = \lim_{\lambda&amp;rsquo;\to\infty}\log(\lambda&amp;rsquo;) - \log(\lambda)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Thus, up to an infinite constant, the identity holds. Note that if we take
the trace of a log of a determinant, we are equivalently summing over the
log of the eigenvalues of the operator. Therefore, we can say that:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathrm{tr}\log(\mathcal{O}) = \sum_{\lambda}\log(\lambda) = -\int_{0}^{\infty}\dfrac{ds}{s}\sum_{\lambda}e^{-\lambda s} =
\int_{0}^{\infty}\dfrac{ds}{s}\mathrm{tr}e^{-\mathcal{O} s}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We will define the factor of $e^{-\mathcal{O}s}$ as the &lt;strong&gt;heat kernel&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
K(s, x, y) \equiv \langle x|e^{-\mathcal{O}_{x} s}|y\rangle
\end{align}$$&lt;/p&gt;
&lt;p&gt;where the subscript $x$ denotes that the derivatives and function evaluation of $\mathcal{O}$ to be evaluated with $x$. Then, the trace of $e^{-\mathcal{O} s}$ is just the integral over $x$ of $K(s,x,x)$:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\mathrm{tr}e^{-\mathcal{O} s} = \int d^{d}x K(s,x,x)
\end{align}$$&lt;/p&gt;
&lt;p&gt;The heat-kernel turns out to satisfy the heat equation (hence the name). This is
easy to see:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\partial}{\partial s}e^{-\mathcal{O}_{x} s} = -{\mathcal{O}_{x}} K(s,x,y)
\quad \implies \quad \left(\dfrac{\partial}{\partial s} + {\mathcal{O}_{x}}\right)K(s,x,y)
= 0
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The right-most equality is simply the heat equation with a source term of
$\omega_{n}^2 + m^2 + V(x)$. The boundary condition of the heat equation can be
found by setting $s=0$:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K(s=0,x,y) = \langle x|y\rangle = \delta^d(x-y)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The heat-kernel can be determined exactly if we set $V(x) = 0$. Let&amp;rsquo;s call:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{M}^2 = \omega_{n}^2 + m^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;for ease of notation. The heat-kernel for the operator:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O}_{0} = -\nabla^2 + \mathcal{M}^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;is given by the following:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K_{0}(s,x,y) = \dfrac{1}{(4\pi s)^{d/2}}\exp\left(-\dfrac{|x-y|^2}{4s}-s\mathcal{M}^2\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;This can be verified by differentiation. Additionally, one can check that this
expression satisfies the boundary condition (to do this, integrate some function
$f(x)$ by Taylor expanding the function. The results are a set of gaussian
integrals which can easily be evaluate to obtain $f(y)$.) Further more,
$K_{0}(s, x, x)$ is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K_{0}(s,x,x) = \dfrac{1}{(4\pi s)^{d/2}}e^{-s\mathcal{M}^2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We can use this result to find the general result. Recall the Zassenhaus formula (a special case of the Baker-Campbell-Hausdorff formula):&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
e^{-t(X + Y)} &amp;amp;= e^{-t X}e^{-t Y}e^{-\frac{t^2}{2}[X,Y]}
e^{-\frac{t^3}{3!}(2[Y,[X,Y]]+ [X,[X,Y]])}\cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where the $\cdots$ represent terms of order $t^{4}$ and higher. If we break up our general operator into:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{O} = \mathcal{O}_{0} + V(x),
\end{align}
$$&lt;/p&gt;
&lt;p&gt;then we find that the general heat-kernel is given by:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
e^{-s\mathcal{O}} &amp;amp;= e^{-s\mathcal{O}_{0}}e^{-sV}e^{-\frac{s^2}{2}[\mathcal{O}_{0},V]}
e^{-\frac{s^3}{3!}(2[V,[\mathcal{O}_{0},V]]+ [\mathcal{O}_{0},[\mathcal{O}_{0},V]])}\cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We can easily evaluate the various commutators by considering their action on some test function $f(x)$. The results for the commutators shown are:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
[\mathcal{O}_{0},V] &amp;amp;= -\nabla^2 V\\
2[V,[\mathcal{O}_{0},V]]+ [\mathcal{O}_{0},[\mathcal{O}_{0},V]] &amp;amp;=-4V\nabla^2V+\nabla^4V
\end{align}
$$&lt;/p&gt;
&lt;p&gt;The higher order terms can easily be evaluated as well. Thus, we have that:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K(s,x,x) &amp;amp;= e^{-s(\mathcal{M}^2 + V)}e^{\frac{s^2}{2}\nabla^2V}
e^{-\frac{s^3}{3!}\left(\nabla^4V-4V\nabla^2V\right)}\cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In order to make progress on this expression, we need to have control over which terms in the expression are important. Let&amp;rsquo;s re-introduce our original definitions:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{M}^2=\omega_{n}^2+m^2 = \tilde{\omega}_{n}^2T^2 + m^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where we defined:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\tilde{\omega}_{n}^2 = \omega_{n}^2/T^2
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Next, we will define a scaleless variable $z=sT^2$. In terms of $z$, our expression is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
K(s,x,x) &amp;amp;= e^{-z\tilde{\omega}_{n}^2}e^{-\frac{z}{T^2}(m^2 + V)}e^{\frac{z^2}{2T^4}\nabla^2V}
e^{-\frac{z^3}{3!T^6}\left(\nabla^4V-4V\nabla^2V\right)}e^{\mathcal{O}(T^{-6})}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now it is clear how to proceed. We expand this expression in inverse powers of $T$. If we expand in inverse powers of $T$ and integrate over $s$, we find that, for bosons:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;\dfrac{T}{2}\sum_{n=-\infty}^{\infty} \mathrm{tr}\log(-{\nabla^2}+(2\pi n T)^2 + m^2 +V({x}))\\\
&amp;amp;\hspace{1cm}= -\dfrac{T}{2}\sum_{n=\infty}^{\infty} \int d^{d}{x}\left(\dfrac{T}{4\pi}\right)^{d/2}\int_{0}^{\infty}dz\dfrac{K(z,{x},{x})}{z^{d/2+1}}\notag\\
&amp;amp;\hspace{1cm}\underset{d\to3-2\epsilon}{=} \int d^{3}{x}\bigg{[}
-\frac{\pi^2 T^4}{90}+\frac{T^2(m^2 + V)}{24} -\frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{\mu^2}{4\pi T^2e^{-\gamma_{E}}})\right)}{64\pi^2}+ \mathrm{O}({T^{-2}})
\notag\\
&amp;amp;\hspace{3cm} +
\left(-\dfrac{T(m+V)^{3/2}}{12\pi} + \dfrac{T({\nabla}^2V)}{32\pi\sqrt{m^2+V}} + \dfrac{T(-4V{\nabla}^2V + {\nabla}^2V)}{192\pi(m^2+V)^{3/2}} + \cdots\right)
\bigg{]}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and for fermions:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;-\dfrac{T}{2}\sum_{n=-\infty}^{\infty} \mathrm{tr}\log(-{\nabla^2}+(2\pi (n+1/2) T)^2 + m^2 +V({x}))\\\
&amp;amp;\hspace{1cm}=\dfrac{T}{2}\sum_{n=\infty}^{\infty} \int d^{d}{x}\left(\dfrac{T}{4\pi}\right)^{d/2}\int_{0}^{\infty}dz\dfrac{K(z,{x},{x})}{z^{d/2+1}}\notag\\
&amp;amp;\hspace{1cm}\underset{d\to3-2\epsilon}{=}
\int d^{3}{x}\bigg{[} -\frac{7\pi^2 T^4}{720}
+ \frac{T^2(m^2 + V)}{48}
+ \frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{4e^{-\gamma_{E}}\mu^2}{\pi T^2})\right)}{64\pi^2}+\mathrm{O}({T^{-2}})\bigg{]}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;It is useful to note that, for bosons, the term proportional to $(m^2+V)^2$ can be written as:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;-\frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{\mu^2}{4\pi T^2e^{-\gamma_{E}}})\right)}{64\pi^2}\\
&amp;amp;\qquad= \frac{\left(m^2 + V\right)^2}{64\pi^2}\left[-\left(\frac{1}{\epsilon}+\log(4\pi e^{-\gamma})\right)+2\left(\dfrac{3}{4}+\log(4\pi)-\gamma_{E}\right)+\left(\log\left(\dfrac{T^2}{\mu^2}\right)-\dfrac{3}{2}\right)\right]\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where we&amp;rsquo;ve isolated the typical subtraction term (containing the $1/\epsilon +
\log(4\pi e^{-\gamma_{E}})$) and the Coleman-Weinberg-like potential term (the
$\log(T^2/\mu^2) - 3/2$). We can do the same for fermions, obtaining:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp;\frac{\left(m^2 + V\right)^2 \left(\frac{1}{\epsilon}+\log(\frac{4\mu^2e^{-\gamma_{E}}}{\pi T^2})\right)}{64\pi^2}\\
&amp;amp;\qquad= \frac{\left(m^2 + V\right)^2}{64\pi^2}\left[
\left(\frac{1}{\epsilon}+\log(4\pi e^{-\gamma})\right)-2\left(\dfrac{3}{4}+\log(\pi)-\gamma_{E}\right)-\left(\log\left(\dfrac{T^2}{\mu^2}\right)-\dfrac{3}{2}\right)\right]\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Even though we stopped our expansion at order $T^{0}$, one can easily see how to
include higher order term: simply cary out the expansion of the heat-kernel to
higher orders in $1/T$. For expand, the next term in the non-zero mode bosonic
expansion is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\zeta(3)}{768\pi^2 T^2}\left[\nabla^4V+2V\nabla^2V+(m^2+V)^3\right]
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and the next term in the fermionic expansion is the same thing multiplied by 7.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Effective Potential in a Scalar Field Theory</title>
      <link>https://loganamorrison.github.io/post/effective-potential-scalar-ft/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/effective-potential-scalar-ft/</guid>
      <description>&lt;h2 id=&#34;generic-form&#34;&gt;Generic Form&lt;/h2&gt;
&lt;p&gt;To derive the effective potential, we start with a couple definitions. We
define the generating function for greens functions as:
$$\begin{align}
Z[J] = \int\mathcal{D}\phi\exp(iS[\phi] + \int d^{4}x J(x)\phi(x))
\end{align}$$
This functional generates all possible Feynman diagrams. Not all of these
diagrams will be connected. To generate the connected diagrams, we
introduce the generating functional for connected diagrams:
$$\begin{align}
W[J] = -i\ln(Z[J])
\end{align}$$
Even the connected diagrams are not the most fundamental. The most
fundamental are the one-particle irreducible (1PI) diagrams. These are
generated by a functional which is the Legandre transform of $W[J]$:
$$\begin{align}
\Gamma[\phi_{\text{cl}}] = W[J] - \int d^{4}x J(x)\phi_{\text{cl}}(x)
\end{align}$$
where
$$\begin{align}
\phi_{\text{cl}}(x) = \dfrac{\delta W[J]}{\delta \phi(x)}
\end{align}$$
The effective potential will be given by
$$\begin{align}
\Gamma[\phi_{\text{cl}}] = -(VT)V_{\text{eff}}(\phi_{\text{cl}})
\end{align}$$
where $VT$ is the volume of space-time. Let&amp;rsquo;s illustrate how to compute
the effective action using the background field method. We begin by
expanding $\phi$ about the classical field, taking $\phi_{\text{cl}}$ to
be independent of space-time. That is,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\phi(x) = \phi_{\text{cl}} + \eta(x)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\eta(x)$ is a field representing the high momentum degrees of freedom of
$\phi(x)$. We now expand the action about $\phi_{\text{cl}}$:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
S[\phi(x)] &amp;amp; = S[\phi_{\text{cl}}] + \sum_{n=1}\dfrac{1}{n!}\int d^{4}x_{1}
\cdots\int d^{4}x_{n}\dfrac{\delta^{n}S[\phi(x)]}{\delta\phi(x_{1})
\cdots\delta\phi(x_{n})}\\
&amp;amp; = S[\phi_{\text{cl}}] + \int d^{4}y \dfrac{\delta S[\phi(x)]}{\delta\phi(y)}\eta(y) + \dfrac{1}{2}\int d^{4}y \int d^{4}z \dfrac{\delta^{2}S}{\delta\phi(y)\delta\phi(z)}\eta(y)\eta(z) + \cdots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
S[\phi] + \int d^{4}y J(y)(\phi(y) +\phi_{\text{cl}}) &amp;amp; = S[\phi_{\text{cl}}] + \int d^{4}y J(y)\phi_{\text{cl}} +
\int d^{4}y \eta(y)\left(\dfrac{\delta S[\phi]}{\delta\phi(y)} + J(y)\right)\\\
&amp;amp; \qquad + \int d^{4}y\int d^{4}z \eta(y)\dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\eta(z) + \cdots\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where all the functional derivatives are evaluated at $\phi_{\text{cl}}$. Note
that the equations of motion, which $\phi_{\text{cl}}$ satisfies, are&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\delta S[\phi]}{\delta\phi(y)}\bigg{|}&lt;em&gt;{\phi=\phi&lt;/em&gt;{\text{cl}}} + J(y) = 0
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, the term linear term in $\eta$ of the expansion of the action is zero. Now, the functional $Z[J]$ to quadratic order in $\eta$ is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Z[J] &amp;amp; = \int\mathcal{D}\phi\exp(iS[\phi] + i\int d^{4}y J(y)\phi(y))\notag\\
&amp;amp; = \exp\left(iS[\phi_{\text{cl}}] + i\int d^{4}y J(y)\phi_{\text{cl}})\right)\int\mathcal{D}\eta\exp\left(\dfrac{i}{2}\int d^{4}y\int d^{4}z \eta(y)\dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\eta(z) +\cdots\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We can explicitly evaluate the functional integral by wick rotating: $t\to i\tau$. Then,
$$\begin{align}
\int\mathcal{D}\eta\exp\left(-\dfrac{1}{2}\int d^{4}y_{E}\int d^{4}z_{E} \eta(y)\dfrac{\delta^{2} S_{E}[\phi]}{\delta\phi(y)\delta\phi(z)}\eta(z)\right) \propto \left(\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right)^{-1/2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now, using&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\left(\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right)^{-1/2} = \exp\left(-\dfrac{1}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;And thus,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Z[J] = \exp\left(iS[\phi_{\text{cl}}] + i\int d^{4}y J(y)\phi_{\text{cl}} -\dfrac{1}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\right) = e^{iW[J]}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Therefore,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
W[J] = S[\phi_{\text{cl}}] + \int d^{4}y J(y)\phi_{\text{cl}} + \dfrac{i}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now, the effective action is given by&lt;/p&gt;
&lt;p&gt;$$
\begin{align}\label{effective_potential}
\Gamma[\phi_{\text{cl}}] &amp;amp; = W[J] - \int d^{4}y J(y)\phi_{\text{cl}}\                                                       &amp;amp; =S[\phi_{\text{cl}}] + \int d^{4}y J(y)\phi_{\text{cl}} + \dfrac{i}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}- \int d^{4}y J(y)\phi_{\text{cl}} \notag\
&amp;amp; =S[\phi_{\text{cl}}] + \dfrac{i}{2}\ln\det \dfrac{\delta^{2} S[\phi]}{\delta\phi(y)\delta\phi(z)}\notag
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;specific-example-linear-sigma-model&#34;&gt;Specific Example: Linear Sigma Model&lt;/h2&gt;
&lt;h3 id=&#34;effective-potential-in-the-linear-sigma-model&#34;&gt;Effective Potential in the Linear Sigma Model&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s examine this process of computing the effective action for a simple example. Consider the linear sigma model:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathcal{L} = \dfrac{1}{2}\left(\partial_{\mu}\mathbf{\Phi}\right)\cdot\left(\partial^{\mu}\mathbf{\Phi}\right) + \dfrac{1}{2}\mu^{2}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right) - \dfrac{\lambda}{4}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right)^{2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\mathbf{\Phi}$ is a vector containing $N$ scalar fields. We now expand these fields about the classical fields:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\mathbf{\Phi} = \mathbf{\Phi}_{\text{cl}} + \mathbf{\eta}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where $\mathbf{\Phi}_{\text{cl}}$ are space-time independent fields. Now, we would
like to take the second functional derivative with respect to the fields of the
action. Let&amp;rsquo;s first look at the derivative term:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp; \dfrac{\delta}{\delta\Phi^{i}(y)}\left(\partial_{\mu}\Phi^{k}(x)\right)\left(\partial^{\mu}\Phi^{k}(x)\right)                         \\
&amp;amp;= \lim_{\epsilon\to0}\dfrac{
\partial^{\mu}\left(\Phi^{k}(x) + \epsilon\delta^{4}(x-y)\right)\partial^{\mu}\left(\Phi^{k}(x) + \epsilon\delta^{4}(x-y)\right)
-\partial_{\mu}\Phi^{k}(x)\partial_{\mu}\Phi^{k}(x)
}{\epsilon}\\
&amp;amp; = \lim_{\epsilon\to0}\dfrac{2\partial^{\mu}\Phi^{k}(x)\epsilon\partial^{\mu}\delta^{4}(x-y)\delta^{ik} + \mathcal{O}(\epsilon^{2})}{\epsilon} \\
&amp;amp; = 2\partial^{\mu}\Phi^{k}(x)\partial^{\mu}\delta^{4}(x-y)\delta^{ik}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Taking a second functional derivative, we find
$$
\begin{align}
\dfrac{\delta^{2}}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\left(\partial_{\mu}\Phi^{k}(x)\right)\left(\partial^{\mu}\Phi^{k}(x)\right)
&amp;amp; = 2\partial_{\mu}\delta^{4}(x-z)\partial^{\mu}\delta^{4}(x-y)\delta^{ij}            \\
&amp;amp; = -2\delta^{4}(x-z)\partial^{2}\delta^{4}(x-y)\delta^{ij} + \text{total derivative}
\end{align}
$$
Note that the derivative is with respect to $x$. The $\mu$ term gives us
$$\begin{align}
\dfrac{\delta^{2}}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\Phi^{k}\Phi^{k} = 2\delta^{4}(x-z)\delta^{4}(x-y)\delta^{ij}
\end{align}$$
The $\lambda$ term gives us
$$\begin{align}
\dfrac{\delta^{2}}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\Phi^{m}\Phi^{m}\Phi^{n}\Phi^{n}
&amp;amp; = 2\dfrac{\delta}{\delta\Phi^{j}(z)}\left(\delta^{im}\Phi^{m}\Phi^{n}\Phi^{n} + \delta^{in}\Phi^{n}\Phi^{n}\Phi^{n}\right)\delta^{4}(x-y) \\
&amp;amp; = 2\left(\delta^{ij}\Phi^{n}\Phi^{n} + \delta^{ij}\Phi^{n}\Phi^{n}\right)\delta^{4}(x-y)\delta^{4}(x-z)                                   \\
&amp;amp; \qquad +4\left(\Phi^{i}\Phi^{j} + \Phi^{i}\Phi^{j}\right)\delta^{4}(x-y)\delta^{4}(x-z)\notag                                             \\
&amp;amp; = 4\delta^{ij}\Phi^{n}\Phi^{n}\delta^{4}(x-y)\delta^{4}(x-z)                                                                              \\
&amp;amp; \qquad +8\Phi^{i}\Phi^{j}\delta^{4}(x-y)\delta^{4}(x-z)\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\Phi^{i}=\Phi^{i}_{\text{cl}}}
&amp;amp; =-\delta^{4}(x-z)\partial^{2}\delta^{4}(x-y)\delta^{ij}                                                                           \\
&amp;amp; \qquad + \mu^{2}\delta^{4}(x-y)\delta^{4}(x-z)\delta^{ij} -\lambda\delta^{ij}\Phi^{n}\Phi^{n}\delta^{4}(x-y)\delta^{4}(x-z)\notag \\
&amp;amp; \qquad -2\lambda\Phi_{\text{cl}}^{i}\Phi_{\text{cl}}^{j}\delta^{4}(x-y)\delta^{4}(x-z)\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;To make things easier, let&amp;rsquo;s rotate $\Phi_{\text{cl}}^{i}$ such that&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Phi_{\text{cl}}^{i} \to (0,0,\dots,0,\Phi_{\text{cl}})
\end{align}$$&lt;/p&gt;
&lt;p&gt;Then,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Phi^{n}\Phi^{n} = \Phi_{\text{cl}}^{2} \qquad \text{and} \qquad \Phi_{\text{cl}}^{i}\Phi_{\text{cl}}^{j} =\Phi_{\text{cl}}^{2}\delta^{iN}\delta^{jN}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Denoting $\delta^{4}(x-y)$ as $\delta_{xy}$, we find that&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\mathbf{\Phi}=\mathbf{\Phi}_{\text{cl}}}
&amp;amp; =-\delta_{xz}\partial^{2}\delta_{xy}\delta^{ij}                                                                       \\
&amp;amp; \qquad + \mu^{2}\delta_{xy}\delta_{xz}\delta^{ij} -\lambda\delta^{ij}\Phi_{\text{cl}}^{2}\delta_{xy}\delta_{xz}\notag \\
&amp;amp; \qquad -2\Phi_{\text{cl}}^{2}\delta^{iN}\delta^{jN}\delta_{xy}\delta_{xz}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int\mathcal{D}\mathbf{\eta} &amp;amp; \exp(\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{i}(y)\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\mathbf{\Phi}=\mathbf{\Phi}_{\text{cl}}}\eta^{j}(z))\\\
&amp;amp; = \int\mathcal{D}\mathbf{\eta}\exp\bigg{(}-\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{1}(y)\delta_{xz}\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2} \right)\delta_{xy}\eta^{1}(z)\notag \\
&amp;amp; \qquad +\cdots\notag\\
&amp;amp; \qquad -\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{N-1}(y)\delta_{xz}\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2} \right)\delta_{xy}\eta^{N-1}(z)\notag\\
&amp;amp; \qquad -\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{N}(y)\delta_{xz}\left(\partial^{2} + 3\lambda\Phi_{\text{cl}}^{2} -\mu^{2} \right)\delta_{xy}\eta^{N}(z)\bigg{)}\notag
\end{align}$$&lt;/p&gt;
&lt;p&gt;Each of these terms in going to produce a term proportional to the inverse square root of the determinant of the operator sandwiched between the $\eta$&amp;rsquo;s:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int\mathcal{D}\mathbf{\eta} &amp;amp; \exp(-\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{i}(y)M(y,z)\eta^{j}(z)) \propto \left(\det M(y,z)\right)^{-1/2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Each of these operators has a Klein-Gordon operator: $\partial^{2} + m^{2}$. Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\left(\det M(y,z)\right)^{-1/2} = \exp(-\dfrac{1}{2}\log\det M(y,z))
\end{align}$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\log\det M(y,z) = \mathrm{tr}\log M(y,z)
\end{align}$$&lt;/p&gt;
&lt;p&gt;we have&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int\mathcal{D}\mathbf{\eta} &amp;amp; \exp(\dfrac{i}{2}\int d^{4}y\int d^{4}z\eta^{i}(y)\dfrac{\delta^{2}S}{\delta\Phi^{i}(y)\delta\Phi^{j}(z)}\bigg{|}_{\mathbf{\Phi}=\mathbf{\Phi}_{\text{cl}}}\eta^{j}(z)) \\
&amp;amp; \qquad =
\exp(-\dfrac{1}{2}\mathrm{tr}\log\left(
\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{N-1}
\left(\partial^{2} + 3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)\right))\notag
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, our effective action is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Gamma[\Phi_{\text{cl}}] = S[\Phi_{\text{cl}}] + \dfrac{i}{2}\mathrm{tr}\log\left(
\left(\partial^{2} + \lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{N-1}
\left(\partial^{2} + 3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;To evaluate these determinants, we can use&lt;/p&gt;
&lt;p&gt;$$\begin{align}\label{trace_operator}
\mathrm{tr}\log
\left(\partial^{2} + m^{2}\right)
&amp;amp; = \int d^{4}x \langle{x}\log
\left(\partial^{2} + m^{2}\right)\rangle{x}\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}k}{(2\pi)^{4}}\int \dfrac{d^{4}p}{(2\pi)^{4}} \langle{x}\rangle{p}\langle{p}\log
\left(\partial^{2} + m^{2}\right)\rangle{k}\langle{k}\rangle{x}\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}k}{(2\pi)^{4}}\int \dfrac{d^{4}p}{(2\pi)^{4}} \langle{x}\rangle{p}(2\pi)^{4}\delta^{4}(k-p)\log
\left(-k^{2} + m^{2}\right)\langle{k}\rangle{x}\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}p}{(2\pi)^{4}} \left|\langle{x}\rangle{p}\right|^{2}\log
\left(-p^{2} + m^{2}\right)\\\
&amp;amp; = \int d^{4}x\int \dfrac{d^{4}p}{(2\pi)^{4}} \log
\left(-p^{2} + m^{2}\right)\\\
&amp;amp; = VT\int \dfrac{d^{4}p}{(2\pi)^{4}} \log
\left(-p^{2} + m^{2}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;This last integral can be evaluated using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\log(-p^{2}+m^{2}) = -\lim_{\alpha\to0}\dfrac{\partial}{\partial\alpha}\dfrac{1}{(-p^{2}+m^{2})^{\alpha}}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using this, moving to Euclidean space and switching our integration dimension to $d$, we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\int \dfrac{d^{d}p}{(2\pi)^{d}} \log
\left(-p^{2} + m^{2}\right)
&amp;amp; = -i\lim_{\alpha\to0}\dfrac{\partial}{\partial\alpha}\int \dfrac{d^{d}p_{E}}{(2\pi)^{d}}\dfrac{1}{\left(p_{E}^{2} + m^{2}\right)^{\alpha}}                                   \\
&amp;amp; =-i\lim_{\alpha\to0}\dfrac{\partial}{\partial\alpha} \dfrac{(-1)^{\alpha}}{(4\pi)^{d/2}}\dfrac{\Gamma(\alpha-d/2)}{\Gamma(\alpha)}\left(\dfrac{1}{m^{2}}\right)^{\alpha-d/2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Gamma(\alpha) = \dfrac{1}{\alpha} - \gamma + \mathcal{O}(\alpha)
\end{align}$$&lt;/p&gt;
&lt;p&gt;we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{\partial}{\partial\alpha}\dfrac{1}{\Gamma(\alpha)} = 1
\end{align}$$&lt;/p&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{align}\label{log_integral}
\int \dfrac{d^{d}p}{(2\pi)^{d}} \log
\left(-p^{2} + m^{2}\right)
&amp;amp; =-i\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(m^{2}\right)^{d/2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, we have found that,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\Gamma[\Phi_{\text{cl}}] = S[\Phi_{\text{cl}}] + \dfrac{VT}{2}\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} + \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
S[\Phi_{\text{cl}}]
&amp;amp; = \int d^{4}x \dfrac{1}{2}\left(\partial_{\mu}\Phi_{\text{cl}}\right)\cdot\left(\partial^{\mu}\Phi_{\text{cl}}\right) + \dfrac{1}{2}\mu^{2}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right) - \dfrac{\lambda}{4}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right)^{2} \\
&amp;amp; = VT\left(\dfrac{1}{2}\mu^{2}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right) - \dfrac{\lambda}{4}\left(\Phi_{\text{cl}}\cdot\Phi_{\text{cl}}\right)^{2}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, the effective potential is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
V_{\text{eff}}(\Phi_{\text{cl}}) &amp;amp; = -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4} \\
&amp;amp; \qquad-\dfrac{1}{2}\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} + \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}\right)\notag
\end{align}$$&lt;/p&gt;
&lt;p&gt;One will notice that this expression is divergent. The reason being that we
haven&amp;rsquo;t yet renormalized the effective potential. In the next section, we will
take care of these divergences in detail.&lt;/p&gt;
&lt;h3 id=&#34;renormalization-of-linear-sigma-model&#34;&gt;Renormalization of Linear Sigma Model&lt;/h3&gt;
&lt;p&gt;Before we can proceed, we need to renormalize the linear sigma model.
The renormalizable parameters are $Z_{a}$, the wave function
renormalizations, $\mu$, the masses and $\lambda$, the quartic
couplings. We thus augment the Lagrangian by the following counterterms:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\mathcal{L}&amp;amp; = \dfrac{1}{2}\left(\partial_{\mu}\mathbf{\Phi}\right)\cdot\left(\partial^{\mu}\mathbf{\Phi}\right) + \dfrac{1}{2}\mu^{2}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right) - \dfrac{\lambda}{4}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right)^{2}\\
&amp;amp; \qquad + \dfrac{1}{2}\delta_{Z}\left(\partial_{\mu}\mathbf{\Phi}\right)\cdot\left(\partial^{\mu}\mathbf{\Phi}\right) - \dfrac{1}{2}\delta_{\mu}\mu^{2}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right) - \dfrac{\delta_{\lambda}}{4}\left(\mathbf{\Phi}\cdot\mathbf{\Phi}\right)^{2}\notag\end{aligned}$$&lt;/p&gt;
&lt;p&gt;The Feynmann rules for the vertices and there corresponding counter terms
are given by:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Vertex&lt;/th&gt;
&lt;th&gt;Rule&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2-pt&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma3.png&#34; alt=&#34;renorm_linear_sigma3&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2-pt CT&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma4.png&#34; alt=&#34;renorm_linear_sigma4&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4-pt&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma1.png&#34; alt=&#34;renorm_linear_sigma1&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4-pt CT&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;renorm_linear_sigma2.png&#34; alt=&#34;renorm_linear_sigma2&#34; width=&#34;300&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;First, we will compute the mass renormalization graph. This graph is:&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma5.png&#34; alt=&#34;renorm_linear_sigma5&#34; width=&#34;300&#34;/&gt;
&lt;p&gt;Suppose that $\Phi_{b}$ is running in the loop. Then, the value of this
graph in $d=4-\epsilon$ dimensions is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Sigma = \dfrac{1}{2}(-2i\lambda)\left(\delta_{ab}\delta_{cc} + \delta_{ac}\delta_{bc}+\delta_{ac}\delta_{bc}\right)\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{i}{p^{2}+\mu^{2}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This is easily evaluated to&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Sigma = \lambda\delta_{ab}\left(N+2\right)\dfrac{(-1)i}{(4\pi)^{d/2}}\dfrac{\Gamma\left(1- \frac{d}{2}\right)}{\Gamma(1)}\left(-\dfrac{1}{\mu^{2}}\right)^{1- \frac{d}{2}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;In $d=4-\epsilon$ dimensions, the mass dimension of the fields is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\left[\Phi\right] = m^{(d-2)/2}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This means that&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
m^{d} = \left[\lambda\Phi^{4}\right] = m^{2d-4}\left[\lambda\right] \qquad \implies \qquad \left[\lambda\right] = m^{4-d} = m^{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s keep $\lambda$ dimensionless. To do this, we define&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\lambda = \left(\xi^{2}\right)^{\epsilon/2}\tilde{\lambda}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;where $\xi$ has dimensions of mass. Additionally, recall that the Gamma
function near $x=-n$ is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\Gamma(x) = \dfrac{(-1)^{n}}{n!}\left(\dfrac{1}{x+n}+1+\cdots + \dfrac{1}{n} + \mathcal{O}(x+n)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This means that&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\Gamma\left(\dfrac{\epsilon}{2}-1\right) = -\left(\dfrac{2}{\epsilon}+1-\gamma + \mathcal{O}(\epsilon)\right) = \dfrac{2}{\epsilon}\left(1+ \dfrac{2}{\epsilon}\log(e^{1-\gamma})+ \mathcal{O}(\epsilon)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Now, we have that, to order $\epsilon$,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\Sigma
&amp;amp; = -\tilde{\lambda}\delta_{ab}\left(N+2\right)\dfrac{\mu^{2}}{8\epsilon\pi^{2}}\left(1+\dfrac{\epsilon}{2}\log(4\pi)\right)\left(1-\dfrac{\epsilon}{2}\log(-\mu^{2})\right)\left(1+ \dfrac{\epsilon}{2}\log(e^{1-\gamma})\right)\left(1+\dfrac{\epsilon}{2}\log(\xi^{2})\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;And thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\boxed{\Sigma = -\tilde{\lambda}\delta_{ab}\left(N+2\right)\dfrac{\mu^{2}}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon}\left(1+\dfrac{\epsilon}{2}\log(\dfrac{4\pi\xi^{2}e^{1-\gamma}}{-\mu^{2}})\right)}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;The divergent piece is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\boxed{\Sigma = -\tilde{\lambda}\mu^{2}\delta_{ab}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s evaluate the other divergences. The source of the rest of the
divergences are from the following graphs:&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma6.png&#34; alt=&#34;renorm_linear_sigma6&#34; width=&#34;300&#34;/&gt;
&lt;p&gt;Let&amp;rsquo;s start by evaluating graph $a$. To avoid clutter, define
$C_{abcd} = \delta_{ab}\delta_{cd} + \delta_{ac}\delta_{bd} + \delta_{ad}\delta_{cb}$.
Then, the four-pt graph is:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = \dfrac{1}{2}\sum_{e,f}(-2i\lambda C_{abef})(-2i\lambda C_{efcd})\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{i}{(p_{s}+k)^{2}-m_{e}^{2}}\dfrac{i}{k^{2}-m_{f}^{2}} \\
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{1}{[(p_{s}+k)^{2}-m_{e}^{2}][k^{2}-m_{f}^{2}]}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;To evaluate this integral, we introduce Feynman parameters of the form:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\dfrac{1}{AB} = \int_{0}^{1}dx\int_{0}^{1}dy \dfrac{\delta(1-x-y)}{\left(Ax+By\right)^{2}} = \int_{0}^{1}dx\dfrac{1}{\left(B + (A-B)x\right)^{2}}\end{aligned}$$
Let&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
A &amp;amp; = (p_{s}+k)^{2}-m_{e}^{2} = k^{2} + 2p_{s}k + p_{s}^{2} -m_{e}^{2} \\
B &amp;amp; = k^{2}-m_{f}^{2}\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Then,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
B + (A-B)x
&amp;amp; = k^{2}-m_{f}^{2} + (k^{2} + 2p_{s}k + p_{s}^{2} -m_{e}^{2} - k^{2}+m_{f}^{2})x  \\
&amp;amp; = \left[k+x p_{s}k\right]^{2}+x(1-x)p_{s}^{2}-m_{f}^{2} + (m_{f}^{2}-m_{e}^{2})x
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Define&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\ell_a = k+x p_{s}k \qquad \text{and}\qquad \Delta = -x(1-x)p_{s}^{2}+m_{f}^{2} - (m_{f}^{2}-m_{e}^{2})x
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Then, switching integration variables to $\ell_{a}$,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx\int \dfrac{d^{d}k}{(2\pi)^{d}}\dfrac{1}{\left(\ell_{a}^{2}-\Delta\right)^{2}}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This can quickly be integrated to&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx \dfrac{(-1)^{2}i}{(4\pi)^{d/2}}\dfrac{\Gamma\left(2- \frac{d}{2}\right)}{\Gamma(2)}\left(\dfrac{1}{\Delta}\right)^{2-d/2}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Using $d=4-\epsilon$, this becomes&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx \dfrac{2i}{16\epsilon\pi^{2}}\left(1+ \dfrac{\epsilon}{2}\log(4\pi)\right)\left(1+ \dfrac{\epsilon}{2}\log(e^{-\gamma})\right)\left(1- \dfrac{\epsilon}{2}\log(\Delta)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\lambda = \tilde{\lambda}\left(\xi^{2}\right)\epsilon^{\epsilon/2}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This becomes&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\sum_{e,f}C_{abef}C_{efcd}\int_{0}^{1} dx \dfrac{2i}{16\epsilon\pi^{2}}\left(1+ \dfrac{\epsilon}{2}\log(\dfrac{4\pi\xi^{4}e^{-\gamma}}{\Delta})\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Using $m_{e}=m_{f}=\mu$, we find&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\left((N+4)\delta_{ab}\delta_{cd}+2\delta_{ac}\delta_{bd} + 2\delta_{ad}\delta_{bc}\right)\int_{0}^{1} dx \dfrac{2i}{16\epsilon\pi^{2}}\left(1+ \dfrac{\epsilon}{2}\log(\dfrac{4\pi\xi^{4}e^{-\gamma}}{\mu^{2}-x(1-x)p_{s}^{2}})\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;The divergence goes like&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\Gamma_{a}
&amp;amp; = 2\lambda^{2}\left((N+4)\delta_{ab}\delta_{cd}+2\delta_{ac}\delta_{bd} +
2\delta_{ad}\delta_{bc}\right)\dfrac{2i}{16\epsilon\pi^{2}} + \text{finite}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;This is exactly what we would get if we did the other diagrams, but with
the indices swapped. Adding everything up, we find&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\boxed{\Gamma
= 2\lambda^{2}\left(\delta_{ab}\delta_{cd}+\delta_{ac}\delta_{bd} + \delta_{ad}\delta_{bc}\right)(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon} + \text{finite}}\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We can now determine $\delta_{\mu},\delta_{Z}$ and $\delta_{\lambda}$.
For the self-energy graph, we require that, at $p^{2}=\mu^{2}$, the sum
of 1PI diagrams be zero. Diagramatically, this looks like:&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma7.png&#34; alt=&#34;renorm_linear_sigma7&#34; width=&#34;500&#34;/&gt;
&lt;p&gt;where the one-particle-irreducible diagrams. The sum in is given by&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\dfrac{i}{p^{2}+\mu^{2}} &amp;amp; = \dfrac{1}{Z}\left(\dfrac{i}{p^{2}+\mu_{0}^{2}} + \dfrac{i}{p^{2}+\mu_{0}^{2}}i\Sigma\dfrac{i}{p^{2}+\mu_{0}^{2}} + \dfrac{i}{p^{2}+\mu_{0}^{2}}i\Sigma\dfrac{i}{p^{2}-\mu_{0}^{2}}i\Sigma\dfrac{i}{p^{2}+\mu_{0}^{2}} + \cdots\right) \\
&amp;amp; = \dfrac{1}{Z}\dfrac{i}{p^{2}+\mu_{0}^{2}}\dfrac{1}{1 + \frac{\Sigma}{p^{2}+\mu_{0}^{2}}}\\
&amp;amp; = \dfrac{1}{Z}\dfrac{i}{p^{2}+\mu_{0}^{2} + \Sigma}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;where $Z = 1 + \delta_{Z}$ and $\mu_{0}^{2} = \left(1+\delta_{\mu}\right)\mu_{R}^{2}$.
The denominator is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
Z(p^{2}-\mu_{0}^{2} + \Sigma) = p^{2} +\mu_{R}^{2} -
\delta_{Z}p^{2}+\mu_{R}^{2}\left(\delta_{Z}+\delta_{\mu}\right) + \Sigma(p^{2})
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Our renormalization condition will require that this quantity is equal
to $p^{2} -\mu_{R}^{2}$ at $p^{2} = \mu_{R}^{2}$. That is, the pole is
at $\mu_{R}^{2}$. This requires that&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
0=-\tilde{\lambda}_{R}\mu^{2}_{R}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon} + \mu_{R}^{2}\delta_{\mu}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Thus, $\delta_{Z} = 0$ and&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\delta_{\mu} =-\tilde{\lambda}\mu^{2}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We also require the amplitude of&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
i\mathcal{M}(\Phi_{a}\Phi_{b}\to\Phi_{c}\Phi_{d}) = -2i\lambda\left(\delta_{ab}\delta_{cd} +
\delta_{ac}\delta_{bd} + \delta_{ad}\delta_{cb}\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;at $p^{2}=4m^{2}$.&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma8.png&#34; alt=&#34;renorm_linear_sigma8&#34; width=&#34;500&#34;/&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;img src=&#34;renorm_linear_sigma9.png&#34; alt=&#34;renorm_linear_sigma9&#34; width=&#34;500&#34;/&gt;
&lt;p&gt;Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
0 &amp;amp; =-2i\delta_{\lambda}\left(\delta_{ab}\delta_{cd} + \delta_{ac}\delta_{bd} + \delta_{ad}\delta_{cb}\right)                                                   \\
&amp;amp; \qquad + 2i\lambda^{2}\left(\delta_{ab}\delta_{cd}+\delta_{ac}\delta_{bd} + \delta_{ad}\delta_{bc}\right)(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon}\notag\end{aligned}$$&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\delta_{\lambda} = \lambda^{2}(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s now return to the effective potential. The divergent part came from&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
-\dfrac{1}{2}\dfrac{\Gamma(-d/2)}{(4\pi)^{d/2}}\left(
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} + \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Letting $d=4-\epsilon$, we have that&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}  &amp;amp; = \left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\left(1- \dfrac{\epsilon}{2}\log(\lambda\Phi_{\text{cl}}^{2} -\mu^{2})\right)   \\
\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} &amp;amp; = \left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\left(1- \dfrac{\epsilon}{2}\log(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2})\right) \\
\Gamma(-d/2) &amp;amp; = \dfrac{1}{\epsilon}\left(1- \dfrac{\epsilon}{2}\left(\gamma- \dfrac{3}{2}\right)\right)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Now,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
&amp;amp; (N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2} +
\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{d/2}                                                                                                 \\
&amp;amp; = (N-1)\left(\lambda^{2}\Phi_{\text{cl}}^{4} -2\lambda\mu^{2}\Phi_{\text{cl}}^{2} + \mu^{4}\right) + \left(9\lambda^{2}\Phi_{\text{cl}}^{4}
-6\lambda\mu^{2}\Phi_{\text{cl}}^{2} + \mu^{4}\right) + \mathcal{O}(\epsilon)\notag \\
&amp;amp; = (N+8)\lambda^{2}\Phi_{\text{cl}}^{4} -2(N+2)\lambda\mu^{2}\Phi_{\text{cl}}^{2} + N\mu^{4} +\mathcal{O}(\epsilon)
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Therefore, the divergent part of the effective potential, before adding in the
counterterms, is&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
V_{\text{eff}} = -\dfrac{1}{32\epsilon\pi^{2}}\left((N+8)\lambda^{2}\Phi_{\text{cl}}^{4} -2(N+2)\lambda\mu^{2}\Phi_{\text{cl}}^{2} + N\mu^{4} \right) + \cdots
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;To add in the counterterms, we let&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\mu^{2} &amp;amp; \to \mu^{2}+\lambda\mu^{2}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{2}{\epsilon} \\
\lambda &amp;amp; \to\lambda + \lambda^{2}(N+8)\dfrac{1}{16\pi^{2}}\dfrac{2}{\epsilon}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We only make these changes to terms of order&lt;/p&gt;
&lt;p&gt;$\mathcal{O}(\epsilon^{0})$. Thus,&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
-\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4} \to -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4} -\lambda\mu^{2}\left(N+2\right)\dfrac{1}{16\epsilon\pi^{2}}\dfrac{1}{\epsilon}\Phi_{\text{cl}}^{2} + \lambda^{2}(N+8)\dfrac{1}{32\pi^{2}}\dfrac{1}{\epsilon}\Phi_{\text{cl}}^{4}
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Miraculously, we can see that the infinities attached to
$\Phi_{\text{cl}}^{2}$ and $\Phi_{\text{cl}}^{4}$ cancel! Our potential is now&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
V_{\text{eff}} &amp;amp; = -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4}\\
&amp;amp; \qquad +\dfrac{1}{4}\dfrac{1}{16\pi^{2}}\bigg{[}
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(\lambda\Phi_{\text{cl}}^{2} -\mu^{2})\notag\\
&amp;amp; \qquad +\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}) + \gamma- \dfrac{3}{2} - \log(4\pi)\bigg{]}\notag
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;We can modify our subtraction scheme in order to get rid of the annoying
constants and make the log dimensionless. Doing so, we obtain&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
V_{\text{eff}} &amp;amp; = -\dfrac{1}{2}\mu^{2}\Phi_{\text{cl}}^{2} + \dfrac{\lambda}{4}\Phi_{\text{cl}}^{4}                                                      \\
&amp;amp; \qquad +\dfrac{1}{4}\dfrac{1}{16\pi^{2}}\bigg{[}
(N-1)\left(\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(\dfrac{\lambda\Phi_{\text{cl}}^{2} -\mu^{2}}{\xi^{2}})\notag\\
&amp;amp; \qquad +\left(3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}\right)^{2}\log(\dfrac{3\lambda\Phi_{\text{cl}}^{2} -\mu^{2}}{\xi^{2}})\bigg{]}
\notag
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Where $\xi$ is a parameter with dimensions of mass.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Solving the Boltzmann Equation</title>
      <link>https://loganamorrison.github.io/post/solving-boltzman-equation/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/solving-boltzman-equation/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this notebook, we will investigate how to solve the Boltzmann equation in
order to determine the relic abundance of a species. Our focus will be on
a species which represents a dark matter (DM) particle. We will assume that the
dark matter interacts with the standard model (SM) through a massive mediator
with interactions that look like
$\bar{\chi}\chi\to \mathrm{SM}_{1} + \mathrm{SM}_{2}$, i.e. through a $2\to2$
interaction. For these types of interactions, the Boltzmann equation takes the
form of:
$$\begin{align}
\dfrac{dn}{dt} + 3Hn = -\langle\sigma v\rangle(n^2 - n_{\mathrm{eq}}^2)
\end{align}$$
where $n$ is the DM number density, $n_{\mathrm{eq}}$ is the DM equilibrium
number density, $H$ is the hubble constant and $\langle\sigma v\rangle$ is the
annihilation cross section for DM into SM particles. As is, this equation is
in poor form. We will make several changes to bring it into a more suitible
form for numerically solving.&lt;/p&gt;
&lt;p&gt;Our first change will be to define the so called comoving number density, $Y$.
This will be defined as:
$$\begin{align}
Y = \dfrac{n}{s}
\end{align}$$
where $s$ is the SM entropy density. Note that the total SM entropy is
conserved, i.e. $a^3s = \mathrm{constant}$ with $a$ being the scale factor of
the universe. This implies that:
$$\begin{align}
\dfrac{d}{dt}a^3s = 3\dfrac{da}{dt}a^2s + a^3\dfrac{ds}{dt} = 0
\end{align}$$
If we rearange this equation and recall that $d\log(a)/dt = H$, we find that:
$$\begin{align}
\dfrac{ds}{dt} = -3\dfrac{1}{a}\dfrac{da}{dt}s = -3Hs
\end{align}$$
This relation will allow us to determine $dY/dt$:
$$\begin{align}
\dfrac{1}{s}\dfrac{dn}{dt} &amp;amp;= \dfrac{dY}{dt} - 3HY
\end{align}$$
Therefore, the Boltzmann equation for $Y$ is:
$$\begin{align}
\dfrac{dY}{dt} = -s\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)
\end{align}$$
where we defined $Y_{\mathrm{eq}} = n_{\mathrm{eq}}/s$. Next, we will change
independent variables from time to temperature. To do this, we again us
$\dot{s}/s = -3H$. Using the explict form $s=2\pi^2/45 hT^3$
($h$ being the number of d.o.f. in entropy),
one finds that:
$$\begin{align}
-3H = \dfrac{1}{s}\dfrac{ds}{dt} =
\dfrac{3}{T}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\dfrac{dT}{dt}
\end{align}$$
Therefore,
$$\begin{align}
\dfrac{dt}{dT} =-\dfrac{1}{HT}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\end{align}$$
We can use this relationship to determine $dY/dT$:
$$\begin{align}
\dfrac{dY}{dT} = \dfrac{dt}{dT}\dfrac{dY}{dt} =
\dfrac{s}{HT}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)
\end{align}$$
Another change people usually make is again changing the indepednent variable
from $T\to x = m/T$ where $m$ is the mass of the DM particle. If we make this
change, we find that:
$$\begin{align}
\dfrac{dY}{dx} =-
\dfrac{s}{Hx}\left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)
\end{align}$$
We can expand out the definitions of $s$ and $H=\sqrt{8\pi\rho/3}/M_{\mathrm{pl}}$
$$\begin{align}
H = \sqrt{\dfrac{8\pi G}{3}\rho} =
\sqrt{\dfrac{8\pi^3}{90}}\sqrt{g}\dfrac{T^2}{M_{\mathrm{pl}}}
\end{align}$$
to obtain:
$$\begin{align}
\boxed{\dfrac{dY}{dx} =-
\sqrt{\dfrac{\pi}{45}}\dfrac{m M_{\mathrm{pl}}}{x^2}g^{1/2}_{\star}
\langle\sigma v\rangle(Y^2 - Y_{\mathrm{eq}}^2)}
\end{align}$$
where we defined:
$$\begin{align}
g^{1/2}_{\star} \equiv \left(1 + \dfrac{T}{3h}\dfrac{dh}{dT}\right)
\dfrac{h}{\sqrt{g}}
\end{align}$$
This is typically how people quote the Boltzmann equation. However, one final
set of modifications needs to be made for numerical purposes. $Y$ can vary
over many orders of magnitude. Thus, it is very useful to define
$W\equiv\log(Y)$. Then, $W$ only undergoes order $1$ changes. Additionally, it
is useful to work with the $\log(x)$ instead of $x$. Making these changes
we find that:
$$\begin{align}
\boxed{\dfrac{dW}{d\log(x)} =-
\sqrt{\dfrac{\pi}{45}}\dfrac{m M_{\mathrm{pl}}}{x}g^{1/2}_{\star}
\langle\sigma v\rangle(e^{W} - e^{2W_{\mathrm{eq}}-W})}
\end{align}$$
In the next sections, we will solve this equation.&lt;/p&gt;
&lt;h2 id=&#34;simple-model&#34;&gt;Simple Model&lt;/h2&gt;
&lt;p&gt;In many cases, the thermally averaged annihilation cross section can be brought
into the form:
$$\begin{align}
\langle\sigma v\rangle = \langle\sigma v\rangle_{0}x^{-n} +
\mathrm{O}(x^{-n-1})
\end{align}$$
In this form, we can simplify the Boltzmann equation to:
$$\begin{align}
\dfrac{dW}{d\log(x)} =-
\sqrt{\dfrac{\pi}{45}}\dfrac{m M_{\mathrm{pl}}}{x^{n+1}}g^{1/2}_{\star}
\langle\sigma v\rangle_{0}(e^{W} - e^{2W_{\mathrm{eq}}-W})
\end{align}$$&lt;/p&gt;
&lt;h4 id=&#34;evolution-of-w--logns&#34;&gt;Evolution of $W = \log(n/s)$&lt;/h4&gt;
&lt;p&gt;Now, let&amp;rsquo;s define a model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DarkSUN

mutable struct DarkMatterModel
  χ::ThermodynamicFermion
  n::Int64
  sm::StandardModel
  σ0::Float64
end

&amp;quot;&amp;quot;&amp;quot;
  DarkMatterModel(m::Float64, n::Int64, σ0::Float64)

Default constructor for DM model

# Arguments
- `m::Float64`: DM mass
- `n::Int64`: interaction order - 0: s-wave, 1: p-wave and so on.
- `σ0::Float64`: thermal cross section coefficient
&amp;quot;&amp;quot;&amp;quot;
function DarkMatterModel(m::Float64, n::Int64, σ0::Float64)
  χ = ThermodynamicFermion(m, 2.0)
  DarkMatterModel(χ, n, StandardModel(), σ0)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To solve the Boltzmann equation, we will use &lt;code&gt;DifferentialEquantions.jl&lt;/code&gt;
(for solving the differential equation) and &lt;code&gt;DarkSUN&lt;/code&gt; (for thermal functions
such as $g^{1/2}_{\star}$ and $n_{\mathrm{eq}}$.) Let&amp;rsquo;s define the Boltzmann
equation:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DifferentialEquations

const Mpl = 1.220910e19

&amp;quot;&amp;quot;&amp;quot;
  boltzmann(w, p, logx)

Boltzmann equation in `DifferentialEquations.jl` format.

# Arguments
- `dW::Array{Float64, 1}`: derivative of log of number density over SM entropy density
- `W::Array{Float64, 1}`: log of number density over SM entropy density
- `model::DarkMatterModel`: model
- `logx::Float64`: log of mass over temperature
&amp;quot;&amp;quot;&amp;quot;
function boltzmann!(dW::Array{Float64, 1}, W::Array{Float64, 1},
                   model::DarkMatterModel, logx::Float64)
  x::Float64 = exp(logx)
  # update the temperature
  model.χ.T = model.χ.mass / x
  model.sm.T = model.χ.mass / x
  pf::Float64 = (-sqrt(π/45) * model.σ0 * model.χ.mass * Mpl * sqrt_gstar(model.sm) / x^(model.n+1))
  Weq::Float64 = log_neq(model.χ) - log_entropy_density(model.sm)
  dW[1] = pf * (exp(W[1]) - exp(2Weq - W[1]))
end


&amp;quot;&amp;quot;&amp;quot;
  jacobian(w, p, logx)

Jacobian of the boltzmann equation in `DifferentialEquations.jl` format.

# Arguments
- `J::Array{Float64, 2}`: derivative of log of number density over SM entropy density
- `W::Array{Float64, 1}`: log of number density over SM entropy density
- `model::DarkMatterModel`: model
- `logx::Float64`: log of mass over temperature
&amp;quot;&amp;quot;&amp;quot;
function jacobian!(J::Array{Float64, 2}, W::Array{Float64, 1},
                   model::DarkMatterModel, logx::Float64)
  x::Float64 = exp(logx)
  # update the temperature
  model.χ.T = model.χ.mass / x
  model.sm.T = model.χ.mass / x
  pf::Float64 = (-sqrt(π/45) * model.σ0 * model.χ.mass * Mpl * sqrt_gstar(model.sm) / x^(model.n+1))
  Weq::Float64 = log_neq(model.χ) - log_entropy_density(model.sm)
  J[1,1] = pf * (exp(W[1]) + exp(2Weq - W[1]))
end;

&amp;quot;&amp;quot;&amp;quot;
  solve(model, logxspan)

Solve the Boltzmann equation for the given model.

# Arguments
- `model::DarkMatterModel`: DM model
- `logxspan::Tuple{Float64}`: range of log(x)
&amp;quot;&amp;quot;&amp;quot;
function solve!(model::DarkMatterModel, logxspan::Tuple{Float64, Float64})
  # Initialize temperatures
  model.χ.T = model.χ.mass * exp(-logxspan[1])
  model.sm.T = model.χ.mass * exp(-logxspan[1])
  # Initial value for W
  W0 = log_neq(model.χ) - log_entropy_density(model.sm)
  # Create ODE problem
  ff = ODEFunction(boltzmann!;jac=jacobian!)
  prob = ODEProblem(ff,[W0],logxspan, model)
  # Solve it!
  solve(prob, Rodas5(autodiff=false));
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s solve for various values of $\sigma_{0}$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Values for logx
logxspan = (log(1), log(500))
σ0s = [1e-7, 1e-8, 1e-9, 1e-10]
models = [DarkMatterModel(100.0, 0, σ0) for σ0 in σ0s]
sols = [solve!(model, logxspan) for model in models];
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can plot the solution:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

plt.figure(dpi=100)
for (i, sol) in enumerate(sols)
  plt.plot(sol.t, sol[1,:], label=L&amp;quot;$\sigma_{0} = $&amp;quot;*string(σ0s[i]))
end
plt.ylabel(L&amp;quot;$W$&amp;quot;, fontsize=16)
plt.xlabel(L&amp;quot;$\log(x)$&amp;quot;, fontsize=16)
plt.xlim([logxspan[1], logxspan[2]])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_10147bd2bacfaa1aa815628983cdfff4.webp 400w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_56d2474567ca18be94e709899cdf0bb6.webp 760w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_4_1_hu3b2444c456dd439a1d6cad1e0dd242c4_24211_10147bd2bacfaa1aa815628983cdfff4.webp&#34;
               width=&#34;578&#34;
               height=&#34;442&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;relic-densities&#34;&gt;Relic Densities&lt;/h4&gt;
&lt;p&gt;Recall that the relic density is computed using:
$$\begin{align}
\Omega_{\chi} h^2 = \dfrac{s_{0}}{\rho_{c}}m_{\chi}Y(x=\infty)
\end{align}$$
where $s_{0} = 2891.2 \mathrm{cm}^{-3}$ and
$\rho_{c} =1.05375\times10^{-5}\mathrm{h}^2\mathrm{GeV}\mathrm{cm}^{-3}$. Let&amp;rsquo;s
perform the excercise of computing the relic density for values values of
$m_{\chi}$ and $\langle\sigma v\rangle_{0}$. We will then plot the contours
for which the combination $(m_{\chi}, \langle\sigma v\rangle_{0})$ gives the
correct observed relic density, which is $\Omega_{\chi}h^2=0.1198$. First,
let&amp;rsquo;s write a function to solve the Boltzmann equantion and compute the relic
density:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;const ρc = 1.05375e-5
const s₀ = 2891.2

function relic_density(model::DarkMatterModel)
  sol = solve!(model, (log(1), log(1000)))
  s₀ / ρc * model.χ.mass * exp(sol[1, end])
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&amp;rsquo;s compute the relic density for DM masses between $10$ and
$10^4\mathrm{GeV}$ with cross sections between $10^{-12}$ and
$10^{-7} \mathrm{GeV}^{-2}$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;mχs = 10 .^(range(-1, stop=4, length=150))
σ0s = 10 .^(range(-12, stop=-7, length=150))
models = [DarkMatterModel(mχ, 0, σ0) for mχ in mχs, σ0 in σ0s]
Ωh²s = [relic_density(model) for model in models];
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&amp;rsquo;s plot the contours of correct relic density:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Contour
const Ωh²cdm = 0.1198

cs = contour(mχs, σ0s, Ωh²s, Ωh²cdm)

plt.figure(dpi=100)
for line in lines(cs)
  xs, ys = coordinates(line)
  plt.plot(xs, ys .* 1.16733e-17 * 1e26) # convert units to 10^-26 cm^3/s
end
plt.xscale(&amp;quot;log&amp;quot;)
plt.ylabel(L&amp;quot;$\langle\sigma v\rangle_{0} \ (10^{-26}\mathrm{cm}^{3}/\mathrm{s})$&amp;quot;, fontsize=16)
plt.xlabel(L&amp;quot;$m_{\chi} \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.ylim([0, 6])
plt.xlim([minimum(mχs),maximum(mχs)])
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_83f099ab6a750d7c7e3358d385183d5e.webp 400w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_412cf33d3a1dd3cf0474bbce2a0fddf1.webp 760w,
               /post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/solving-boltzman-equation/2019-08-24-solving-the-boltzmann-equation_7_1_hu31f3b955834c97c4dd7a43520c87a52f_16602_83f099ab6a750d7c7e3358d385183d5e.webp&#34;
               width=&#34;571&#34;
               height=&#34;444&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Temperature Evolution of a Decoupled Dark Sector</title>
      <link>https://loganamorrison.github.io/post/temp-evolution-decoupled/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/temp-evolution-decoupled/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this document, we will invesigate how to compute the temperature and
evolution of temperature of a species which is decoupled from the standard
model. For simplicity, we will consider a set of particles which are decoupled
from the standard model but are coupled in their own sector. If a species
or set of species is completely decoupled from the standard model, then there
should be no entropy exchange between the standard model and the secluded
sector. Let&amp;rsquo;s denote the secluded sector as the &amp;ldquo;dark&amp;rdquo; sector. Then, the entropy
density of the dark sector, denoted by $s_{d}$, is conserved in totality, i.e.,
$\frac{d}{dt}(a^3s_{d}) = 0$ ($a$ is the scale factor of the universe.) This
implies that the ratio of entropy densities of the dark and standar model is
a constant:
$$\begin{align}
\mathrm{constant} = \dfrac{a^3s_{d}(T_{d})}{a^3s(T)} = \dfrac{s_{d}(T_{d})}{s(T)}
\end{align}$$
where $s$ is the standard model entropy density, $T_{d}$ is the dark sector
temperature and $T$ is the standard model temperature. Since this ratio is a
constant, we can evaluate the ratio at different temperature and still have
equality. i.e.:
$$\begin{align}
\dfrac{s_{d}(T_{d,1})}{s(T_1)} = \dfrac{s_{d}(T_{d,2})}{s(T_2)}
\end{align}$$
Let&amp;rsquo;s parameterize the entropy densities in terms of their repsective
relativistic degrees of freedom:
$$\begin{align}
s_{d}(T_{d}) &amp;amp;= \dfrac{2\pi^2}{45}h_{d}(T_{d})T_{d}^3\
s(T) &amp;amp;= \dfrac{2\pi^2}{45}h(T)T^3
\end{align}$$
Then, the ratio of entropy densities becomes:
$$\begin{align}
\dfrac{s_{d}(T_{d})}{s(T)} = \dfrac{h_{d}(T_{d})}{h(T)}\left(\dfrac{T_{d}}{T}\right)^3
\end{align}$$
We will define the ratio of dark to standard model temperatures as
$\xi\equiv T_{d}/T$. Now, our conservation equation reads:
$$\begin{align}
\dfrac{h_{d}(T_{d,1})}{h(T_1)}\xi_{1}^3 = \dfrac{h_{d}(T_{d,2})}{h(T_2)}\xi_{2}^3
\end{align}$$
Suppose that in the very early universe, the ratio of temperatures is known.
Let&amp;rsquo;s call it $\xi_{\infty} = T_{d,\infty}/T_{\infty}$. Then, at lower
temperatures, the ratio will be given by:
$$\begin{align}
\xi^3 = \dfrac{h(T)}{h_{d}(T_{d})}\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})}\xi_{\infty}^3
= \dfrac{h(T)}{h_{d}(T_{d})} C_{\infty}
\end{align}$$
where we defined $C_{\infty} = \xi_{\infty}^3h_{d}(T_{d,\infty})/h(T_{\infty})$.
Thus, the evolution of the dark sector temperature is governed by the evolution
of its own d.o.f. and the standard model d.o.f. In principle, if the ratio at
very large temperatures is known, then the ratio at lower temperatures can be
computed numerically. In the next sections, we will figure out how to
numerically determine the ratio at lower temperatures. We will do so for two
cases: one case where all dark sector particles are massive and two where there
is at least one massless species. The reason for the distinction can be seen
from the above equation. For massive particles, the entropy density drops off
exponentially once the temperature drops bellow its mass. Therefore, if all
particles are massive, the dark temperature will increase exponentially
compared to the standard model as long as the massive particles are in kinetic
equilibrium. If there is at least one massless particle, the temperature never
undergoes an exponetial increase.&lt;/p&gt;
&lt;h2 id=&#34;approximate-form-of-dof-in-entropy&#34;&gt;Approximate Form of D.O.F in Entropy&lt;/h2&gt;
&lt;p&gt;Here we give results for the general form of $h_{d}(T_{d})$. It is:
$$\begin{align}
h_{d}(T_{d}) = \dfrac{45}{4\pi^4}\sum_{i}\left(\dfrac{T_{i}}{T_{d}}\right)^3
g_{i}x_{i}^3\sum_{m=1}^{\infty}\dfrac{(\mp1)^{m+1}}{m}K_{3}(mx_{i})
\end{align}$$
where the sum runs over all particles in the sector, $g_{i}$ is the number
of internal d.o.f. in species $i$, $T_{i}$ is the temperature of species $i$,
and $x_{i} = m_{i}/T_{i}$. Typically, it is
sufficient to keep only the $m=1$ term in the series, yielding:
$$\begin{align}
h_{d}(T_{d}) = \dfrac{45}{4\pi^4}\sum_{i}\left(\dfrac{T_{i}}{T_{d}}\right)^3
g_{i}x_{i}^3K_{3}(x_{i}) =
\dfrac{45}{4\pi^4 T_{d}^3}\sum_{i}g_{i}m_{i}^3K_{3}(m_{i}/T_{i})
\end{align}$$
For a massless species, one finds that:
$$\begin{align}
m_{i}^3K_{3}(m_{i}/T_{i}) \to 8T_{i}^3
\end{align}$$
Therefore, the general expression is:
$$\begin{align}
h_{d}(T_{d}) =
\dfrac{90}{\pi^4}\sum_{m_{i}=0}g_{i} +
\dfrac{45}{4\pi^4}\sum_{m_{i}\neq0}g_{i}x_{i}^3K_{3}(x_{i}) + \cdots
\end{align}$$
where the $\cdots$ represent terms that are decoupled.&lt;/p&gt;
&lt;h2 id=&#34;case-1-all-massive-dark-sector-particles&#34;&gt;Case 1: All Massive Dark Sector Particles&lt;/h2&gt;
&lt;p&gt;The equation that we wish to solve is the following:
$$\begin{align}
\xi^3h_{d}(\xi T) = h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})}\xi_{\infty}^3
\end{align}$$
where, in this expression, one should consider $T$ as being fixed and $\xi$
being a function of $T$. Our goal will be to find upper and lower bounds on
the LHS of this equation. Note that
$$\begin{align}
\dfrac{45}{4\sqrt{2}\pi^{7/2}}\sum_{i}x_{i}^{5/2}e^{-x_{i}}
&amp;lt;
h_{d}(\xi T) &amp;lt; \sum_{i,b}g_{i} + \dfrac{7}{8}\sum_{i,f}g_{i}
\end{align}$$
where the sum over $b$ is for bosons and $f$ for fermions and
$x_{i} = m_{i} / T_{d} = m_{i} / \xi T$. We can therefore see a concrete
lower bound on $\xi$ from the upper inequality:
$$\begin{align}
\left(h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})
\sum_{i}\eta_{i}g_{i}}\right)^{1/3}\xi_{\infty} &amp;lt; \xi
\end{align}$$
Here we defined $\eta_{i} = 1$ for bosons and $7/8$ for fermions. To get the
upper bound on $\xi$, we need to work a bit harder. First, we notice the the
lower bound on $\xi^3h_{d}$ is a sum of positive terms. Thus, we can simply
take one of the terms and retain the inequality. Let&amp;rsquo;s take the term with the
smallest mass. Let $x_{\ell}$ denote the term with the smallest mass.
Additionally, let $\tilde{x}_{\ell} = \xi x_{\ell} = m_{\ell}/T$. Then,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{45}{4\sqrt{2}\pi^{7/2}}g_{\ell}\tilde{x}_{\ell}^{5/2}\sqrt{\xi}e^{-\tilde{x}_{\ell}/\xi}
&amp;lt; h(T) \dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})}\xi_{\infty}^3
\end{align}$$
The solution to this inequality is a product-log, or the Lambert-W function:
$$\begin{align}
\xi &amp;lt;
\dfrac{2\tilde{x}_{\ell}}{W\left(\dfrac{2025 g_{\ell}^2 h(T_{\infty})^2 \tilde{x_{\ell}}^6}
{16 h_{d}(T_{d,\infty})^2 h(T)^2 \pi^7 \xi_{\infty}^2}\right)}
\end{align}$$&lt;/p&gt;
&lt;p&gt;For example&amp;rsquo;s sake let&amp;rsquo;s suppose that we have a two-component dark sector with
particles $\eta$ and $\Delta$ which have masses $m_{\eta}$ and $m_{\Delta}$. Let
$\Delta$ be a fermion and $\eta$ be a scalar. Suppose these particles interact
with eachother but not with the standard model. Assume that these particles are
in kinetic equilibrium with a temperature $T_{d}$. We would like to determine
$T_{d}$ given a standard model temperature $T$. Let the masses be given by:
$$\begin{align}
m_{\eta} &amp;amp;= \Lambda / \sqrt{N}\
m_{\Delta} &amp;amp;= \Lambda N
\end{align}$$
We will take from the &lt;code&gt;DarkSUN&lt;/code&gt; package the functions for thermodynamic
particles and the SM thermal functions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DarkSUN

mutable struct ToyModel
  η::ThermodynamicParticle
  Δ::ThermodynamicParticle
  sm::StandardModel
  ξ::Float64
  N::Float64
  Λ::Float64

  function ToyModel(Λ::Float64, N::Float64)
    η = ThermodynamicBoson(Λ/sqrt(N), 1.0)
    Δ = ThermodynamicFermion(Λ*sqrt(N), 1.0)
    sm = StandardModel()
    new(η, Δ, sm, NaN, N, Λ)
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, $\xi$ will be given by $T_{d}/T$. We will assume that the value of $\xi$
at large temperatures is 1. i.e., perhaps the dark and SM sectors we coupled at
very large temperatures but decoupled at some point. Given this model,
let&amp;rsquo;s write functions to compute the d.o.f. stored in entropy of the dark
sector:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function dark_dof_entropy(model::ToyModel)
  hη = dof_entropy(model.η)
  hΔ = dof_entropy(model.Δ)
  h::Float64 = isfinite(hη) ? hη : 0.0
  h += isfinite(hΔ) ? hΔ : 0.0
  h
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s now write a function to find the temperature of the dark sector using
a bisection routine:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Roots
using LambertW

function ξ_lower_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1);
  ξinf::Float64 = 1.0
  sumg::Float64 = model.η.g + model.Δ.g * 7/8
  cbrt(hsm * hdinf * ξinf^3 / (hsminf * sumg))
end

function ξ_upper_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1)
  ξinf::Float64 = 1.0
  xl::Float64 = model.η.mass / T
  gl::Float64 = model.η.g
  lw_arg_num::Float64 = 2025gl^2 * hsminf^2 * xl^6
  lw_arg_den::Float64 = 16hdinf^2 * hsm^2 * π^7 * ξinf^2
  2xl / lambertw(lw_arg_num / lw_arg_den)
end

function compute_ξ(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7/8 * 4model.N + 2.0 * (model.N^2 - 1)
  ξinf::Float64 = 1.0
  function residual(ξ::Float64)
    model.η.T = ξ * T
    model.Δ.T = ξ * T
    res::Float64 = dark_dof_entropy(model)*ξ^3 -hsm*hdinf*ξinf^3/hsminf
    return res
  end
  lb::Float64 = ξ_lower_bound(T, model)
  ub::Float64 = ξ_upper_bound(T, model)

  ξsol::Float64 = find_zero(residual, (lb*0.99, ub*1.01), Bisection())
  model.ξ = ξsol
  ξsol
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&amp;rsquo;s pick various values of $T$ and solve for $T_{d}$:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

model = ToyModel(10.0, 1.0)

Ts = 10 .^(range(-2, stop=2.0, length=100))
ξs = [compute_ξ(T, model) for T in Ts]
ξs_ub = [ξ_upper_bound(T, model) for T in Ts]
ξs_lb = [ξ_lower_bound(T, model) for T in Ts]

plt.figure(dpi=100)
plt.title(L&amp;quot;Evolution of $\xi$ With All Massive Species&amp;quot;)
plt.plot(Ts, ξs)
plt.plot(Ts, ξs_ub, &amp;quot;--&amp;quot;, label=&amp;quot;upper-bound&amp;quot;)
plt.plot(Ts, ξs_lb, &amp;quot;--&amp;quot;, label=&amp;quot;lower-bound&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$T \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.ylabel(L&amp;quot;$\xi(T)$&amp;quot;, fontsize=16)
plt.ylim([1e-1,1e2])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_465648c16ff17f05d638cef1b8af5af8.webp 400w,
               /post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_19c79573a4dd3bc451b4a5400efea480.webp 760w,
               /post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_ad933b263457463d2c623440241d445c.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/temp-evolution-decoupled/_huf0980fb77da5da47f5c0de19f7bb20a8_29154_465648c16ff17f05d638cef1b8af5af8.webp&#34;
               width=&#34;584&#34;
               height=&#34;459&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We can therefore see that our bounds are correct and the root finding routine
correctly finds values of $\xi$ between these bounding curves. Additionally,
the value of $\xi$ is asymptotic to these bounding curves in the limits as
$T\to 0$ and $T\to\infty$. It is interesting to note the behavior of $\xi$ in
the limit as $T\to0$. We can see that $\xi$ exponentially grows, implies that
the dark sector becomes exponentially hot compared to the standard model. This
behavior does not continue forever, however. Once all of the dark sector
particles have left kinetic equilibrium, their temperatures will begin to drop
and simply red-shift away.&lt;/p&gt;
&lt;h2 id=&#34;case-2-one-massless-dark-sector-particle&#34;&gt;Case 2: One Massless Dark Sector Particle&lt;/h2&gt;
&lt;p&gt;The senario in which there exists at least on massless species is a bit simpler
than the case of all massive species. This is because the lower bound on
$\xi^3h_{d}$ is much simpler. In this case, the bounds on $\xi$ are:
$$\begin{align}
\left(h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})
\sum_{i}\eta_{i}g_{i}}\right)^{1/3}\xi_{\infty} &amp;lt; \xi &amp;lt;
\left(h(T)\dfrac{h_{d}(T_{d,\infty})}{h(T_{\infty})
g_{\ell}}\right)^{1/3}\xi_{\infty}
\end{align}$$
Here we&amp;rsquo;ve take $g_{\ell}$ to be one of the massless species. If we have many
massless species, we can strengthen the lower bound by replacing $g_{\ell}$
with a sum over all massles species. Let&amp;rsquo;s modify our previous model by adding
in a massless particle.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function dark_dof_entropy(model::ToyModel)
  hη = dof_entropy(model.η)
  hΔ = dof_entropy(model.Δ)
  h::Float64 = isfinite(hη) ? hη : 0.0
  h += isfinite(hΔ) ? hΔ : 0.0
  h += 2.0 # massles vector boson
  h
end

function ξ_lower_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1) + 2.0;
  ξinf::Float64 = 1.0
  sumg::Float64 = model.η.g + model.Δ.g * 7/8 + 2.0
  cbrt(hsm * hdinf * ξinf^3 / (hsminf * sumg))
end

function ξ_upper_bound(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7.0 / 8.0 * 4model.N + 2.0 * (model.N^2 - 1) + 2.0;
  ξinf::Float64 = 1.0
  sumg::Float64 = 2.0
  cbrt(hsm * hdinf * ξinf^3 / (hsminf * sumg))
end

function compute_ξ(T::Float64, model::ToyModel)
  model.sm.T = T
  hsm::Float64 = dof_entropy(model.sm)
  hsminf::Float64 = 106.83
  hdinf::Float64 = 7/8 * 4model.N + 2.0 * (model.N^2 - 1) + 2.0
  ξinf::Float64 = 1.0
  function residual(ξ::Float64)
    model.η.T = ξ * T
    model.Δ.T = ξ * T
    res::Float64 = dark_dof_entropy(model)*ξ^3 -hsm*hdinf*ξinf^3/hsminf
    return res
  end
  lb::Float64 = ξ_lower_bound(T, model)
  ub::Float64 = ξ_upper_bound(T, model)

  ξsol::Float64 = find_zero(residual, (lb*0.99, ub*1.01), Bisection())
  model.ξ = ξsol
  ξsol
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s plot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

model = ToyModel(10.0, 1.0)

Ts = 10 .^(range(-2, stop=2.0, length=100))
ξs = [compute_ξ(T, model) for T in Ts]
ξs_ub = [ξ_upper_bound(T, model) for T in Ts]
ξs_lb = [ξ_lower_bound(T, model) for T in Ts]

plt.figure(dpi=100)
plt.title(L&amp;quot;Evolution of $\xi$ With a Massless Species&amp;quot;)
plt.plot(Ts, ξs)
plt.plot(Ts, ξs_ub, &amp;quot;--&amp;quot;, label=&amp;quot;upper-bound&amp;quot;)
plt.plot(Ts, ξs_lb, &amp;quot;--&amp;quot;, label=&amp;quot;lower-bound&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$T \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.ylabel(L&amp;quot;$\xi(T)$&amp;quot;, fontsize=16)
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_1cfafb771cd77b42bf735bd6eb1b3d44.webp 400w,
               /post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_e899de8ac5b52ef75346b2468ca2caf5.webp 760w,
               /post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_e8e876b2eb307f920c9ab8f1684cfe5a.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/temp-evolution-decoupled/_hu715cf947b10252ae81e167eb1502f2d6_28611_1cfafb771cd77b42bf735bd6eb1b3d44.webp&#34;
               width=&#34;606&#34;
               height=&#34;459&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The behavior that we are seeing shouldn&amp;rsquo;t be too surprising. Our bounding
curves for $\xi$ are both proportional to $h(T)$. Therefore, $\xi$ simply
interpolates bewteen to different scalings of $h(T)$.&lt;/p&gt;
&lt;h2 id=&#34;case-3-sm-temperature-from-the-dark-temperature&#34;&gt;Case 3: SM Temperature from the Dark Temperature&lt;/h2&gt;
&lt;p&gt;Suppose we want to compute the tempertature of the SM in given the a dark
sector temperature. Then, we need to solve the following equation:
$$\begin{align}
\xi^3(T_{d}) = \dfrac{T_{d}^3}{T^3} = \dfrac{h(T)}{h_{d}(T_{d})}C_{\infty}
\end{align}$$
In this case, one should think of $T_{d}$ as a fixed number and $T$ being a
function of $T_{d}$. Isolating the constant pieces, we find:
$$\begin{align}
h(T)T^3 = \dfrac{T_{d}^3h_{d}(T_{d})}{C_{\infty}}
\end{align}$$
The LHS of this equation is constant. Let&amp;rsquo;s look at a plot $h(T)$ for the
SM.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using DelimitedFiles
import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

sm_data = readdlm(string(@__DIR__) * &amp;quot;assets/data/smdof.csv&amp;quot;, &#39;,&#39;, skipstart=1)
sm_data_ts = sm_data[:, 1];
sm_data_hs = sm_data[:, 3];

plt.figure(dpi=100)
plt.plot(sm_data_ts, sm_data_hs)
plt.plot(sm_data_ts, [sm_data_hs[end] for _ in 1:length(sm_data_ts)], &amp;quot;k--&amp;quot;)
plt.plot(sm_data_ts, [sm_data_hs[1] for _ in 1:length(sm_data_ts)], &amp;quot;k--&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.ylabel(L&amp;quot;$h_{\mathrm{eff}}(T)$&amp;quot;, fontsize=16)
plt.xlabel(L&amp;quot;$T \ (\mathrm{GeV})$&amp;quot;, fontsize=16)
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_0ee9f2531fadfe6013936d7924b40a12.webp 400w,
               /post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_d97dddc04d7e5e12feb3e8f9011b965c.webp 760w,
               /post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_c7838c58a55715770b7a77a8e37d4bc4.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/temp-evolution-decoupled/_hu84cbee5f7cfe9364418fc072b085e6b7_15690_0ee9f2531fadfe6013936d7924b40a12.webp&#34;
               width=&#34;576&#34;
               height=&#34;442&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;From this plot, we can see that $h(T)$ is bounded from above and below. The
bounding values are:
$$\begin{align}
h_{\mathrm{min}} \approx 3.93 &amp;lt; h(T) &amp;lt; 106.83  \approx h_{\mathrm{max}}
\end{align}$$
It is therefore straight forward to find bounds on $T$:
$$\begin{align}
\dfrac{T_{d}^3h_{d}(T_{d})}{C_{\infty}h_{\mathrm{max}}} &amp;lt; T &amp;lt; \dfrac{T_{d}^3h_{d}(T_{d})}{C_{\infty}h_{\mathrm{min}}}
\end{align}$$
Given these bounds, one can use a bisection method to solve for $T$ given a
value for $T_{d}$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thermal Distribution Functions</title>
      <link>https://loganamorrison.github.io/post/thermal-distributions/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/thermal-distributions/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this notebook we wish to compute the thermal distribution functions for
fermions and bosons. The functions we wish to compute are the equilibirium
number, energy, pressure and entropy densities. In full form, these are given by:
$$\begin{align}
n(T) &amp;amp;= g\int\dfrac{d^3k}{(2\pi)^2}f(\mathbf{k})\\\
\rho(T) &amp;amp;= g\int\dfrac{d^3k}{(2\pi)^2}E(\mathbf{k})f(\mathbf{k})\\\
P(T) &amp;amp;= g\int\dfrac{d^3k}{(2\pi)^2}\dfrac{|\mathbf{k}|^2}{3E(\mathbf{k})}f(\mathbf{k})
\end{align}$$
with $g$ representing the number of internal degrees of freedom (d.o.f),
$E^2 = k^2 + m^2$ and $f(\mathbf{k})$ is the phase-space distribution
function. For a species in kinetic equilibirium, the phase space distribution
is given by:
$$\begin{align}
f(\mathbf{k}) &amp;amp;= \dfrac{1}{e^{E/T}\pm1}
\end{align}$$
where one takes the $+$ for fermions and $-$ for bosons. Note that we have
ignored the chemical potential in writing down $f$. Since $f(\mathbf{k})$ is
independent of angles, we can integrate of the solid angle and obtain:
$$\begin{align}
n(T) &amp;amp;= \dfrac{g}{2\pi^2}\int_{m}^{\infty} dE \dfrac{E\sqrt{E^2-m^2}}{e^{E/T}\pm1}\\
\rho(T) &amp;amp;= \dfrac{g}{2\pi^2}\int_{m}^{\infty} dE \dfrac{E^2\sqrt{E^2-m^2}}{e^{E/T}\pm1}\\
P(T) &amp;amp;= \dfrac{g}{6\pi^2}\int_{m}^{\infty} dE \dfrac{(E^2-m^2)^{3/2}}{e^{E/T}\pm1}
\end{align}$$
We can further simplify these functions by defining: $z = E / T$ and
$x = m / T$. Doing so, we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
n(T) &amp;amp;= gT^3\bar{n}_{\pm}(x)\\\
\rho(T) &amp;amp;= gT^4\bar{\rho}_{\pm}(x)\\\
P(T) &amp;amp;= gT^4\bar{P}_{\pm}(x)
\end{align}$$&lt;/p&gt;
&lt;p&gt;where we defined the &amp;lsquo;barred&amp;rsquo; quantities as:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\int_{x}^{\infty} dz \dfrac{z\sqrt{z^2-x^2}}{e^{z}\pm1}\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\int_{x}^{\infty} dz \dfrac{z^2\sqrt{z^2-x^2}}{e^{z}\pm1}\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{1}{6\pi^2}\int_{x}^{\infty} dz \dfrac{(z^2-x^2)^{3/2}}{e^{z}\pm1}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define functions for these quantities. We will negelect $g$ and factors
of $T$ for now since they only contribute scaling.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using QuadGK

&amp;quot;&amp;quot;&amp;quot;
  nbar(x, stats)

Integral representation of n̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function nbar(x::Float64, stats::Symbol)
  pf::Float64 = 1 / (2π^2)
  function integrand(z::Float64)
    if stats == :boson
      return z * sqrt(z^2 - x^2) / (exp(z) - 1)
    elseif stats == :fermion
      return z * sqrt(z^2 - x^2) / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  ρbar(x, stats)

Integral representation of ρ̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function ρbar(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return z^2 * sqrt(z^2 - x^2) / (exp(z) - 1)
    elseif stats == :fermion
      return z^2 * sqrt(z^2 - x^2) / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  pbar(x, stats)

Integral representation of p̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function pbar(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return (z^2 - x^2)^1.5 / (exp(z) - 1)
    elseif stats == :fermion
      return (z^2 - x^2)^1.5 / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return quadgk(integrand, x, Inf)[1] / (6π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s plot the results of these functions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import PyPlot; const plt = PyPlot # python plotting
using LaTeXStrings

xs = 10 .^(range(-1, stop=1, length=100))
nbar_fermions = [nbar(x, :fermion) for x in xs]
ρbar_fermions = [ρbar(x, :fermion) for x in xs]
pbar_fermions = [pbar(x, :fermion) for x in xs]

nbar_bosons = [nbar(x, :boson) for x in xs]
ρbar_bosons = [ρbar(x, :boson) for x in xs]
pbar_bosons = [pbar(x, :boson) for x in xs]

plt.figure(dpi=100)
plt.plot(xs, nbar_fermions, label=L&amp;quot;$\bar{n}$ fermions&amp;quot;)
plt.plot(xs, ρbar_fermions, label=L&amp;quot;$\bar{\rho}$ fermions&amp;quot;)
plt.plot(xs, pbar_fermions, label=L&amp;quot;$\bar{P}$ fermions&amp;quot;)

plt.plot(xs, nbar_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ bosons&amp;quot;)
plt.plot(xs, ρbar_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ bosons&amp;quot;)
plt.plot(xs, pbar_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ bosons&amp;quot;)

plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
plt.ylim([1e-3, 1])
plt.xlim([1e-1, 1e1])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_0c5be179540cb710060d55ca9a1a83da.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_f2025a9262cabb33e865e6d373e033aa.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_2_1_hu1e69a7eac82d643e598b8db3a7f361a2_32243_0c5be179540cb710060d55ca9a1a83da.webp&#34;
               width=&#34;563&#34;
               height=&#34;440&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;There are a few things to take away from this plot. The first is that the
asymptotic behaviour as $x\to\infty$ is independent of statistics. The reseason
for this is clear: as $x\to\infty$, the integrand starts off with a very large
value of $z$ and hence, $e^{z} \gg \pm1$. The second thing to notice is that
the asymptotic behavior of $\bar{n}$ and $\bar{P}$ are identical, but they
differer from the asymptotic behavior of $\bar{\rho}$. The third thing to
notice is that the differences between fermions and bosons is small. We will
show why that&amp;rsquo;s the case later on.&lt;/p&gt;
&lt;h2 id=&#34;asymptotic-forms&#34;&gt;Asymptotic forms&lt;/h2&gt;
&lt;p&gt;The integrals for the number, energy and pressure densities can be evaluated
exactly for $x\ll 1$ and $x\gg1$. If we set $x = 0$, then the results are:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}(x) &amp;amp;= \dfrac{\zeta(3)}{\pi^2}
\begin{cases}
1 &amp;amp; \text{bosons}\\
3/4 &amp;amp; \text{fermions}
\end{cases}\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{\pi^2}{30}
\begin{cases}
1 &amp;amp; \text{bosons}\\
7/8 &amp;amp; \text{fermions}
\end{cases}\\
\bar{P}_{\pm}(x) &amp;amp;= \bar{\rho}/3
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In the opposite limit, we can simply ignore the statistics factors in the
denominators of the integral, obtaining:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}(x) &amp;amp;= e^{-x}\left(\frac{x}{2\pi}\right)^{3/2}\\
\bar{\rho}_{\pm}(x) &amp;amp;= xe^{-x}\left(\frac{x}{2\pi}\right)^{3/2}\\
\bar{P}_{\pm}(x) &amp;amp;= e^{-x}\left(\frac{x}{2\pi}\right)^{3/2}\\
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s check that these are correct:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using SpecialFunctions
nbar_small_x_b = zeta(3)/π^2
nbar_small_x_f = 3/4 * zeta(3)/π^2
ρbar_small_x_b = π^2/30
ρbar_small_x_f = 7/8 * π^2/30
pbar_small_x_b = π^2/90
pbar_small_x_f = 7/8 * π^2/90

nbar_large_x(x::Float64) = exp(-x) * (x/(2π))^1.5
ρbar_large_x(x::Float64) = x * exp(-x) * (x/(2π))^1.5
pbar_large_x(x::Float64) = exp(-x) * (x/(2π))^1.5
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=0, length=100))
nbar_fermions = [nbar(x, :fermion) for x in xs]
ρbar_fermions = [ρbar(x, :fermion) for x in xs]
pbar_fermions = [pbar(x, :fermion) for x in xs]

nbar_bosons = [nbar(x, :boson) for x in xs]
ρbar_bosons = [ρbar(x, :boson) for x in xs]
pbar_bosons = [pbar(x, :boson) for x in xs]

plt.figure(dpi=100)
plt.subplot(2, 2, 1)
plt.title(&amp;quot;Fermions&amp;quot;)
plt.plot(xs, nbar_fermions)
plt.plot(xs, ρbar_fermions)
plt.plot(xs, pbar_fermions)

plt.plot(xs, [nbar_small_x_f for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ small x&amp;quot;)
plt.plot(xs, [ρbar_small_x_f for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ small x&amp;quot;)
plt.plot(xs, [pbar_small_x_f for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ small x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.legend()

plt.subplot(2, 2, 2)
plt.title(&amp;quot;Bosons&amp;quot;)
plt.plot(xs, nbar_bosons)
plt.plot(xs, ρbar_bosons)
plt.plot(xs, pbar_bosons)
plt.plot(xs, [nbar_small_x_b for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ small x&amp;quot;)
plt.plot(xs, [ρbar_small_x_b for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ small x&amp;quot;)
plt.plot(xs, [pbar_small_x_b for _ in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ small x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.legend()

xs = 10 .^(range(0, stop=1, length=100))
nbar_fermions = [nbar(x, :fermion) for x in xs]
ρbar_fermions = [ρbar(x, :fermion) for x in xs]
pbar_fermions = [pbar(x, :fermion) for x in xs]

nbar_bosons = [nbar(x, :boson) for x in xs]
ρbar_bosons = [ρbar(x, :boson) for x in xs]
pbar_bosons = [pbar(x, :boson) for x in xs]

plt.subplot(2, 2, 3)
plt.plot(xs, nbar_fermions)
plt.plot(xs, ρbar_fermions)
plt.plot(xs, pbar_fermions)
plt.plot(xs, [nbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ large x&amp;quot;)
plt.plot(xs, [ρbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ large x&amp;quot;)
plt.plot(xs, [pbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ large x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
plt.legend()

plt.subplot(2, 2, 4)
plt.plot(xs, nbar_bosons)
plt.plot(xs, ρbar_bosons)
plt.plot(xs, pbar_bosons)
plt.plot(xs, [nbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{n}$ large x&amp;quot;)
plt.plot(xs, [ρbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{\rho}$ large x&amp;quot;)
plt.plot(xs, [pbar_large_x(x) for x in xs], &amp;quot;--&amp;quot;, label=L&amp;quot;$\bar{P}$ large x&amp;quot;)
plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
plt.legend()

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_c9684bc50574191847c61ad29ae76059.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_72e88b499117f4f3a991d3e1580dd733.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_5_1_hu919eebb188a1bc8ade07cc6cd9d75b0f_52625_c9684bc50574191847c61ad29ae76059.webp&#34;
               width=&#34;629&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;bessel-function-series-of-thermal-functions&#34;&gt;Bessel Function Series of Thermal Functions&lt;/h2&gt;
&lt;p&gt;The integrals for $\bar{n}(x), \bar{\rho}(x)$ and $\bar{P}(x)$ can be evaluated
exactly if one ignores the $\pm1$ in the denomiator of the integrands. This
suggests that one may be able to perform a series expansion of the denominator
in powers of $e^{-z}$ and evaluate the integrals exactly. This turns our to be
true. Note that:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{1}{e^{z}\pm1} &amp;amp;= \sum_{n=1}^{\infty}(\mp1)^{n+1}e^{-nz}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Therefore, the functions $\bar{n}(x), \bar{\rho}(x)$ and $\bar{P}(x)$ can be
written as:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}\int_{x}^{\infty} dz e^{-nz}z\sqrt{z^2-x^2}\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{1}{2\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}\int_{x}^{\infty} dz e^{-nz}z^2\sqrt{z^2-x^2}\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{1}{6\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}\int_{x}^{\infty} dz e^{-nz}(z^2-x^2)^{3/2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;These integrals can be represented as modified bessel functions of the second
kind:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\dfrac{(\mp 1)^{n+1}}{n}K_{2}(nx)\\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp 1)^{n+1}}{n^2}\left[n x K_{1}(nx)+3K_{2}(nx)\right]\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp 1)^{n+1}}{n^2}K_{2}(nx)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s make functions for these sums:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using SpecialFunctions

&amp;quot;&amp;quot;&amp;quot;
  nbar_bessel(x, stats, order)

Sum-of-bessel function representation of n̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
-`order::Int64`: number of terms in series to keep
&amp;quot;&amp;quot;&amp;quot;
function nbar_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n * besselk(2, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n * besselk(2, n*x) for n in 1:order])
  end
  bsum * x^2 / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  ρbar_bessel(x, stats, order)

Sum-of-bessel function representation of ρ̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
-`order::Int64`: number of terms in series to keep
&amp;quot;&amp;quot;&amp;quot;
function ρbar_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n^2 * (n * x * besselk(1, n*x) +
                3 * besselk(2, n*x)) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n^2 * (n * x * besselk(1, n*x) +
                3 * besselk(2, n*x)) for n in 1:order])
  end
  bsum * x^2 / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  pbar_bessel(x, stats, order)

Sum-of-bessel function representation of p̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
-`order::Int64`: number of terms in series to keep
&amp;quot;&amp;quot;&amp;quot;
function pbar_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n^2 * besselk(2, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n^2 * besselk(2, n*x) for n in 1:order])
  end
  bsum * x^2 / (2π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s plot these functions and see that they are correct:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=log10(3), length=100))

nrows = 2
ncols = 3

plt.figure(dpi=100)
for nrow in 1:nrows
  stats = (nrow == 1) ? :boson : :fermion
  for ncol in 1:ncols
    plt.subplot(nrows, ncols, ncols * (nrow - 1) + ncol)
    if ncol == 1
      plt.title(L&amp;quot;$\bar{n}$ &amp;quot; * string(stats))
      exact = [nbar(x, stats) for x in xs]
      approx1 = [nbar_bessel(x, stats, 1) for x in xs]
      approx5 = [nbar_bessel(x, stats, 5) for x in xs]
    elseif ncol == 2
      plt.title(L&amp;quot;$\bar{p}$ &amp;quot; * string(stats))
      exact = [pbar(x, stats) for x in xs]
      approx1 = [pbar_bessel(x, stats, 1) for x in xs]
      approx5 = [pbar_bessel(x, stats, 5) for x in xs]
    elseif ncol == 3
      plt.title(L&amp;quot;$\bar{\rho}$ &amp;quot; * string(stats))
      exact = [ρbar(x, stats) for x in xs]
      approx1 = [ρbar_bessel(x, stats, 1) for x in xs]
      approx5 = [ρbar_bessel(x, stats, 5) for x in xs]
    end
    plt.plot(xs, exact, lw=3, alpha=0.6, label=&amp;quot;exact&amp;quot;)
    plt.plot(xs, approx1, &amp;quot;r--&amp;quot;, label=&amp;quot;n=1&amp;quot;)
    plt.plot(xs, approx5, &amp;quot;k--&amp;quot;, label=&amp;quot;n=1:5&amp;quot;)
    plt.yscale(&amp;quot;log&amp;quot;)
    plt.xscale(&amp;quot;log&amp;quot;)
    plt.xlim([minimum(xs), maximum(xs)])
    if ncol == 3 &amp;amp;&amp;amp; nrow == 2
      plt.legend()
    end
  end
end

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_20c01f773be2813f7de88a4d1b0c8d9c.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_ed9902173e7629aee4a42ec6c3bceba7.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_8_1_hu0019447d4fbb8735ea14e80f47f3b7c9_49575_20c01f773be2813f7de88a4d1b0c8d9c.webp&#34;
               width=&#34;629&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;From these plots, we can see that even just the first term approximates the
thermal functions quite well. In practice, it is a good approximation to take:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}K_{2}(x)\\\
\bar{\rho}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}\left[xK_{1}(x)+3K_{2}(x)\right]\\
\bar{P}_{\pm}(x) &amp;amp;= \dfrac{x^2}{2\pi^2}K_{2}(x)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;These approximations have the added benifit of being independent of statistics.
The corrections for statistics come in when we include the second terms in the
sums. Let&amp;rsquo;s plot the percent errors when only including the first and second
terms in the series:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=log10(3), length=100))

nrows = 2
ncols = 3

plt.figure(dpi=100)
for nrow in 1:nrows
  stats = (nrow == 1) ? :boson : :fermion
  for ncol in 1:ncols
    plt.subplot(nrows, ncols, ncols * (nrow - 1) + ncol)
    if ncol == 1
      plt.title(L&amp;quot;$\bar{n}$ &amp;quot; * string(stats))
      exact = [nbar(x, stats) for x in xs]
      approx1 = [nbar_bessel(x, stats, 1) for x in xs]
      approx2 = [nbar_bessel(x, stats, 2) for x in xs]
      approx3 = [nbar_bessel(x, stats, 3) for x in xs]
    elseif ncol == 2
      plt.title(L&amp;quot;$\bar{p}$ &amp;quot; * string(stats))
      exact = [pbar(x, stats) for x in xs]
      approx1 = [pbar_bessel(x, stats, 1) for x in xs]
      approx2 = [pbar_bessel(x, stats, 2) for x in xs]
      approx3 = [pbar_bessel(x, stats, 3) for x in xs]
    elseif ncol == 3
      plt.title(L&amp;quot;$\bar{\rho}$ &amp;quot; * string(stats))
      exact = [ρbar(x, stats) for x in xs]
      approx1 = [ρbar_bessel(x, stats, 1) for x in xs]
      approx2 = [ρbar_bessel(x, stats, 2) for x in xs]
      approx3 = [ρbar_bessel(x, stats, 3) for x in xs]
    end
    if ncol == 1
      plt.ylabel(L&amp;quot;$\%$ error&amp;quot;)
    end
    plt.plot(xs, abs.(exact .- approx1) ./ exact .* 100, label=&amp;quot;n=1&amp;quot;)
    plt.plot(xs, abs.(exact .- approx2) ./ exact .* 100, label=&amp;quot;n=1:2&amp;quot;)
    plt.plot(xs, abs.(exact .- approx3) ./ exact .* 100, label=&amp;quot;n=1:3&amp;quot;)
    plt.xscale(&amp;quot;log&amp;quot;)
    #plt.yscale(&amp;quot;log&amp;quot;)
    plt.xlim([minimum(xs), maximum(xs)])
    plt.ylim([0, 20])
    if ncol == 1 &amp;amp;&amp;amp; nrow == 2
      plt.legend()
    end
  end
end

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_9f9bc5b6ead32807a3136cd0af00ccf8.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_7678a102ffa0784075419c1ca6b30629.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_9_1_hu9f2b5e6b82f6b794785d24eb8d9e3559_38665_9f9bc5b6ead32807a3136cd0af00ccf8.webp&#34;
               width=&#34;629&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;From these plots, we can see that we are always within 20% of the actual value
even when only including the first term in the series. We see rapid global
convergence when we begin including higher order terms.&lt;/p&gt;
&lt;h2 id=&#34;entropy-density&#34;&gt;Entropy Density&lt;/h2&gt;
&lt;p&gt;In addition to the number, pressure and energy density, one also typical cares
about the entropy density. It can be shown that the entropy density is given
by:
$$\begin{align}
s(T) &amp;amp;= \dfrac{\rho(T) + P(T)}{T} = gT^3(\bar{\rho}(x) + \bar{P}(x))
\end{align}$$
In integral form, this is:
$$\begin{align}
s(T) &amp;amp;= gT^3\bar{s}(x)
\end{align}$$
where&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{s}(x) &amp;amp;=  \bar{\rho}(x) + \bar{P}(x) = \dfrac{1}{6\pi^2}\int_{x}^{\infty} dz \dfrac{(4z^2-x^2)\sqrt{z^2-x^2}}{e^{z}\pm1}\
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In terms of bessel functions, this is:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{s}(x) &amp;amp;= \dfrac{x^3}{2\pi^2}\sum_{n=1}^{\infty}\dfrac{(\mp1)^{n+1}}{n}K_{3}(nx)
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;degrees-of-freedom-stored-in-energy-and-entropy&#34;&gt;Degrees of Freedom Stored in Energy and Entropy&lt;/h2&gt;
&lt;p&gt;When dealing with many species of particles, it is often useful to define the
energy and entropy density in terms of a single function:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\rho(T) &amp;amp;= \sum_{i}\rho_{i}(T) = T^4\sum_{i}g_{i}\bar{\rho}_{i}(x) \equiv \dfrac{\pi^2}{30}g_{\mathrm{eff}}(T)T^4\\
s(T) &amp;amp;= \sum_{i}s_{i}(T) = T^3\sum_{i}g_{i}\bar{s}_{i}(x) \equiv \dfrac{2\pi^2}{45}h_{\mathrm{eff}}(T)T^3
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where the sum runs over all particles and the effective number of relativistic
d.o.f. stored in energy and entropy $g_{\mathrm{eff}}$, $h_{\mathrm{eff}}$ are:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
g_{\mathrm{eff}}(T) &amp;amp;= \dfrac{30}{\pi^2}\sum_{i}g_{i}\bar{\rho}_{i}(x)\\\
h_{\mathrm{eff}}(T) &amp;amp;= \dfrac{45}{2\pi^2}\sum_{i}g_{i}\bar{s}_{i}(x)
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;derivatives-of-thermal-functions&#34;&gt;Derivatives of Thermal Functions&lt;/h2&gt;
&lt;p&gt;Lastly, let&amp;rsquo;s investigate the derivatives of the various functions. The
derivatives are:
$$\begin{align}
\dfrac{dn}{dT} &amp;amp;= gT^2\left(3T\bar{n}(x)-x\dfrac{d\bar{n}}{dx}\right)\\\
\dfrac{d\rho}{dT} &amp;amp;= gT^3\left(4T\bar{\rho}(x)-x\dfrac{d\bar{\rho}}{dx}\right)\\\
\dfrac{dP}{dT} &amp;amp;= gT^3\left(4T\bar{P}(x)-x\dfrac{d\bar{P}}{dx}\right)\\\
\dfrac{ds}{dT} &amp;amp;= gT^2\left(3T\bar{s}(x)-x\dfrac{d\bar{s}}{dx}\right)
\end{align}$$&lt;/p&gt;
&lt;p&gt;We will want to compute derivatives of the barred quantities. All of the barred
quantities are of the form:
$$\begin{align}
\int_{x}^{\infty}f(x,z)dz
\end{align}$$
Using Leibniz&amp;rsquo;s rule for differentiating integrals, one finds that:
$$\begin{align}
\dfrac{d}{dx}\int_{x}^{\infty}f(x,z)dz =
\int_{x}^{\infty}\dfrac{\partial f}{\partial x}dz - f(x, x)
\end{align}$$
Notice that all the integrand for our function evaluated at $z=x$ are zero.
Thus, we only need the integrate the derivative of the integrand w.r.t $x$. The
derivatives are:
$$\begin{align}
\dfrac{d\bar{n}}{dx} &amp;amp;= -\dfrac{x}{2\pi^2}\int_{x}^{\infty}\dfrac{z}{(e^{z}-1)\sqrt{z^2-x^2}}\\
\dfrac{d\bar{\rho}}{dx} &amp;amp;= -\dfrac{x}{2\pi^2}\int_{x}^{\infty}\dfrac{z^2}{(e^{z}-1)\sqrt{z^2-x^2}}\\
\dfrac{d\bar{P}}{dx} &amp;amp;= -\dfrac{x}{2\pi^2}\int_{x}^{\infty}\dfrac{\sqrt{z^2-x^2}}{(e^{z}-1)}
\end{align}$$
Let&amp;rsquo;s make some function for these and then invesigate how the look&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot;&amp;quot;&amp;quot;
  nbar_deriv(x, stats)

Derivative of the integral representation of n̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function nbar_deriv(x::Float64, stats::Symbol)
  pf::Float64 = 1 / (2π^2)
  function integrand(z::Float64)
    if stats == :boson
      return z / (exp(z) - 1) / sqrt(z^2 - x^2)
    elseif stats == :fermion
      return z / (exp(z) + 1) / sqrt(z^2 - x^2)
    else
      return 0.0
    end
  end
  return -x * quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  ρbar_deriv(x, stats)

Derivative of the integral representation of ρ̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function ρbar_deriv(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return z^2 / (exp(z) - 1) / sqrt(z^2 - x^2)
    elseif stats == :fermion
      return z^2 / (exp(z) + 1) / sqrt(z^2 - x^2)
    else
      return 0.0
    end
  end
  return -x * quadgk(integrand, x, Inf)[1] / (2π^2)
end

&amp;quot;&amp;quot;&amp;quot;
  pbar_deriv(x, stats)

Derivative of the integral representation of p̄

# Arguments
-`x::Float64`: mass of particle divided by temperature
-`stats::Symbol`: `:boson` or `:fermion`
&amp;quot;&amp;quot;&amp;quot;
function pbar_deriv(x::Float64, stats::Symbol)
  function integrand(z::Float64)
    if stats == :boson
      return sqrt(z^2 - x^2) / (exp(z) - 1)
    elseif stats == :fermion
      return sqrt(z^2 - x^2) / (exp(z) + 1)
    else
      return 0.0
    end
  end
  return -x * quadgk(integrand, x, Inf)[1] / (2π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s plot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-1, stop=1, length=100))
nbar_deriv_fermions = [nbar_deriv(x, :fermion) for x in xs]
ρbar_deriv_fermions = [ρbar_deriv(x, :fermion) for x in xs]
pbar_deriv_fermions = [pbar_deriv(x, :fermion) for x in xs]

nbar_deriv_bosons = [nbar_deriv(x, :boson) for x in xs]
ρbar_deriv_bosons = [ρbar_deriv(x, :boson) for x in xs]
pbar_deriv_bosons = [pbar_deriv(x, :boson) for x in xs]

plt.figure(dpi=100)
plt.plot(xs, nbar_deriv_fermions, label=L&amp;quot;$d\bar{n}/dx$ fermions&amp;quot;)
plt.plot(xs, ρbar_deriv_fermions, label=L&amp;quot;$d\bar{\rho}/dx$ fermions&amp;quot;)
plt.plot(xs, pbar_deriv_fermions, label=L&amp;quot;$d\bar{P}/dx$ fermions&amp;quot;)

plt.plot(xs, nbar_deriv_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$d\bar{n}/dx$ bosons&amp;quot;)
plt.plot(xs, ρbar_deriv_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$d\bar{\rho}/dx$ bosons&amp;quot;)
plt.plot(xs, pbar_deriv_bosons, &amp;quot;--&amp;quot;, label=L&amp;quot;$d\bar{P}/dx$ bosons&amp;quot;)

#plt.yscale(&amp;quot;log&amp;quot;)
plt.xscale(&amp;quot;log&amp;quot;)
plt.xlabel(L&amp;quot;$x$&amp;quot;, fontsize=16)
#plt.ylim([1e-3, 1])
plt.xlim([minimum(xs), maximum(xs)])
plt.legend()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_4231ed3c7c141cc5856c48e0230a7515.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_7a917f034b7d92cb16be111d8f88bd80.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_12_1_hu39cb897a72c79f8387e2fcf2bc2e421c_53419_4231ed3c7c141cc5856c48e0230a7515.webp&#34;
               width=&#34;570&#34;
               height=&#34;439&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Next, let&amp;rsquo;s investigate the sum-over-bessel function representation of the
derivatives. These are:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\bar{n}_{\pm}(x) &amp;amp;= -\dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}(\mp1)^{n+1}K_{1}(nx)\\\
\bar{\rho}_{\pm}(x) &amp;amp;= -\dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp1)^{n+1}}{n}\left[nxK_{0}(nx)+K_{1}(nx)\right]\\
\bar{P}_{\pm}(x) &amp;amp;= -\dfrac{x^2}{2\pi^2}\sum_{n=1}^{\infty}\frac{(\mp1)^{n+1}}{n}K_{1}(nx)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s make functions for these:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using SpecialFunctions

function nbar_deriv_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) * besselk(1, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([besselk(1, n*x) for n in 1:order])
  end
  -bsum * x^2 / (2π^2)
end

function ρbar_deriv_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n * (n * x * besselk(0, n*x) +
                besselk(1, n*x)) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n * (n * x * besselk(0, n*x) +
                besselk(1, n*x)) for n in 1:order])
  end
  -bsum * x^2 / (2π^2)
end

function pbar_deriv_bessel(x::Float64, stats::Symbol, order::Int64)
  bsum::Float64 = 0.0
  if stats == :fermion
    bsum = sum([(-1)^(n+1) / n * besselk(1, n*x) for n in 1:order])
  elseif stats == :boson
    bsum = sum([1 / n * besselk(1, n*x) for n in 1:order])
  end
  -bsum * x^2 / (2π^2)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s plot to compare:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = 10 .^(range(-2, stop=1, length=100))

nrows = 2
ncols = 3

plt.figure(dpi=100)
for nrow in 1:nrows
  stats = (nrow == 1) ? :boson : :fermion
  for ncol in 1:ncols
    plt.subplot(nrows, ncols, ncols * (nrow - 1) + ncol)
    if ncol == 1
      plt.title(L&amp;quot;$\bar{n}$ &amp;quot; * string(stats))
      exact = [nbar_deriv(x, stats) for x in xs]
      approx1 = [nbar_deriv_bessel(x, stats, 1) for x in xs]
      approx5 = [nbar_deriv_bessel(x, stats, 5) for x in xs]
    elseif ncol == 2
      plt.title(L&amp;quot;$\bar{p}$ &amp;quot; * string(stats))
      exact = [pbar_deriv(x, stats) for x in xs]
      approx1 = [pbar_deriv_bessel(x, stats, 1) for x in xs]
      approx5 = [pbar_deriv_bessel(x, stats, 5) for x in xs]
    elseif ncol == 3
      plt.title(L&amp;quot;$\bar{\rho}$ &amp;quot; * string(stats))
      exact = [ρbar_deriv(x, stats) for x in xs]
      approx1 = [ρbar_deriv_bessel(x, stats, 1) for x in xs]
      approx5 = [ρbar_deriv_bessel(x, stats, 5) for x in xs]
    end
    plt.plot(xs, exact, lw=3, alpha=0.6, label=&amp;quot;exact&amp;quot;)
    plt.plot(xs, approx1, &amp;quot;r--&amp;quot;, label=&amp;quot;n=1&amp;quot;)
    plt.plot(xs, approx5, &amp;quot;k--&amp;quot;, label=&amp;quot;n=1:5&amp;quot;)
    #plt.yscale(&amp;quot;log&amp;quot;)
    plt.xscale(&amp;quot;log&amp;quot;)
    plt.xlim([minimum(xs), maximum(xs)])
    if ncol == 3 &amp;amp;&amp;amp; nrow == 2
      plt.legend()
    end
  end
end

plt.tight_layout()
plt.gcf()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_c4c4aab3029047290b566181e1f27c16.webp 400w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_abc42e1d5887aa3a7bd57b7b77d60670.webp 760w,
               /post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://loganamorrison.github.io/post/thermal-distributions/2019-08-21-thermal-distribution-functions_14_1_hu482d3b1ce6706dff3e45ed267245765c_68008_c4c4aab3029047290b566181e1f27c16.webp&#34;
               width=&#34;630&#34;
               height=&#34;469&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rutherford Scattering</title>
      <link>https://loganamorrison.github.io/post/rutherford-scattering/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://loganamorrison.github.io/post/rutherford-scattering/</guid>
      <description>&lt;h2 id=&#34;classical-calculation&#34;&gt;Classical Calculation&lt;/h2&gt;
&lt;p&gt;$\require{cancel}$
$\newcommand{\bra}[1]{\left&amp;lt; #1 \right|}$
$\newcommand{\ket}[1]{\left| #1 \right&amp;gt;}$
$\newcommand{\bk}[2]{\left&amp;lt; #1 \middle| #2 \right&amp;gt;}$
$\newcommand{\bke}[3]{\left&amp;lt; #1 \middle| #2 \middle| #3 \right&amp;gt;}$
$\newcommand{\Tr}{\mathrm{Tr}}$&lt;/p&gt;
&lt;p&gt;We consider a charged particle of mass $m$ scattering off a heavy
nucleus. Let the impact parameter be $b$ and the energy of the impinging
particle be $E$. The classical Lagrangian for a particle with charge $e$
scattering off a heavy nucleus of charge $eZ$ is:
$$\begin{align}
\mathcal{L}= T - V = \dfrac{1}{2}m \left(\dfrac{d\mathbf{r}}{dt}\right)^2 - V(r)
\end{align}$$
with
$$\begin{align}
V(r) = \dfrac{e^2Z}{4\pi r}
\end{align}$$
In the plane of scattering, we need only to consider two variables - $|\mathbf{r}| = r$ and $\theta$. We can write the derivative of $\mathbf{r}$ as:
$$\begin{align}
\dfrac{d\mathbf{r}}{dt} = \dfrac{dr}{dt}\hat{\mathbf{r}} + r \dfrac{d\theta}{dt}\hat{\mathbf{\theta}}
\end{align}$$
Our Lagrangian then reads:
$$\begin{align}
\mathcal{L}= \dfrac{1}{2}m \left(\left(\dfrac{dr}{dt}\right)^2 + r^2 \left(\dfrac{d\theta}{dt}\right)^2\right) - \dfrac{e^2Z}{4\pi r}
\end{align}$$
The Euler-Lagrange equation of $\theta$ reads:
$$\begin{align}
0 = \dfrac{\partial\mathcal{L}}{d\theta} = \dfrac{d}{dt}\dfrac{\partial\mathcal{L}}{\partial\dot{\theta}} = \dfrac{d}{dt}mr^2\dot{\theta}
\end{align}$$
Hence, $mr^2\dot{\theta}$ is a constant, which is the angular momentum,
$L = b\sqrt{2mE}$. Therefore,
$$\begin{align}
\dfrac{d\theta}{dt} = \dfrac{L}{mr^2}
\end{align}$$
By energy conservation, we can write
$$\begin{align}
E = \dfrac{1}{2}m \left(\left(\dfrac{dr}{dt}\right)^2 + r^2 \left(\dfrac{d\theta}{dt}\right)^2\right) + \dfrac{e^2Z}{4\pi r}
\end{align}$$
We can readily solve this equation for the time derivative of $r$,
obtaining:
$$\begin{align}
\dfrac{dr}{dr} = \dfrac{1}{mr}\sqrt{2mEr^2 - \dfrac{e^2Zm}{2\pi}r - L^2}
\end{align}$$
We can write
$$\begin{align}
\dfrac{d\theta}{dt} = \dfrac{d\theta}{dr}\dfrac{dr}{dt} = \dfrac{L}{mr^2}
\end{align}$$
Therefore,
$$\begin{align}
\dfrac{d\theta}{dr} = \dfrac{L}{mr^2}\left(\dfrac{dr}{dt}\right)^{-1} = \dfrac{L}{r\sqrt{2mEr^2 - \dfrac{e^2Zm}{2\pi}r - L^2}}
\end{align}$$
This equation can be integrated to obtain the final value of $\theta$.
We would want to integrate this equation over $\infty\to\infty$. We can
instead integrate this equation over $r_{0}\to\infty$ where $r_0$ is the
minimum value of $r$. The minimum value of $r$ will occur when
$dr/dt = 0$, which happens when
$$\begin{align}
2mEr^2 - \dfrac{e^2Zm}{2\pi}r - L^2 = 0
\end{align}$$
We can solve this equation by completing the square:
$$\begin{align}
r_0 = \dfrac{e^2Z}{8\pi E} + \sqrt{\dfrac{L^2}{2mE} + \dfrac{e^4Z^2}{64\pi^2 E^2}} = A + \sqrt{A^2 + b^2}
\end{align}$$
where
$$\begin{align}
A &amp;amp; = \dfrac{e^2Z}{8\pi E}
\end{align}$$
Given these definitions,
$$\begin{align}
\theta(\infty)-\theta(r_{0}) = \int_{r_{0}}^{\infty}dr \dfrac{b}{r\sqrt{(r-A)^2-A^2-b^2}}
\end{align}$$
Integrating this give us:
$$\begin{align}
\theta(\infty)-\theta(r_{0}) = -\dfrac{\pi}{2} - i\log(\dfrac{-b+iA}{\sqrt{A^2+b^2}})
\end{align}$$
If we rotate our system such that $\theta(r_0) = \pi/2$ (which sends
$\theta\to\theta/2$), then we find that
$$\begin{align}
\sin(\theta/2) = \dfrac{A}{\sqrt{A^2+b^2}}
\end{align}$$
We thus find that
$$\begin{align}
b = A\cot(\theta/2)
\end{align}$$
This implies that the impact parameter as a function of $\theta$ is
$$\begin{align}
b = \dfrac{e^2Z}{8\pi E\tan(\theta/2)}
\end{align}$$
Recall that the differential scattering cross-sections is
$$\begin{align}
\dfrac{d\sigma}{d\Omega} = \dfrac{b}{\sin\theta}\dfrac{db}{d\theta}
\end{align}$$
we find that
$$\begin{align}
\dfrac{d\sigma}{d\Omega} = \dfrac{e^4Z^2}{256\pi^2E^2\sin^4(\theta/2)} = \dfrac{\alpha^2Z^2}{16E^2\sin^4(\theta/2)} = \dfrac{\alpha^2Z^2}{4m^2v_i^2\sin^4(\theta/2)}
\end{align}$$
where $\alpha = e^2/4\pi$.&lt;/p&gt;
&lt;h2 id=&#34;quantum-field-theory-calculation&#34;&gt;Quantum Field Theory Calculation&lt;/h2&gt;
&lt;p&gt;In this section, we will investigate Rutherford Scattering through the
point of view of quantum field theory. We will consider the electron and
positron as dynamic fields and the photon field as static. The
Lagrangian we will consider is
$$\begin{align}
\mathcal{L}= \overline{\Psi}\left(i\cancel{\partial}-m\right)\Psi
-eA_{\mu}\overline{\Psi}\gamma^{\mu}\Psi
\end{align}$$
Our goal will be to calculate the differential cross-section
$\dfrac{d\sigma}{d\Omega}$ for an electron scattering of the static
potential. The $T$ matrix element for this process, to first order in
the electromagnetic coupling constant, is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p}
&amp;amp; = \bra{p&amp;rsquo;,s&amp;rsquo;}T\exp\left[-i\int d^4x \mathcal{L}_{I}(x)\right]\ket{p,s} \\
&amp;amp; = ie\int d^4x \bra{p&amp;rsquo;,s&amp;rsquo;}A_{\mu}(x)\overline{\Psi}(x)\gamma^{\mu}\Psi(x)\ket{p,s}+
\mathcal{O}(e^2)\\\
&amp;amp; = ie\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)
\int d^4xA_{\mu}(x)e^{i(p&amp;rsquo;-p)x}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now Fourier transform the photon field:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
A_{\mu}(x) = \int \dfrac{d^4q}{(2\pi)^4}\tilde{A}_{\mu}(q)e^{-iqx}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Inserting this into the expression for the $T$-matrix element, we find&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p}
&amp;amp; = ie\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)
\int d^4x\int \dfrac{d^4q}{(2\pi)^4}
\tilde{A}_{\mu}(q)e^{i(p&amp;rsquo;-p-q)x}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Integrating over $x$ will produce a factor of $(2\pi)^4\delta^4(p&amp;rsquo;-p-q)$. We can then integrate over $q$ using this delta function, producing&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p}
&amp;amp; = ie\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)\tilde{A}_{\mu}(p&amp;rsquo;-p)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, suppose the photon field is time-independent. Then, the fourier
transform of the photon field is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\tilde{A}_{\mu}(p&amp;rsquo;-p) &amp;amp; = \int d^3zA_{\mu}(\mathbf{z}) e^{i(\mathbf{p}&amp;rsquo;-\mathbf{p})\cdot\mathbf{z}}\int_{-\infty}^{\infty}dt&amp;rsquo;e^{i(E_{p&amp;rsquo;}-E_{p})t&amp;rsquo;}\\
&amp;amp; = (2\pi)\delta(E_{p&amp;rsquo;}-E_{p})\int d^3zA_{\mu}(\mathbf{z})
e^{i(\mathbf{p}&amp;rsquo;-\mathbf{p})\cdot\mathbf{z}}
\end{align}$$&lt;/p&gt;
&lt;p&gt;We now define the matrix element as&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\langle{p&amp;rsquo;}|iT|\rangle{p} = (2\pi)i\delta(E_{p&amp;rsquo;}-E_{p})\mathcal{M}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Through this definition, we can see that $\mathcal{M}$ is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\mathcal{M}= e\overline{u}^{s&amp;rsquo;}(p&amp;rsquo;)\gamma^{\mu}u^s(p)
\tilde{A}_{\mu}(\mathbf{p}&amp;rsquo;-\mathbf{p})
\end{align}$$&lt;/p&gt;
&lt;p&gt;where it is understood that $E_{p&amp;rsquo;} = E_{p}$. Let&amp;rsquo;s square this matrix element and average over the initial spin and sum over final spin of the electron:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\sum_{s,s&amp;rsquo;}\left|\mathcal{M}\right|^2
&amp;amp; =\dfrac{1}{2}e^2\tilde{A}_{\mu}\tilde{A}_{\nu}
\Tr\left[\left(\cancel{p}&amp;rsquo;+m\right)\gamma^{\mu}
\left(\cancel{p}+m\right)\gamma^{\nu}\right]\\
&amp;amp; =\dfrac{1}{2}e^2\tilde{A}_{\mu}\tilde{A}_{\nu}
\left(\Tr\left[\cancel{p}&amp;rsquo;\gamma^{\mu}\cancel{p}\gamma^{\nu}\right]
+m^2\Tr\left[\gamma^{\mu}\gamma^{\nu}\right]\right)\\\
&amp;amp; = 2e^2\tilde{A}_{\mu}\tilde{A}_{\nu}
\left(p&amp;rsquo;^{\mu}p^{\nu}+p&amp;rsquo;^{\nu}p^{\mu}-(p&amp;rsquo;\cdot p)g^{\mu\nu}
+m^2g^{\mu\nu}\right)\\\
&amp;amp; = 2e^2\left[2\left(\tilde{A}\cdot p&amp;rsquo;\right)\left(\tilde{A}\cdot p\right)
+(m^2-p&amp;rsquo;\cdot p)\left(\tilde{A}\cdot\tilde{A}\right)\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s assume that the four-potential is generated by a charged
particle of charge $Ze$. Then, the vector potential is given by&lt;/p&gt;
&lt;p&gt;$$\begin{align}
A^0(\mathbf{x}) = \dfrac{Ze}{4\pi r} \qquad \text{and}\qquad\mathbf{A}(\mathbf{x}) = 0
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $r = \left|\mathbf{x}\right|$. Now, let&amp;rsquo;s compute the fourier transform of
this potential. To do so, we need to regulate the integrate. We modify
it in the following way:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
A^0(\mathbf{x}) = \dfrac{Ze}{4\pi r}e^{-\lambda r}
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $\lambda$ will be taken to zero at the end of the calculation. The
Fourier transform of this vector potential is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\tilde{A}^0(k)
&amp;amp;= \int d^3\mathbf{x}\dfrac{Ze}{4\pi r}e^{-\lambda r}e^{i k r\cos(\theta)}\\
&amp;amp;= \dfrac{Ze}{2}\int_{0}^{\infty}dr\int_{-1}^{1}d(\cos\theta)re^{-\lambda r}
e^{i k r\cos(\theta)}\\
&amp;amp;= \dfrac{Ze}{2ik}\left[\dfrac{e^{(ik-\lambda) r}}{ik-\lambda}+
\dfrac{e^{(-ik-\lambda) r}}{ik+\lambda}\right]_{0}^{\infty}\\
&amp;amp;= -\dfrac{Ze}{2ik}\left[\dfrac{(-ik-\lambda)+(-ik+\lambda)}{k^2+\lambda^2}\right]\\
&amp;amp; = \dfrac{Ze}{k^2+\lambda^2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $k = |\mathbf{p}&amp;rsquo;-\mathbf{p}|$. Taking $\lambda$ to zero, we obtain&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\tilde{A}^0(\mathbf{p}&amp;rsquo;-\mathbf{p}) = \dfrac{Ze}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^2}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s use this to simplify the matrix element. The matrix element is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\sum_{s,s&amp;rsquo;}\left|\mathcal{M}\right|^2
&amp;amp; = 2e^2
\left[2 \dfrac{Z^2e^2E_iE_f}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}
+(m^2-E_iE_f+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;)
\dfrac{Z^2e^2}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}\right]\\
&amp;amp; =  \dfrac{2Z^2e^4}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}
\left[E_iE_f+m^2+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;We are now ready to compute the differential cross section. The
differential cross section is given by&lt;/p&gt;
&lt;p&gt;$$\begin{align}
d\sigma = \dfrac{1}{2E_iv_i}\dfrac{d^3p_f}{(2\pi)^3(2E_f)}
(2\pi)\delta(E_f-E_i)\left|\mathcal{M}\right|^2
\end{align}$$&lt;/p&gt;
&lt;p&gt;Using&lt;/p&gt;
&lt;p&gt;$$\begin{align}
p_f^2 dp_fd\Omega = p_fE_fdE_fd\Omega
\end{align}$$&lt;/p&gt;
&lt;p&gt;(where $p_f$ and $p_i$ are the magnitude of the initial and final momentum
respectively,) and integrating over $E_f$, we obtain $E_f=E_i=E$ and
$p_f = p_i$. Thus, the differential cross section is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{d\sigma}{d\Omega}
= \dfrac{1}{4Ev_i(2\pi)^2}
\dfrac{2Z^2e^4}{|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4}p_f
\left[E^2+m^2+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let $\theta$ be the angle between $\mathbf{p}&amp;rsquo;$ and $\mathbf{p}$. Then,&lt;/p&gt;
&lt;p&gt;$$\begin{align}
|\mathbf{p}&amp;rsquo;-\mathbf{p}|^4 &amp;amp; = \left(p_i^2+p_f^2-2p_fp_i\cos\theta\right)^2 \\
&amp;amp; = \left(2p_i^2-2p_i^2\cos\theta\right)^2       \\
&amp;amp; = 4p_i^4\left(1-\cos\theta\right)^2            \\
&amp;amp; = 16p_i^4\sin^4(\theta/2)
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now, in the non-relativistic limit, the momentum is $p_i=mv_i$ and $E=m$.
Hence, the differential cross section is&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{d\sigma}{d\Omega}
&amp;amp; = \dfrac{1}{4mv_i(2\pi)^2}
\dfrac{2Z^2e^4mv_i}{(16)m^4v_i^4\sin^4(\theta/2)}
\left[E^2+m^2+\mathbf{p}\cdot\mathbf{p}&amp;rsquo;\right]\\
&amp;amp; = \dfrac{1}{8\pi^2}
\dfrac{Z^2e^4}{(16)m^4v_i^4\sin^4(\theta/2)}
\left[2m^2+m^2v_i^2\cos\theta\right]
\end{align}$$&lt;/p&gt;
&lt;p&gt;Since $v_i\ll 1$, we find that&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{d\sigma}{d\Omega}
&amp;amp; =\dfrac{Z^2\alpha^2}{4m^2v_i^4\sin^4(\theta/2)}
\end{align}$$&lt;/p&gt;
&lt;p&gt;where we used $e^2=4\pi\alpha$.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
